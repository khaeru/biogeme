\documentclass[12pt]{memoir}

%\usepackage{fancyhdr}
%\usepackage{euler,beton}
\usepackage{euler}
\usepackage{times}

%Package to display boxes around texts. Used especially for the internal notes.
\usepackage{framed}

\newcommand{\note}[1]{
\begin{framed}{}%
\textbf{\underline{Internal note}:} #1
\end{framed}}

\usepackage[dcucite,abbr]{harvard}
\harvardparenthesis{none}\harvardyearparenthesis{round}

\usepackage{index}
%\usepackage{makeidx}
\usepackage{amsmath}
\usepackage{float}
\usepackage{amsfonts}
\usepackage{moreverb}
\usepackage{varioref}
\usepackage{epsfig}
\usepackage{pstricks}
\usepackage{pst-plot}

\renewcommand{\bf}{\textbf}

\makeindex


\title{Estimation of discrete choice models with Biogeme}
\author{Michel Bierlaire\thanks{Ecole Polytechnique F\'ed\'erale de Lausanne, Transport and Mobility Laboratory, CH-1015 Lausanne,
Switzerland. Email: michel.bierlaire@epfl.ch}}

\date{\today}


\begin{document}

%\newcommand{\citeasnoun}[1]{\cite{#1}}

\newcommand{\prob}{\operatorname{Pr}}
\newcommand{\expect}{\operatorname{E}}
\newcommand{\req}[1]{(\ref{#1})}
\newcommand{\BIOGEME}{Biogeme~2.4}
%\newcommand{\BIOROUTE}{Bioroute~1.9}
\newcommand{\BIOSIM}{Biosim~2.4}
\newcommand{\PBIOGEME}{PythonBiogeme~2.4}

% A redefinir

\newcommand{\paramitem}[1]{\texttt{#1}\index{default.par!#1}}
\newcommand{\specitem}[1]{\texttt{[#1]}\index{Model specification file!#1}}
\newcommand{\routeitem}[1]{\texttt{[#1]}\index{BIOROUTE!#1}}
\newcommand{\fileitem}[1]{\texttt{#1}\index{Files!#1}}

\newcommand{\C}{\mathcal{C}}
\newcommand{\R}{\mathbb{R}}
\renewcommand{\L}{\mathcal{L}}
\maketitle

\vspace{2cm}

\begin{center}
\small Report TRANSP-OR xxxxxx \\ Transport and Mobility Laboratory \\ School of Architecture, Civil and Environmental Engineering \\ Ecole Polytechnique F\'ed\'erale de Lausanne \\ \verb+transp-or.epfl.ch+
\end{center}

\clearpage


\tableofcontents




\chapter{Introduction}

Bierlaire Optimization toolbox for GEv Model Estimation (BIOGEME) is a
freeware package designed for the development of research in the context of discrete
choice models. Originally developed specifically for Multivariate  Extreme Value models   (called Generalized Extreme Valur, or GEV models, by \cite{McFa78}), it can now handle a wide variety of models. The distribution of BIOGEME, as well as related material, is maintained at
\begin{center}
\texttt{biogeme.epfl.ch}.
\end{center}
The archives of the users group  can be found at
\begin{center}
\texttt{groups.yahoo.com/group/biogeme}
\end{center}

The following pieces of software are available:
\begin{description}
\item[Biogeme] performs maximum likelihood estimation of the parameters of a list of predetermined models: logit, nested logit, cross nested logit, network MEV, binary probit,  ordered logit, and continuous and discrete mixtures of these models. The model description is performed using a simple syntax in a text file. The syntax has been developed using the Bison parser generator. Therefore, we refer sometimes to it as \emph{BisonBiogeme}, as opposed to \emph{PythonBiogeme} presented below. 
\item[Biosim] performs a sample enumeration of an estimated model on a data set. It applies the model to each observation, and compute the utilities as well as the choice probability of each alternative. 
\item[Biomerge] is a simple facility designed to merge files with the
  same number of rows, so that each row is merged with the
  corresponding rows of the other files. It is typically used to merge
  a sample file with a file generated by biosim.  
\item[PythonBiogeme] performs maximum likihood estimation of the
  parameters of any model such that it is possible to write the
  likelihood function. It comes with a list of models already
  implemented, including the logit, the nested logit, the cross nested
  logit, the MEV models, as well as examples about the specification
  of other models. The model description is based on an extension of
  the Python programming language.  PythonBiogeme can exploit multi-threading to speed-up the estimation time in the presence of multiple processors. 
\end{description}
as well as the following utilities 
\begin{description}
\item[histograms] an utility written in Python that takes a list of raw numbers and
  organizes them into bins in order to plot histograms. 
\item[mod2py] a script that runs Biogeme to transform a model written for
  BisonBiogeme (a \texttt{.mod} file) into a model written for
  PythonBiogeme (a \texttt{.py} file). 
\item[Likelihood ratio test] an excel worksheet that performs a
  likelihood ratio test.
\item[CNL correlation] a Matlab code to compute the correlation matrix of a cross-nested logit model given the value of its parameters. 
\item[Variance computation] Excel sheet  to compute the
  variance of the difference and the ratio of two random variables.   
\item[Prepare data] Biogeme requires that the data file contains only
  numerical data. If your data file happens to contain text data (such
  as names of cities, for example), this script written in Python will
  assign a value to each of the strings, generate a data file compliant
  with Biogeme's requirements as well as a glossary explaning which
  number corresponds to which string. 
\end{description}

In addition to this document, several examples are posted online. Make sure to visit the webpage.  If the
document, the examples and and your ``trial-and-errors'' do not help solving problems in
using the software, make sure you visit the archives of the users
group. Several questions have been asked by other users, and the responses are often available in the archives.  If you don't find a solution to your problem, post a message
to\index{Support}
\begin{center}
\texttt{groups.yahoo.com/group/biogeme/post}
\end{center}
  Also, your contribution is very appreciated. If you have suggestions to improve Biogeme, 
  post them to the users group as well.

  Biogeme is developed under the GNU environment
  (\texttt{www.gnu.org}). Therefore, it is easy to install from
  sources on a Linux platform, as well as on a Apple Mac OS X platform
  with Xcode (\texttt{developer.apple.com/xcode/}). Executables for
  Windows are available too. Note that PythonBiogeme running on
  Windows is based on Cygwin (\texttt{www.cygwin.com}), which
  significantly slows down the execution. In principle, BisonBiogeme
  should not suffer from the same limitation and seems to run fine on
  Windows.  In any case, except if you need to run simple examples for
  teaching purposes, we strongly recommend to use Biogeme on Linux or
  Mac OS X.

 Also, a stand alone version of BisonBiogeme with a graphical user
 interface is made available for teaching purposes. It is however
 advised to run the software from a terminal.

Biogeme is distributed free of charge. We ask each user \index{Registration}
\begin{enumerate}
\item  to register to the Biogeme's users group 
\begin{center}
\texttt{groups.yahoo.com/group/biogeme},
\end{center}
and
\item to mention explicitly the use of the package when publishing results, using a reference to this document as well as the following:
\begin{itemize}
\item Bierlaire, M. (2003). BIOGEME: A free package for the estimation of discrete choice models , Proceedings of the 3rd Swiss Transportation Research Conference, Ascona, Switzerland. 
\item Bierlaire, M., and Fetiarison, M. (2009). Estimation of discrete choice models: extending BIOGEME. Proceedings of the 9th Swiss Transport Research Conference, Ascone, Switzerland.
\end{itemize}
\end{enumerate}
If you have any question about \BIOGEME, post them on the users' group.  

\section{Discrete choice models}
\label{sec:models}
\index{Discrete choice models|(}

   This section is not an introduction to discrete choice
   models. Instead, it describes the models that are implemented in
   \BIOGEME. We refer the reader to the abundant literature on the topic,
   including   \citeasnoun{BenALerm85} and \citeasnoun{Trai09}.

  Random utility models are based on the following ingredients:
  \begin{itemize}
  \item a finite population with individuals denoted by $n$, each of them characterized by a vector of socio-economic characteristics $s_n$;
  \item for each individual $n$, a finite choice set $\C_n$ containing $J_n$ alternatives, each of them characterized by a vector of attributes $z_{in}$;
  \item for each individual $n$ and each alternative $i \in \C_n$, a utility function represented by the random variable
\begin{equation}
U_{in} = V_{in} + \varepsilon_{in},
\end{equation}
where $V_{in} = V_{in}(s_n,z_{in};\theta)$ is the deterministic part,
that depends on variables $s_n$ and $z_{in}$, and unknown parameters
$\theta$ to be estimated from data, and $\varepsilon_{in}$ is the
error term, assumed to follow a given distribution, possibly depending
on unknown parameters to be estimated too.
  \end{itemize}

The probability that individual $n$ chooses alternative $i$ within
choice set $\C_n$ is given by
\begin{equation}
P(i|\C_n) =\prob(U_{in} \geq U_{jn} \forall j \in \C_n).
\end{equation}
If $F$ is the CDF of the random variable $\varepsilon_{in}$, the
choice probability is 
\begin{equation}
P(i|\C_n) =\int_{\xi=-\infty}^{+\infty} \frac{\partial F}{\partial \varepsilon_{i}}(\ldots,V_{in}-V_{(i-1)n}+\xi,\xi,V_{in}-V_{(i+1)n}+\xi,\ldots)d\xi.
\end{equation}
In the following, we drop the index $n$ for notational simplicity. 

\subsection{Multivariate Extreme Value models}

   Biogeme has been designed for Multivariate Extreme Value (MEV)
   models (introduced as Generalized Extreme Value models by
   \cite{McFa78}). Given a choice probability generating function
   $G:\R_+^J\to \R$ verifying the following properties 
   \begin{enumerate} 
      \item\label{prop1} $G$ is homogeneous of degree $\mu > 0$, that
        is $G(\alpha y) = \alpha^\mu G(y)$ for each $\alpha \neq 0$,
      \item\label{prop2} $\lim_{y_i \rightarrow +\infty} G(y_1,\ldots,y_i,\ldots,y_J) = +\infty$, for each $i=1,\ldots,J$,
      \item\label{prop3} the $k$\/th partial derivative with respect to $k$ distinct $y_i$ is non-negative if $k$ is odd and non-positive if $k$ is even that is, for any distinct indices $i_1,\ldots, i_k \in \{1,\ldots, J \}$, we have
         \begin{equation}
         (-1)^k \frac{\partial^k G }{\partial x_{i_1}\ldots\partial x_{i_k}}(x) \leq 0, 
         \; \forall x \in \mathbb{R}_+^J.
         \end{equation}
   \end{enumerate}
   The choice probability is then given by
   \begin{equation}
   P(i|C) = \frac{e^{V_i + \ln G_i(e^{V_1},\ldots,e^{V_J})}}{\sum_{j=1}^J e^{V_j + \ln G_j(e^{V_1},\ldots,e^{V_J})}},
   \end{equation}
   where $G_i = \partial G/\partial y_i$.

   

   \BIOGEME\ implements four instances of that family of discrete choice models and through the use 
   of random coefficients, to normal or uniform mixture of each version.
   \begin{enumerate}
      \item the logit model\index{Model!Logit}\index{Logit}. If you are using Biogeme, we safely
         assume that you are  familiar with this model. If not, read
         \citeasnoun{BenALerm85}. The $G$  function is
         \[
         G(y) = \sum_{i=1}^J y_i^\mu,
         \] 
         where $\mu$ is a scale parameter. As it is unidentified, it is
         usually normalized to 1. The choice probability is
\begin{equation}
  \label{eq:BAL5.8}
  P(i|\C) = \frac{e^{\mu V_{i}}}{\sum_{j\in \C} e^{\mu V_{j}}},
\end{equation}

         

      \item the nested logit model\index{Model!Nested logit}\index{Nested logit} (\cite{BenA73}, 
         \cite{Daly87}), where the choice set is partitioned into $M$
         nests, so that each alternative belongs to exactly one nest\footnote{In Biogeme, a nested logit model contains only one level of nests. 
         However, it is possible to handle multiple levels thanks to
         the Network MEV model (see below).}. The $G$ function is
\begin{equation}
\label{eq:mev-nl}
G(y)= \sum_{m=1}^M \left( \sum_{\ell \in \C} (\alpha_{\ell m} y_\ell)^{\mu_m} \right)^{\mu/\mu_m}.
\end{equation}
         where $\alpha_{\ell m}$ is 1 if alternative $i$ belongs to nest
         $m$ and 0 otherwise,   $\mu$ is a scale parameter usually
         normalized to 1, and $\mu_m$ are nested specific parameters verifying 
  $\mu \leq \mu_m$ for all $m$. The choice probability is given by
\[
P(i|\C) =\frac{e^{\mu_m V_{i}}}{\sum_{j\in \C} \alpha_{jm} e^{\mu_m
    V_{jn}}}\frac{ \left( \sum_{\ell\in \C} \alpha_{\ell m}e^{\mu_m
    V_{\ell n}}\right)^{\frac{\mu}{\mu_m}}}{\sum_{p=1}^M\left(
  \sum_{\ell\in \C} \alpha_{\ell p}e^{\mu_p V_{\ell n}}\right)^{\frac{\mu}{\mu_p}}}.
\]


      \item The cross-nested logit model\index{Model!Cross-Nested
        Logit}\index{Cross-Nested Logit} generalized the nested logit
        formulation in allowing the $\alpha$ parameters to take values
        between 0 and 1 in the nested logit formultion, so that an
        alternative can belong to more than one nest, so that complex
        correlation structures can be investigated. 
          We refer the reader to the
         literature for the description of the cross-nested logit model (\cite{Smal87},
         \cite{Vovs97},  \cite{BenABier03}, \cite{Papo04},
         \cite{Bier06-cnl}, \cite{WenKopp01}, \cite{AbbeBierTole07}).

         \begin{equation}
G(y_1,\ldots,y_J) = \sum_{m=1}^M \left(\sum_{j\in \C}({\alpha_{jm}}^{1/\mu}
y_{j})^{\mu_{m}}\right)^\frac{\mu}{\mu_{m}},
         \end{equation}
         with $\mu \leq \mu_m$ for all $m$, and $\alpha_{jm}\geq 0$ for all
         $j$ and $m$. For identification purposes, the constraint
\[
\sum_{m=1}^M \alpha_{jm} = 1 \;\;\; \forall j \in \C
\]
must be imposed (see \cite{WenKopp01} and \cite{AbbeBierTole07}).

      \item the network MEV model\index{Model!Network MEV Model}\index{Network MEV
         Model}. This family of models is equivalent to the Recursive Nested Extreme
         Value Model proposed by \citeasnoun{Daly01}, but based purely on a network
         structure, as proposed by \citeasnoun{Bier02}. We refer the
         reader to \citeasnoun{DalyBier06} for details about this
         model (called ``network GEV'' in the paper, following the
         original naming of \cite{McFa78}). It allows to define a wide class of MEV models
         by designing a network structure, with specific properties, easy to
         verify. The  Logit model, the nested logit model and the
         cross-nested logit model are
         special instances of the network MEV model. In the network, there is a
         parameter associated with each node and with each arc.

         If $i$ is a node corresponding to an alternative,
         \[
          G^i(y_{i}) = y_i^{\mu_i} \;\;\; i=1,\ldots,J,
         \]
         and if not,
         \[
         G^i(y) = \sum_{j \in \text{succ}(i)} \alpha_{ij} G^j(y)^{\frac{\mu_i}{\mu_j}},
         \]
         where $\text{succ}(i)$ denotes the set of successors of $i$,
         $\mu_i > 0$, $\mu_j > 0$, $\mu_i \leq \mu_j$, $\alpha_{ij} \geq 0$, 

   \end{enumerate}

   \subsection{Mixtures}

      \BIOGEME\ allows to include random parameters in the
      specification of a MEV model. Suppose that the choice model is
      based on  a vector of
      fixed parameters $\theta$, and a vector of random parameters $\eta$
      with pdf $f_\eta(\xi;\gamma)$, where $\gamma$ are the parameter
      of the distribution, usually referred to as \emph{deep}
      parameters. The choice probability is then given by
\begin{equation}
\label{eq:mixtures}
P(i|\C;\theta,\gamma) = \int_{\xi} P(i|\C;\theta,\xi)
f_\eta(\xi;\gamma) d\xi, 
\end{equation}
where $P(i|\C;\theta,\xi)$ is a MEV model. The model \req{eq:mixtures}
is called a \emph{mixture} of MEV models. The integral has no closed
form and must be estimated by Monte-Carlo simulation.

 \subsection{Utility function}
  In BisonBiogeme, the population is assumed to be divided into groups, characterized by
  the membership function $s(n)$.  The specification of the utility
  function is 
      \begin{equation}
      \label{eq:Un1}
       U_{n} = \lambda_{s(n)} f(X_{n};\beta_f,\beta_N,\beta_U) + \nu_{n},
      \end{equation}
      where
      \begin{itemize}
         \item $X_{n} \in \mathbb{R}^{J_n \times L}$ is a matrix such that each
            row $j=1,\ldots,J_n$ contains both the attributes $z_{jn}$
            of each alternative $j$
            perceived by individual $n$, and the socio-economic
            characteristics $s_n$ of individual
            $n$,
\item $\beta_f$ is a vector of fixed, real, parameters,
         \item $\beta_N\sim N(\beta_0,\Gamma \Gamma^T)$ is a random vector of dimension $K$, normally
            distributed with mean $\beta_0 \in \mathbb{R}^K$ and variance-covariance matrix
            $\Sigma_\beta = \Gamma \Gamma^T \in \mathbb{R}^{K\times K}$,
        \item $\beta_U$ is a vector of independent uniformly distributed parameters, such that $(\beta_U)_i \sim U(\beta_{ai}-\beta_{bi},\beta_{ai}+\beta_{bi})$.
         \item $f:\mathbb{R}^{J_n \times L} \times \mathbb{R}^K \rightarrow
            \mathbb{R}^J_n$ is a continuously differentiable nonlinear function,
         \item $\lambda_{s(n)}$ is a scale factor associated with the market
            segment $s(n)$, 
         \item $\nu_n$ is a generalized extreme value distributed random
            vector with joint cumulative  distribution function 
            \begin{equation}
            F(\nu_n) = e^{-G_\gamma(e^{-(\nu_{n})_1},\ldots,e^{-(\nu_{n})_{J}} )}
            \end{equation}
            induced by a generating function
              $G_\gamma:\mathbb{R}_+^J\rightarrow\mathbb{R}$ verifying conditions
              \ref{prop1}--\ref{prop3}.
      \end{itemize}
      We  expand the random vector $\beta_N$ as follows:
      \begin{equation}
      \beta_N = \beta_0 + \Gamma \xi,
      \end{equation}
      where $\xi\sim N(0,I)$. 
        Similarly, each uniformly distributed parameter is expanded as follows:
\begin{equation}
(\beta_U)_i = (\beta_a)_i + (\beta_b)_i * \omega_i
\end{equation}
        where $\omega_i \sim U(-1,1)$.

We rewrite \req{eq:Un1} as:
      \begin{equation}
      U_{n} = \lambda_{s(n)} f(X_{n};\beta_f,\beta_0,\Gamma,\beta_a,\beta_b,\xi,\omega) + \nu_{n}.
      \end{equation}
      In the following, we will denote
      \begin{equation}
      \label{eq:vn}
      V_n = \lambda_{s(n)} f(X_{n};\beta_f,\beta_0,\Gamma,\beta_a,\beta_b,\xi,\omega)
      \end{equation}
      and
      \begin{equation}
      \label{eq:vni}
      V_{in} = \lambda_{s(n)} f(X_{n};\beta_f,\beta_0,\Gamma,\beta_a,\beta_b,\xi,\omega)_i
      \end{equation}
      where $f(\cdot)_i$ is the $i$\/th component of $f$.

      The final form of the probability model can be written by first
      deriving the probability model conditional on $\xi$ and $\omega$ (see
      \cite{McFa78}) using the MEV theory.
      \begin{equation}
      \label{eq:proba-gev}
      P(i|\mathcal{C}_n, X_n; \beta_f,\beta_0,\Gamma,\beta_a,\beta_b,\lambda,\gamma;\xi,\omega) = 
      \frac{e^{V_{in} + \log
         G_i(\ldots)}}{\sum_{j\in\mathcal{C}_n} e^{V_{jn}  + \log G_j(\ldots)}},
      \end{equation}
      where $\lambda \in \mathbb{R}^S$ is the vector of scale factors
      associated with market segments,   and
      \begin{equation}
      G_j(\ldots) = \frac{\partial G_\gamma}{\partial y_j}(e^{V_{1n}},\ldots,e^{V_{Jn}}).
      \end{equation}

      We now obtain the probability model by integrating with respect
to $\xi$ and $\omega$, that is $P(i|\mathcal{C}_n, X_n;
\beta_f,\beta_0,\Gamma,\beta_a,\beta_b,\lambda,\gamma) = $
      \begin{equation}
      \label{eq:full-proba}
      \int_{\omega=0}^1 \int_{\xi=-\infty}^{+\infty}
       P(i|\mathcal{C}_n, X_n;
\beta_f,\beta_0,\Gamma,\beta_a,\beta_b,\lambda,\gamma;\xi,\omega)
\phi(\xi;0,I)  \text{d}\xi  \text{d}\omega
       \end{equation}
      where $\phi(\xi;0,I)$ denotes the pdf of the multivariate  normal   density
centered at zero with covariance matrix $I$, evaluated at $\xi$.  If we gather all unknown parameters in a
vector $\theta$, the choice model \req{eq:full-proba} can be written
\begin{equation}
\label{eq:theChoiceModel}
      P(i|\mathcal{C}_n, X_n; \theta)
\end{equation}
        
    The generality of this model provides a great deal of modeling
      flexibility. Not only many models are special cases of this
      formulation, as described below, but new models can be derived in the
      same context. However, if more complex models are required,
      PythonBiogeme has to be used, whih does not assume any model
      structure. The model to be estimated has to be explicitly coded
      in Python language. 

\note{The following mut be moved to the syntax section}
      We now link this formulation with the entries of the model file
      (Section~\ref{sec:spec}). 
      A normally distributed random parameter is mentioned in the definition of the utility
      function using the syntax
      \begin{verbatim}
      BETA [ GAMMA ]
      \end{verbatim}
      For each such random parameter, there must    be two entries in the Section [Beta], one
      corresponding to the entry in $\beta_0$ (\verb+BETA+ in the example above), and the other corresponding
      to the associated diagonal element of $\Gamma$ (\verb+GAMMA+). If
      $\Gamma$ is diagonal, this is sufficient.
      If $\Gamma$ is not diagonal, each non-zero off-diagonal entry must be
      listed in the Section
        [ParameterCovariances]. Each off-diagonal entry is designed to
      capture the covariance between two random parameters. The name of a
      random parameter \verb+BETA [ GAMMA ]+ is by convention
      \verb+BETA_GAMMA+.

      Note that \BIOGEME\ estimates the entries of $\beta_0$ and of
      $\Gamma$. But for most practical applications, the value of $\Gamma$
      is irrelevant, and the values within  $\Gamma \Gamma^T$ are needed.  The
      section \verb+Variance of random coefficients+ in the report files
      reports the entries of the $\Gamma \Gamma^T$ matrix. Note that if
      $\Gamma$ is diagonal, those are simply the square of the estimated
      values reported in the \verb+Utility parameters+ section.

      A uniformly distributed random parameter is mentioned in the definition of the utility
      function using the syntax
      \begin{verbatim}
      BETAA { BETAB }
      \end{verbatim}
      For each such random parameter, there must
      be two entries in the Section [Beta], one
      corresponding to the entry in $\beta_a$ (\verb+BETA+ in the
example above), and the other corresponding to the entry in $\beta_b$(\verb+BETB+ in the
example above).

 \section{Maximum likelihood estimation}

We assume that we have access to a sample of $N$ individuals, such
that for each individual $n$, we have access to the choice set $\C_n$,
the set of variables $X_n$ (containing the socio-economic
characteristics $s_n$ and the attributes of each
alternative $z_{in}$, $i\in\C_n$) as well as one observed choice
$i_n$. Such a sample is usually referred to as \emph{cross-sectional} data.
Given a choice model \req{eq:theChoiceModel}, the likelihood of the
sample is defined as the probability that the model correctly predicts
all observed choices, that is
\begin{equation}
    \mathcal{L}'(\theta)= \prod_{n=1}^N  P(i_n|\mathcal{C}_n, X_n; \theta).
\end{equation}
It is actually more convenient to refer to the log likelihood, that is 
\begin{equation}
\label{eq:logLikelihood}
    \mathcal{L}(\theta)=\log \mathcal{L}'(\theta) =  \sum_{n=1}^N \log P(i_n|\mathcal{C}_n, X_n; \theta).
\end{equation}
The maximum likelihood estimation of the parameters consists in
finding the value of $\theta$ that maximizes
\req{eq:logLikelihood}. The main functionality of \BIOGEME\ is to
solve the optimization problem
\begin{equation}
\max_{\theta}\mathcal{L}(\theta),
\end{equation}
for a given choice model and a given sample file. 

   
   \subsection{Estimation of the  variance-covariance matrix}
   \label{sec:robust}
Under relatively general conditions,  the asymptotic
variance-covariance matrix of the maximum likelihood
estimates is given by the Cramer-Rao bound
\begin{equation}
  \label{eq:RaoCramer}
  -\expect\left[ \nabla^2 \L(\theta)\right]^{-1} =  \left\{-\expect\left[\frac{\partial^2 \L(\theta)}{\partial \theta \partial \theta^T}\right]\right\}^{-1}.
\end{equation}
The term in square brackets is the matrix of the second derivatives
of the log likelihood function with respect to the parameters
evaluated at the true parameters.  Thus the entry in the $k$\/th row and
the $\ell$\/th column is
\begin{equation}
  \label{eq:BAL4.34}
 \frac{\partial^2 \L(\theta)}{\partial \theta_k \partial \theta_{\ell}}.
\end{equation}

From the second order optimality conditions of the optimization problem, this matrix is negative definite if the maximum is unique, which is the algebraic equivalent of the local strict concavity of the log likelihood function. 

Since we do not know the actual values of the parameters at which to
evaluate the second derivatives, or the distribution of $x_{in}$ and
$x_{jn}$ over which to take their expected value, we estimate the
variance-covariance matrix by evaluating the second derivatives  at the estimated parameters
$\hat{\theta}$ and the sample distribution of $x_{in}$ and $x_{jn}$ instead of
 their true distribution. Thus we use
\begin{equation}
  \label{eq:BAL4.35}
  \expect\left[\frac{\partial^2 \L(\theta)}{\partial \theta_k \partial \theta_\ell}  \right]\approx \sum_{n=1}^N \left[\frac{\partial^2\left(y_{in}\ln P_n(i) + y_{jn} \ln P_n(j) \right)}{\partial \theta_k \partial \theta_\ell} \right]_{\theta=\hat{\theta}},
\end{equation}
as a consistent estimator of the matrix of second derivatives. Denote
this matrix as $\hat{A}$. Therefore, an estimate of the Cramer-Rao
bound \req{eq:RaoCramer} is given by 
\begin{equation}
\label{eq:EstimateRaoCramer}
\widehat{\Sigma}^{\text{CR}}_{\theta} = -\hat{A}^{-1}.
\end{equation}
If  the matrix $\hat{A}$ is  negative definite then $-\hat{A}$ is invertible and the Cramer-Rao bound is positive definite. However, this is not guaranteed.  

Another consistent estimator of the (negative of the) second
derivatives matrix can be obtained by the matrix of the cross-products of first derivatives as follows:
\begin{equation}
\label{eq:binaryBHHH}
-E\left[ \frac{\partial^2 \L(\theta)}{\partial \theta \partial \theta^T}\right] \approx  \sum_{n=1}^n \left(\frac{\partial \ell_n(\hat{\theta})}{\partial \theta} \right)\left(\frac{\partial \ell_n(\hat{\theta})}{\partial \theta} \right)^T = \hat{B},
\end{equation}
 where
\begin{equation}
\left(\frac{\partial \ell_n(\hat{\theta})}{\partial \theta} \right) = \frac{\partial}{\partial \theta} (\log P(i_n|\C_n,X_n;\widehat{\theta}))
\end{equation}
is the gradient vector of the likelihood of observation $n$.
This approximation is employed by the BHHH algorithm, from the work by \citeasnoun{BernHallHallHaus74}. Therefore, an estimate of the variance-covariance matrix 
is given by 
\begin{equation}
\widehat{\Sigma}^{\text{BHHH}}_{\theta} =\hat{B}^{-1},
\end{equation}
 although it is rarely used. 
Instead, $\hat{B}$ is
used to derive  a third consistent estimator of the variance-covariance matrix of
the parameters, defined as
\begin{equation}
\label{eq:robustEstimator}
\widehat{\Sigma}^{\text{R}}_{\theta} = (-\hat{A})^{-1} \; \widehat{B}\; (-\hat{A})^{-1} = \widehat{\Sigma}^{\text{CR}}_{\theta} \; (\widehat{\Sigma}^{\text{BHHH}}_{\theta})^{-1} \; \widehat{\Sigma}^{\text{CR}}_{\theta}.
\end{equation}

It is
called the \emph{robust} estimator, or sometimes the \emph{sandwich}
estimator, due to the form of equation
\req{eq:robustEstimator}. \BIOGEME\ reports statistics based on  both the Cramer-Rao estimate
\req{eq:EstimateRaoCramer} and the robust estimate \req{eq:robustEstimator}.


 When the true likelihood function is maximized,  these estimators are
 asymptotically equivalent, and the Cramer-Rao bound should be
preferred (\cite{KaueCarr2001}).  When other consistent estimators are
used, the robust estimator must be used
(\cite{Whit82}). Consistent non-maximum likelihood estimators, known
as pseudo maximum likelihood estimators, are often used when the true
likelihood function is unknown or difficult to compute. In such cases,
it is often possible to obtain consistent estimators by maximizing an
objective function based on a simplified probability distribution. 

\subsection{Panel data}

Sometimes, it is possible to observe individuals over time. We assume that we have access to a sample of $N$ individuals, such
that for each individual $n$ and for each time period $t=1,\ldots,T$, we have access to the choice set $\C_{nt}$,
the set of variables $X_{nt}$ (containing the socio-economic
characteristics $s_n$ and the attributes of each
alternative $z_{int}$, $i\in\C_{nt}$) as well as one observed choice
$i_{nt}$. Such a sample is usually referred to as \emph{panel} data.
In the presence of random parameters in the model, the likelihood
function is slightly different if some of these parameters are
distributed across individuals and not across observations. For the
sake of simplicity here, we assume that all random parameters are
distributed over individuals. In this case, the choice model for an
individual $n$ at time $t$, conditional to the value of $\xi$ and
$\omega$,  is given by \req{eq:proba-gev}
      \[
      P(i|\C_{nt}, X_{nt};
      \beta_f,\beta_0,\Gamma,\beta_a,\beta_b,\lambda,\gamma;\xi,\omega).
\]
Now, for individual $n$, we observe the sequence of choices $i_{n1},
i_{n2},\ldots, i_{nT}$. The likelihood of this sequence, again
conditional to the value of $\xi$ and $\omega$, is given by
\begin{equation}
\prod_{t=1}^T
      P(i_{nt}|\C_{nt}, X_{nt};
      \beta_f,\beta_0,\Gamma,\beta_a,\beta_b,\lambda,\gamma;\xi,\omega).
\end{equation}
We now need to integrate out the random parameters to obtain the
contribution of individual $n$ to the likelihood function:
\begin{equation}
      \int_{\omega=0}^1 \int_{\xi=-\infty}^{+\infty}
\prod_{t=1}^T
      P(i_{nt}|\C_{nt}, X_{nt};
      \beta_f,\beta_0,\Gamma,\beta_a,\beta_b,\lambda,\gamma;\xi,\omega)\phi(\xi;0,I)  \text{d}\xi  \text{d}\omega.
\end{equation}
The log likelihood of the full sample in therefore
\begin{equation}
\L = \sum_{n=1}^N \log       \int_{\omega=0}^1 \int_{\xi=-\infty}^{+\infty}
\prod_{t=1}^T
      P(i_{nt}|\C_{nt}, X_{nt};
      \beta_f,\beta_0,\Gamma,\beta_a,\beta_b,\lambda,\gamma;\xi,\omega)\phi(\xi;0,I)  \text{d}\xi  \text{d}\omega.
\end{equation}

\subsection{Choice based sampling}
\label{sec:selectionBias}

The estimation procedure described above is designed when the sample
has be generated using an exogenous procedure, meaning that the
probability for an individual in the population to be selected in the
sample may depend on the independent (or exogenous) variables $X_n$,
but not on the dependent variable (the choice). For this reason, it is
usually called Exogenous Sample Maximum Likelihood (ESML). If the
sample is choice-based, that is if the probability to be selected in
the sample depends on the choice made, that estimator is not
consistent anymore. 

\citeasnoun{BierBoldMcFa08} have proposed an estimator for
choice-based sample and MEV models. 
It consists in estimating new parameters,
playing a role similar to alternative specific constants, but designed
to absorb the  bias due to choice-based samples.  Ideally, the value
of these parameters should be derived from the sampling
strategy. However, it is possible to estimate them from data, although
it is not necessarily recommended. 


\index{Discrete choice models|)}




\chapter{BisonBiogeme}

BisonBiogeme is the first version of Biogeme. It was first released in
2000, and has been improved permanently ever since. The idea is that
the software provides a large family of choice models that are
pre-implemented. The user has to specify the utility function, and
various additional aspects of the model specification using a simple
modeling language specifically designed for that purpose.

\section{Walkthrough}


In order to introduce the syntax of  BisonBiogeme, we are explaining
in details an example where a logit model with 3 alternatives is
estimated. We use the Swissmetro example (see
\cite{BierAxhaAbay01}). The following files are necessary to run the
example. They are available from \texttt{biogeme.epfl.ch}.
\begin{itemize}
\item The model specification file: \texttt{01logit.mod}
\item The data file: \texttt{swissmetro.dat}
\end{itemize}

\subsection{The model}
The model is a logit model with 3 alternatives. The utility functions are defined as:
{\footnotesize
\begin{verbatim}
V_1 = V_TRAIN =  ASC_TRAIN + B_TIME * TRAIN_TT_SCALED 
                           + B_COST * TRAIN_COST_SCALED
V_2 = V_SM = ASC_SM + B_TIME * SM_TT_SCALED 
                    + B_COST * SM_COST_SCALED
V_3 = V_CAR =  ASC_CAR + B_TIME * CAR_TT_SCALED 
                       + B_COST * CAR_CO_SCALED
\end{verbatim}
}
where 
\verb@TRAIN_TT_SCALED@,
\verb@TRAIN_COST_SCALED@,
\verb@SM_TT_SCALED@,
\verb@SM_COST_SCALED@,
\verb@CAR_TT_SCALED@,
\verb@CAR_CO_SCALED@
are variables, and 
  \verb@ASC_TRAIN@,
  \verb@ASC_SM@,
  \verb@ASC_CAR@,
  \verb@B_TIME@,
  \verb@B_COST@ are parameters to be estimated. Note that it is not possible to identify all alternative specific constants  
  \verb@ASC_TRAIN@,
  \verb@ASC_SM@,
  \verb@ASC_CAR@ from data. Consequently,  \verb@ASC_SM@ is normalized to 0. 

The availability of an alternative \texttt{i} is determined by the
variable \texttt{avi}, \texttt{i}=1,...3, which is equal to 1 if the
alternative is available, 0 otherwise. The probability of choosing an
available alternative \texttt{i} is given by the logit model: 
\begin{equation}
P(i|\C) = \frac{e^{V_i}}{\text{av1} e^{V_1} + \text{av2} e^{V_2}+ \text{av3} e^{V_3}}
\end{equation}
Given a data set of $N$ observations, the loglikelihood of the
sample is 
\begin{equation}
\L = \sum_n \log P(i_n|\C)
\end{equation}
where $i_n$ is the alternative actually chosen
by individual $n$.  

\subsection{The data file}

Biogeme assumes that the data file contains in its first line a list
of labels corresponding to the available data, and that each
subsequent line contains the exact same number of numerical data, each
row corresponding to an observation. Delimiters can be tabs or spaces.

The data file used for this example is \texttt{swissmetro.dat}.

\subsection{The model specification file}
We explain here line by line the model specification file \texttt{01logit.mod}. It is organized into sections. In principle, the order in which the sections appear is irrelevant.

\subsubsection{[ModelDescription]}

This section allows to mention a description of the model that will be
copied in the report file. Each line of the description must be
delimited by double quotes.

{\footnotesize
\begin{verbatim}
[ModelDescription]
"Example of a logit model for a transportation mode choice with 3 alternatives:"
"- Train"
"- Car"
"- Swissmetro, an hypothetical high-speed train"
\end{verbatim}
}

\subsubsection{[Choice]}
It simply describes to Biogeme where the dependent variable (that is, the chosen alternative) can be found in the file. 
{\footnotesize
\begin{verbatim}
[Choice]
CHOICE   
\end{verbatim}
}
  Note that the syntax is case sensitive, and that \texttt{CHOICE} is different from \texttt{choice}, and from \texttt{Choice}. 

\subsubsection{Beta]}

Each parameter to be estimated must be declared in this section. For each parameter, the following must be mentioned:
\begin{enumerate}
\item the name of the parameter
\item the default value
\item a lower bound
\item an upper bound
\item a flag that indicates if the parameter must be estimated (0) or if it keeps its default value (1).
\end{enumerate}

{\footnotesize
\begin{verbatim}
[Beta]
// Name Value  LowerBound UpperBound  status (0=variable, 1=fixed)
ASC_CAR 	0 -10              10              0
ASC_TRAIN  	0 -10              10              0
ASC_SM	        0 -10              10              1
B_TIME		0 -10              10              0
B_COST		0 -10              10              0
\end{verbatim}
}
Note that the fifth entry  for \verb@ASC_SM@ is 1, as we want to keep it  to its default value, that is 0.0.

\subsubsection{[LaTeX]}

Among other  output files, Biogeme generates a file in \LaTeX\ format. In this section, the name of the parameters can be specified in \LaTeX\ syntax, to appear properly in the output file.

{\footnotesize
\begin{verbatim}
[LaTeX]
ASC_CAR "Cte. car"
ASC_SBB "Cte. train"
ASC_SM	"Cte. Swissmetro"
B_TIME	"$\beta_\text{time}$"
B_COST	"$\beta_\text{cost}$"
\end{verbatim}
}

\subsubsection{[Utilities]}

The specification of the
utility functions is described in this section. The specification for one alternative
must start at a new row, and may actually span several rows. 
For each of them, four entries are specified:
\begin{enumerate}
\item The identifier of the alternative, with a numbering convention
  consistent with the section \texttt{[Choice]}.
\item The name of the alternative.
\item The availability condition. In this case, it is a direct
reference to one of the entries  in the data file. The convention is that zero is treated as "false", and one is treated as "true". Actually, any value different from zero is considered as "true".
\item  The linear-in-parameter utility function is composed of a list of terms,
         separated by a \texttt{+}. Each term is composed of the name of a
         parameter and the name of an attribute,
         separated by a \texttt{*}.          Note that a space is
required  after each parameter name.
\end{enumerate}


{\footnotesize
\begin{verbatim}
[Utilities]
// Id Name  Avail  linear-in-parameter expression
    1 A1_TRAIN TRAIN_AV_SP ASC_TRAIN * one 
                            + B_TIME * TRAIN_TT_SCALED 
                            + B_COST * TRAIN_COST_SCALED
    2 A2_SM    SM_AV          ASC_SM * one
                            + B_TIME * SM_TT_SCALED
                            + B_COST * SM_COST_SCALED
    3 A3_Car   CAR_AV_SP     ASC_CAR * one 
                            + B_TIME * CAR_TT_SCALED
                            + B_COST * CAR_CO_SCALED
\end{verbatim}
}

\subsubsection{[Expressions]}
It describes to Biogeme how to
compute attributes not directly available from the data file. 
\begin{itemize}
\item  When boolean variables are involved, the value TRUE is represented by 1, and the value FALSE is represented by 0. Therefore, a multiplication involving a boolean variable is equivalent to a "AND" operator.
{\footnotesize
\begin{verbatim}
CAR_AV_SP =  CAR_AV   * (  SP   !=  0  )
TRAIN_AV_SP =  TRAIN_AV   * (  SP   !=  0  )
SM_COST =  SM_CO   * (  GA   ==  0  ) 
TRAIN_COST =  TRAIN_CO   * (  GA   ==  0  )
\end{verbatim}
}
\item  Variables can be rescaled
{\footnotesize
\begin{verbatim}
TRAIN_TT_SCALED = TRAIN_TT / 100.0
TRAIN_COST_SCALED = TRAIN_COST / 100
SM_TT_SCALED = SM_TT / 100.0
SM_COST_SCALED = SM_COST / 100
CAR_TT_SCALED = CAR_TT / 100
CAR_CO_SCALED = CAR_CO / 100
\end{verbatim}
}

\end{itemize}

\subsubsection{[Exclude]}
It contains a boolean expression that is evaluated for each observation of the data file.  Each observation such that this expression is ``true'' is discarded from the sample. Here, the modeler  has developed the model only for work trips.  
Observations such that the dependent variable CHOICE is 0 are also removed.
{\footnotesize
\begin{verbatim}
(( PURPOSE != 1 ) * (  PURPOSE   !=  3  ) + ( CHOICE == 0 )) 
\end{verbatim}
}

\subsubsection{[Model]}
It tells Biogeme which assumptions must
be used regarding the error term, that is which type of model must be
estimated. In this example, it is the logit model (or MNL, for \emph{multinomial logit}, as it is sometimes called).

{\footnotesize
\begin{verbatim}
[Model]
// $MNL stands for MultiNomial Logit 
$MNL
\end{verbatim}
}

\subsection{Running biogeme}

If Biogeme has been installed properly, the estimation is started with the following statement:
{\footnotesize
\begin{verbatim}
biogeme 01logit swissmetro.dat
\end{verbatim}
}

The following appears on the screen:
\begin{itemize}
\item Information about the version of Biogeme. The date is when the
software was compiled. 

{\footnotesize
\begin{verbatim}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
biogeme 2.4 [Mer 9 jul 2014 15:27:09 CEST]
Michel Bierlaire, EPFL
-- Compiled by michelbierlaire on Darwin
See http://biogeme.epfl.ch
                    !! CFSQP is available !!
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	"In every non-trivial program there is at least one bug."
\end{verbatim}
}
\item Biogeme checks if a file called \texttt{mymodel.par},
containing various parameters, exists. If not, it checks if the file
called \texttt{default.par} exists. If not, it creates it and set
default values to the parameters. That's what most users need in the
beginning. Note that the information like
\texttt{[15:48:50]patFileNames.cc:49} can be safely ignored.
{\footnotesize
\begin{verbatim}
[14:57:01]patFileNames.cc:49  01logit.par does not exist
[14:57:01]patFileNames.cc:53  Trying default.par instead
[14:57:01]patBiogeme.cc:178  File default.par does not exist. Default values will be used
[14:57:01]patBiogeme.cc:180  A file default.par has been created
\end{verbatim}
}
\item  Biogeme then reads the model and data files and reports various information.
{\footnotesize
\begin{verbatim}
 Opening file swissmetro.dat
 Data  file... line 500	Memory: 97 Kb
 Data  file... line 1000	Memory: 184 Kb
 Data  file... line 1500	Memory: 184 Kb
 Data  file... line 2000	Memory: 191 Kb
 Data  file... line 2500	Memory: 289 Kb
 Data  file... line 3000	Memory: 386 Kb
 Data  file... line 3500	Memory: 484 Kb
 Data  file... line 4000	Memory: 503 Kb
 Data  file... line 4500	Memory: 600 Kb
 Data  file... line 5000	Memory: 647 Kb
 Data  file... line 5500	Memory: 745 Kb
 Data  file... line 6000	Memory: 842 Kb
 Data  file... line 6500	Memory: 940 Kb
 Data  file... line 7000	Memory: 1 Mb
 Data  file... line 7500	Memory: 1 Mb
 Data  file... line 8000	Memory: 1 Mb
 Data  file... line 8500	Memory: 1 Mb
 Data  file... line 9000	Memory: 1 Mb
 Data  file... line 9500	Memory: 1 Mb
 Data  file... line 10000	Memory: 1 Mb
 Data  file... line 10500	Memory: 1 Mb
 Total obs.:   10727
 Total memory: 1321.88 Kb
 Run time for data processing: 00:01
\end{verbatim}
}
\item Biogeme then starts the estimation. It displays miscellaneous
information at each iteration of the estimation algorithm.
{\footnotesize
\begin{verbatim}
  Init loglike=-6964.66
     gmax Iter   radius        f(x)     Status       rhok nFree
 +1.44e-03    1 1.00e+00 +6.9646630e+03 ****Converg  +1.05e+00 4  ++
 +1.82e-03    2 2.00e+00 +5.5911931e+03 ****Converg  +9.74e-01 4  ++
 +1.93e-03    3 4.00e+00 +5.3677413e+03 ****Converg  +1.12e+00 4  ++
 +2.04e-03    4 8.00e+00 +5.3424604e+03 ****Converg  +1.52e+00 4  ++
 +1.92e-03    5 1.60e+01 +5.3362826e+03 ****Converg  +1.66e+00 4  ++
 +1.92e-03    6 3.20e+01 +5.3336219e+03 ****Converg  +1.69e+00 4  ++
 +1.97e-03    7 6.40e+01 +5.3324003e+03 ****Converg  +1.69e+00 4  ++
 +2.01e-03    8 1.28e+02 +5.3318102e+03 ****Converg  +1.70e+00 4  ++
 +2.03e-03    9 2.56e+02 +5.3315246e+03 ****Converg  +1.70e+00 4  ++
 +2.03e-03   10 5.12e+02 +5.3313855e+03 ****Converg  +1.70e+00 4  ++
 +1.43e-03   11 1.02e+03 +5.3313175e+03 ****Converg  +1.70e+00 4  ++
 +1.01e-03   12 2.05e+03 +5.3312842e+03 ****Converg  +1.70e+00 4  ++
 +7.11e-04   13 4.10e+03 +5.3312679e+03 ****Converg  +1.70e+00 4  ++
 +5.00e-04   14 8.19e+03 +5.3312598e+03 ****Converg  +1.70e+00 4  ++
 +3.52e-04   15 1.64e+04 +5.3312559e+03 ****Converg  +1.70e+00 4  ++
 +2.47e-04   16 3.28e+04 +5.3312539e+03 ****Converg  +1.70e+00 4  ++
 +1.74e-04   17 6.55e+04 +5.3312529e+03 ****Converg  +1.70e+00 4  ++
 +1.22e-04   18 1.31e+05 +5.3312525e+03 ****Converg  +1.70e+00 4  ++
 +8.58e-05   19 2.62e+05 +5.3312522e+03 ****Converg  +1.70e+00 4  ++
 +6.03e-05   20 5.24e+05 +5.3312521e+03 ****Converg  +1.70e+00 4  ++
 +4.23e-05   21 1.05e+06 +5.3312521e+03 ****Converg  +1.70e+00 4  ++
 +2.97e-05   22 2.10e+06 +5.3312520e+03 ****Converg  +1.70e+00 4  ++
 +2.09e-05   23 4.19e+06 +5.3312520e+03 ****Converg  +1.70e+00 4  ++
 +1.47e-05   24 8.39e+06 +5.3312520e+03 ****Converg  +1.70e+00 4  ++
 +1.03e-05   25 1.68e+07 +5.3312520e+03 ****Converg  +1.70e+00 4  ++
 +7.24e-06   26 3.36e+07 +5.3312520e+03 ****Converg  +1.70e+00 4  ++

 Convergence reached...
--> time interval [14:57:02,14:57:03]
\end{verbatim}
}
\item Biogeme reports the running time and prepares the output files.
{\footnotesize
\begin{verbatim}
Run time: 00:01
 Final log-likelihood=-5331.25
 Be patient... BIOGEME is preparing the output files
--> time interval [14:57:03,14:57:03]
 Run time for var/covar computation: 00:00
\end{verbatim}
}
\item For the record, Biogeme reports the list of files that were actually used as
input.
{\footnotesize
\begin{verbatim}
 BIOGEME Input files
 ===================
 Parameters:			default.par
 Model specification:		01logit.mod
 Sample 1 :				swissmetro.dat
\end{verbatim}
}
\item  Biogeme reports the list of files that have been created,
containing the results of the estimation, as well as many other pieces
of information.

{\footnotesize
\begin{verbatim}
 BIOGEME Output files
 ====================
 Estimation results:		01logit.rep
 Estimation results (HTML):	01logit.html
 Estimation results (Latex):	01logit.tex
 Estimation results (ALogit):	01logit.F12
 Result model spec. file:	01logit.res
 Sample statistics:		01logit.sta
\end{verbatim}
}
\item  Biogeme reports also the name of files that may be helpful in
understanding problems with the model.
{\footnotesize
\begin{verbatim}
 BIOGEME Debug files
 ===================
 Log file:			01logit.log
 Parameters debug:		parameters.out
 Model debug:			model.debug
 Model spec. file debug:	__specFile.debug
\end{verbatim}
}
\item Biogeme reports some information specific to the
model. For logit, it reports the minimum argument of all exponentials
computed during the process, in order to signal a possible
underflow. Most users do not worry about this information.
{\footnotesize
\begin{verbatim}
 Model informations: Multinomial Logit Model
 ==================
 The minimum argument of exp was -18.352

 Run time for estimation:      00:01
 Total run time:               00:02
\end{verbatim}
}

\item For the results, most users will consult the HTML file \texttt{01logit.html} with their
preferred browser.  A file written in ASCII format is also available,
with the extension \texttt{.rep}. A file with \LaTeX\ code is also
created, so that the results can easily be integrated in a report or
an article written with this word processor.</p>
\end{itemize}


\section{Invoking \BIOGEME}

\BIOGEME\  is invoked in a shell under Linux, in a DOS command window or a Cygwin command window 
under Windows using the following statement structure

\begin{center}
\verb+biogeme model_name sample_file_1 sample_file2 sample_file3 ...+
\end{center}

By default, the \verb+sample_file_1+ is assumed to be \verb+sample.dat+, and the 
\verb+model_name+ to be \verb+default+. Therefore, typing
\begin{center}
\verb+biogeme model_name+
\end{center}
is equivalent to typing
\begin{center}
\verb+biogeme model_name sample.dat+
\end{center}
and typing
\begin{center}
\verb+biogeme+
\end{center}
is equivalent to typing
\begin{center}
\verb+biogeme default sample.dat+
\end{center}
Finally, typing
\begin{center}
\verb+biogeme -h+
\end{center}
generates an output looking like

{\footnotesize
\begin{verbatim}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
BIOGEME Version n.x [date]
Michel Bierlaire, EPFL
-- Compiled by Michel Bierlaire on MINGW32_NT-5.1
See http://biogeme.epfl.ch
                    !! CFSQP is available !!
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
        "In every non-trivial program there is at least one bug."

Usage: biogeme model_name sampleFile1 sampleFile2 sampleFile3 ... 
\end{verbatim}
}

If the name of the model is \verb+mymodel+, say, \BIOGEME\ reads the following files:
\begin{itemize}
   \item a file containing the parameters controlling the behavior of \BIOGEME: \texttt{mymodel.par} (Section~\ref{sec:parameter})
   \item a file containing the model specification: \texttt{mymodel.mod}  (Section~\ref{sec:spec}) 
   \item a file containing the data: \texttt{sample.dat}  (Section~\ref{sec:data}) 
   \item optionally a file containing the random numbers to use if estimation is based on simulation.
\end{itemize}

It automatically generates the following output files:
\begin{itemize}
   \item a file reporting the results of the estimation: \texttt{mymodel.rep} (section~\ref{sec:report}), 
   \item the same file in HTML format,
   \item a file containing the main results in \LaTeX\ format: \texttt{mymodel.tex},
   \item a file containing the main results in ALogit format: \texttt{mymodel.F12},
   \item a file containing the specification of the estimated model, in the same format as the model specification file: \texttt{mymodel.res} 
   \item a file containing the specification of the estimated model at each iteration, in the same format as the model specification file: \texttt{mymodel.bck} (only if the parameter \texttt{gevSaveIntermediateResults} is set to one), 
   \item a file containing some descriptive statistics on the data: \texttt{mymodel.sta} (section~\ref{sec:stat}),
\end{itemize}
and the following files to help understanding possible problems
\begin{itemize}
   \item a file containing messages produced by \BIOGEME\ during the run: \texttt{mymodel.log}
   \item a file containing the values of the parameters which have been actually used by \BIOGEME: \texttt{parameters.out}
   \item a file containing the data stored in \BIOGEME\ to represent
the model: \texttt{model.debug}
\index{Debug}
   \item a file containing the specification of the model, as it has actually been understood by \BIOGEME: \texttt{\_\_specFile.debug}
\end{itemize}

These file names may be modified, according to the following rules: 
\begin{enumerate}
   \item If an input file \verb+mymodel.xxx+ does not exist, \BIOGEME\
      attempts to open the file \verb+default.xxx+. If this file does not
      exist, \BIOGEME\ exits with an error. Typically, the parameter file
      is not model-dependent. Therefore, it is common to call it
      \texttt{default.par} to avoid copying it for each different model to
      be estimated.
   \item If an output file \verb+mymodel.xxx+ already exists, \BIOGEME\ does not overwrite it. 
      Instead, it creates the file \verb+mymodel~1.xxx+. If the file \verb+mymodel~1.xxx+ exists, 
      \BIOGEME\  creates the file \verb+mymodel~2.xxx+, and so on.
\end{enumerate}

To avoid any ambiguity, \BIOGEME\ displays the filenames it has actually used for a specific run, 
for instance
{\footnotesize
\begin{verbatim}
BIOGEME Input files
===================
Parameters:                     default.par
Model specification:            mymodel.mod
Sample 1 :                      sample.dat
Sample 2 :                      sample2.dat
BIOGEME Output files
====================
Estimation results:             mymodel~3.rep
Estimation results (HTML):      mymodel~3.html
Estimation results (Latex):     mymodel~5.tex
Estimation results (ALogit):    mymodel~1.F12
Result model spec. file:        mymodel~2.res
Sample statistics:              mymodel~1.sta
BIOGEME Debug files
===================
Log file:                       mymodel.log
Parameters debug:               parameters.out
Model debug:                    model.debug
Model spec. file debug:         __specFile.debug
\end{verbatim}
}

\BIOGEME\ also generates a file called \verb+summary.html+ where a
summary of all runs performed in the working directory are
gathered. The name of this file can be modified (Section~\ref{sec:parameter}).

It is highly recommended to regularly clean the working directory and
save the output files in a different place.

\subsection{Graphical user's interface}

The version of Biogeme with a Graphical user's interface (GUI) is a very simple  interface (see Figures~\vref{fig:gui} and \vref{fig:gui1}) developed with the library Fast Light Toolkit.

The user must select the model specification file and the data file, then click one of the two buttons:
\begin{itemize}
\item \texttt{Estimate} for Biogeme.
\item \texttt{Simulate} for Biosim.
\end{itemize}
If the run completes successfully, the name of the report file is
displayed at the bottom of the screen. It can be viewed by clicking on
the appropriate button.

\begin{figure}[htbf]
\begin{center}
%\epsfig{figure=gui,width=0.8\textwidth}
\caption{\label{fig:gui}Graphical User Interface when \texttt{winbiogeme.exe} is launched}
\end{center}

\end{figure}

\begin{figure}[htbf]
\begin{center}
%\epsfig{figure=gui1,width=0.8\textwidth}
\caption{\label{fig:gui1}Graphical User Interface when the run is finished}
\end{center}

\end{figure}


\section{Parameter file}
\label{sec:parameter}
\index{Parameter file|(}

The parameter file  provides the parameters controlling the
execution of \BIOGEME. It is not mandatory. If it does not exist, \BIOGEME\ uses the default values, and automatically creates a file named \verb+default.par+.
If entries are missing in the file, \BIOGEME\ will use the default values.

The file is divided into sections, each section containing a list of
parameters and their corresponding value.

\begin{description}

  \item[Section [GEV]]

    The five first parameters are the only parameters  which most
    users will ever use. The others are sorted alphabetically. 
   
   \begin{description} 
      \item[\paramitem{gevAlgo}]  It selects the optimization algorithm
         to be used for log-likelihood estimation. As of now,
         \verb+"BIO"+\index{Algorithm!BIO},
         \verb+"BIOMC"+\index{Algorithm!BIOMC},
         \verb+"CFSQP"+\index{Algorithm!CFSQP},
         \verb+"SOLVOPT"+\index{Algorithm!SOLVOPT} and
         \verb+"DONLP2"+\index{Algorithm!DONLP2} are valid entries.  
         The default is \verb+"BIO"+. 
         More details about these algorithms are available at 
         Section~\ref{sec:opt}.

      \item[\paramitem{gevScreenPrintLevel}]\index{Display}\index{Debug} This parameter defines the level of display to be 
         produced on the screen during a run. Valid values are 1 for general messages only, 2 for 
         detailed messages, and 3 for debug messages. Default: 1. 
        
      \item[\paramitem{gevLogFilePrintLevel}]\index{Display}\index{Debug} This parameter defines the level of display to be 
         produced in the log file during a run. Valid values are 1 for general messages only, 2 
         for detailed messages, and 3 for debug messages. Default: 2. 

\item[\paramitem{gevPrintVarCovarAsList}]\index{Variance-covariance} If set to 1, the
  variance-covariance matrix of the estimated parameters is displayed
  as a list (one row per entry). Default: 1.

\item[\paramitem{gevPrintVarCovarAsMatrix}]\index{Variance-covariance} If set to 1, the
  variance-covariance matrix of the estimated parameters is displayed
  as a matrix. We recommend to use this feature only if the number of
  parameters is small (not more than 10). Default: 0.

      \item[\paramitem{gevAutomaticScalingOfLinearUtility}]\index{Variance-covariance} If 1, linear utility functions are automatically scaled to avoid numerical problems during the estimation. The scaling is computed in such a way that all attributes have a level of magnitude of about 1.0. 
         Default value: 0.

        \item[\paramitem{gevBinaryDataFile}] This is the name of the binary data file where the processed data are stored. Default: \texttt{\_\_BiogemeData.bin}.

      \item[\paramitem{gevBufferSize}] \BIOGEME\ reads the first line of the
         data files, and stores it in a buffer to analyze it and extract the
         labels. The size of the buffer is determined by this parameter. The
         default value is 100'000. Adapt the value if the first line of your
         data file contains more that 99'999 characters. BIOGEME
         provides a warning if the default value is exceeded. 
         

      \item[\paramitem{gevCheckDerivatives}]\index{Derivatives}\index{Debug} If set to 1, the analytical
         derivatives of the log-likelihood functions and the nonlinear 
         constraints are compared to the finite difference derivatives. This
         is used basically when a new model is included and for debugging
         purposes. Default value: 0. 
         
      \item[\paramitem{gevDataFileDisplayStep}]\index{Display} While pre-processing the data file before the 
         estimation, \BIOGEME\ reports progress each time it has read a given number of rows.  
         This number is specified by the parameter \verb+getDataFileDisplayStep+, and its default 
         value is 500.

       \item[\paramitem{gevDebugDataFirstRow}]\index{Debug} \BIOGEME\ can print
what it actually reads from the data file. This parameter is the number
of the first row for which his information is displayed. It is
recommended to use it when strange results are generated by the
package. It helps identifying garbage in the data file, such as
strings, for instance.  Default: 0.

   \item[\paramitem{gevDebugDataLastRow}]\index{Debug} \BIOGEME\ can print
what it actually reads from the data file. This parameter is the number
of the last row for which this information is displayed. Default: 0.

\item[\paramitem{gevDecimalDigitsStats}]\index{Format} Number of digits after the decimal points to be used for printing general statistics in the output files. Default: 3.

\item[\paramitem{gevDecimalDigitsTTest}]\index{Format} Number of digits after the decimal points to be used for printing $t$-tests in the output files. Default: 2.

      \item[\paramitem{gevDumpDrawsOnFile}] If set to 1, \BIOGEME\ dumps the draws used for 
         simulated likelihood estimation. The name of the file is displayed at the end of the run. 
         If the model name is \texttt{model}, the filename is \texttt{model.draws}. Default value: 0.

\item[\paramitem{gevForceScientificNotation}]\index{Format} If 1, use the scientific notation for printing results, like in previous versions of Biogeme.  Default: 0.


\item[\paramitem{gevGenerateActualSample}] If set to 1, \BIOGEME\
  generates a copy of the sample file containing only the observations
  that have not been excluded. Default: 0.


\item[\paramitem{gevMinimumMu}] When the homogeneity parameter $\mu$
  of GEV models is estimated, its theoretical lower bound must be
  zero. However, numerically, a value of 0 generates problems during
  the computation of the model. Therefore, the lower bound is
  automatically set to the value defined by this parameter. Default: 1.0e-5.


      \item[\paramitem{gevMaxPrimeNumber}] The generation of Halton sequences is based on prime 
         numbers. This parameter defines the maximum number of prime numbers that can be used. 
         Most users will never have to change the default value. But if it is too low, an error 
         message is generated:
         \begin{center}
            \texttt{Warning:  Error: 23 Halton series must be generated, but there are only 10 
            prime numbers available. Increase the value of gevMaxPrimeNumber in the parameters file}
         \end{center}
         Default value: 1000.

      \item[\paramitem{gevMissingValue}]\index{Missing value}\index{Debug} This parameter is used mainly for
         debugging purposes. It defines the value given to missing values in
         the data file. If one of them is used in the computation of the
         utility functions, an error message is triggered. Default value: 99999.0

\item[\paramitem{gevOutputActualSample}] If parameter
  \verb+gevGenerateActualSample+ is set to 1, this parameter defines
  the name of the file where the sample is saved. Default: \verb+__actualSample.dat+.

\item[\paramitem{gevPrintPValue}]\index{Format} If 1, print the $p$-value in the results. The $p$-value is computed as follows: if $t$ is the $t$-test of the parameters, 
\begin{equation}
p = 2 (1 - \Phi(t)),
\end{equation}
where $\Phi(\cdot)$ is the cumulative density function of the univariate normal distribution.
Default: 1.

      \item[\paramitem{gevRandomDistrib}]\index{Draws} There are three valid entries for this parameter: \newline \verb+PSEUDO+, \verb+MLHS+ and \verb+HALTON+. If \verb+PSEUDO+ is selected, maximum simulated likelihood 
         is based on pseudo-random draws. If \verb+HALTON+ is selected, Halton sequences are generated. If \verb+MLHS+ is selected, a Modified Latin Hypercube Sampling strategy is adopted (see \cite{HessTraiPola05}). 
         Default: \verb+PSEUDO+


\item[\paramitem{gevSaveIntermediateResults}] If 1, the current estimates are saved at each iteration in a file with extension \texttt{.bck}. This is particularly useful for models that take a while to estimate, so that the estimation can be restarted from the last iterate. Default: 0. 


      \item[\paramitem{gevSeed}] It defines the seed value for the
         pseudo-random number generator. Default value: 9021967

\item[\paramitem{gevSignificantDigitsParameters}]\index{Format} Number of significant digits to be used for printing estimated parameters in the output files. Default: 3.

\item[\paramitem{gevSingularValueThreshold}] Identification problems
  are analyzed using a Singular Value Decomposition procedure. If a
  singular value is small (that is, its absolute value is less than
  the value defined by this parameter), the model is considered
  degenerate and the source of this degeneracy is displayed. Default:
  1.0e-4.

      \item[\paramitem{gevStopFileName}]\index{Stop} During the optimization process, \BIOGEME\ checks for the 
         existence of a file, whose name is defined by this parameter. If the file exists, \BIOGEME\ 
         interrupts the iterations and generate output files. This is convenient to prematurely stop 
         iterations without loosing the computations performed thus far. The default value is \verb+"STOP"+.

      \item[\paramitem{gevStoreDataOnFile}] \BIOGEME\ uses a database
         gathering the processed data from the file provided by the user
         and, if applicable, the draws for the simulated maximum likelihood
         estimation. If the parameter is 0, the database is stored in
         memory. If 1, it is stored in the binary file
         defined by the parameter gevBinaryDataFile. It is recommended to use 0, except if
         the data does not fit in  memory. Indeed, accessing to the file
         slows down the estimation process. Default: 0.

      \item[\paramitem{gevSummaryFile}]\index{Summary} Name of the file summarizing
         several runs of \BIOGEME. Default value: \verb+summary.html+

      \item[\paramitem{gevSummaryParameters}]\index{Summary} Name of the file containing
        the name of the parameters whose estimated values must be reported in
        the summary file. Default value: \verb+summary.lis+


  \item[\paramitem{gevVarCovarFromBHHH}] The computation of the
variance-covariance matrix of the estimated parameters using finite difference approximation may
take a while for complex models. It is sometimes useful to use the
BHHH approximation, which is much faster to compute. If so, set this
parameter to 1. It is recommended not to use BHHH in the final
model. Default: 0.

      \item[\paramitem{gevTtestThreshold}] Set the threshold for the $t$-test
         hypothesis tests. If the absolute value of a $t$-test is less than
         \verb+gevTtestThreshold+, a symbol \verb+*+ will be appended to the relevant
         line in the report file (Section~\ref{sec:report}). Default value: 1.96.
         

\item[\paramitem{gevWarningLowDraws}] \BIOGEME\ displays a warning if
  the number of draws for simulated maximum likelihood estimation is
  considered too low. This parameter defines the threshold used in the
  generation of this warning message. Note that it has no effect on
  the estimation itself. Default: 1000. 

      \item[\paramitem{gevWarningSign}] When a $t$-test is not successful, a warning size is 
         displayed in the report file and in the HTML file. This parameter defines the nature 
         of this sign. Default value: \verb+*+.

   \end{description}


   The following are new in \BIOGEME :
\begin{description}
\item[\paramitem{gevNumberOfThreads}] When \BIOGEME\ is compiled to
work with parallel processors, this parameter specifies the number of
threads that will be launched. Note that it may exceed the actual
number of available processors. However, this may affect the
performance by creating unnecessary overhead. It is therefore advised
to set this parameter to the exact number of available processors.
Default: 4.  
\item[\paramitem{gevOne}] Name of the expression that is replaced by
the value 1.0. It can be used in the specification of the utility
without explicitly defining it in the Section
[Expressions]. Default: \texttt{one}.
\item[\paramitem{gevEigenvalueThreshold}] An eigenvalue is considered
to be zero (and the matrix considered to be singular) if its absolute
value is less or equal to the value of this parameter. Default: 1.0e-6.
\end{description}

   The following are new in \BIOSIM :
\begin{description}
\item[\paramitem{gevNonParamPlotRes}] This parameter defines the
number of equally distributed values on the $x$-axis used to generate
nonparametric plots. Default: 100.
\item[\paramitem{gevNonParamPlotMaxY}] When generating nonparametric
plots, values larger that this
parameter are considered equal to the parameter. Symmetrically, values
lower than the negative parameter are considered equal to the negative
value.  Default: 1000.0.
\item[\paramitem{gevNonParamPlotXSizeCm}] Width in centimeters of the
nonparametric plots in the \LaTeX\ output. Default: 15. 
\item[\paramitem{gevNonParamPlotYSizeCm}] Height in centimeters of the
nonparametric plots in the \LaTeX\ output. Default: 10.
\item[\paramitem{gevNonParamPlotMinXSizeCm}] Units on the $x$-axis are computed
automatically for nonparametric plots, but will no be lower than the value
of this parameter. Default: 0.00001.
\item[\paramitem{gevNonParamPlotMinYSizeCm}] Units on the $y$-axis are computed
automatically for nonparametric plots, but will no be lower than the value
of this parameter. Default: 0.00001.
\end{description}



  \item[Section [BasicTrustRegion]]

   This section is designed for the BIO and BIOMC optimization algorithms (see Section~\ref{sec:opt}).
   \begin{description}
      \item[\paramitem{BTRMaxIter}] Maximum number of iterations to be
        performed. Default: 1000.

      \item[\paramitem{BTRTypf}] Typical value of the log-likelihood
         function (see Section~\ref{sec:opt}). Default: 1.0.

      \item[\paramitem{BTRTolerance}] Value used for the stopping criterion
         (see Section~\ref{sec:opt}). Default: 6.05545e-06.

      \item[\paramitem{BTRCheapHessian}] If 1,  BHHH (see
         \cite{BernHallHallHaus74}) is used as an approximation of the
         second derivatives matrix. Default: 1.

      \item[\paramitem{BTRUsePreconditioner}] If 1, the subproblem is
         preconditioned using a modified Cholesky factorization
         (\cite{SchnEsko91}). Default: 0

        \item[\paramitem{BTRInitRadius}] Defines the initial radius of
          the trust region. Default: 1.
        \item[\paramitem{BTRIncreaseTRRadius}] Defines the factor by
          which the trust region is updated. Default: 2. 
\item[\paramitem{BTRMinTRRadius}] Defines the minimum radius of the
  trust region. If this radius is reached, the iterations are
  interrupted. Default: 1.0e-7.

\item[\paramitem{BTRMaxTRRadius}] Defines the maximum radius of the
  trust region. If this radius is reached, the trust region is not
  enlarged anymore. Default: 1.0e10.

        \item[\paramitem{BTRStartDraws}] If BIOMC is used for
          simulated maximum likelihood estimation, this
          parameter defines the number of draws which are used during
          the first iterations. Default: 10.
        \item[\paramitem{BTRIncreaseDraws}] If BIOMC is used for
          simulated maximum likelihood estimation, this
          parameters defines the factor by which  the number of draws
          is increased. Default: 2.
   \end{description}

  \item[Section [cfsqp]]
   This section is designed to define parameters needed by the
   CFSQP\index{Algorithm!CFSQP} algorithm (Section~\ref{sec:opt}).  
   \begin{description}
      \item[\paramitem{cfsqpIprint}] Set it to  1 for silent mode, and to 2 for
         information at each iteration of the optimization algorithm. Default is 1.
      \item[\paramitem{cfsqpMaxIter}] Maximum number of iterations. Default is  500.
      \item[\paramitem{cfsqpMode}] Even if it is a descent algorithm, CFSQP
         sometimes allows non-monotone iterates, hoping not to be trapped in
         local minima. If the function is convex, a descent algorithm is more
         appropriate. In this case, set the value to 100. See CFSQP manual for
         more details. Default is  110.
      \item[\paramitem{cfsqpEps}] See CFSQP manual. Default is  6.05545e-06. In
         general, it should not be changed.
      \item[\paramitem{cfsqpEpsEqn}] See CFSQP manual. Default is  6.05545e-06. In
         general, it should not be changed.
      \item[\paramitem{cfsqpUdelta}] See CFSQP manual. Default is  0.0. In
         general, it should not be changed.
   \end{description}

  \item[Section [solvopt]]
   This section is designed to define parameters needed by the
   SOLVOPT\index{Algorithm!SOLVOPT} algorithm (Section~\ref{sec:opt}).  
   \begin{description}
      \item[\paramitem{solvoptMaxIter}] Maximum number of iterations. Default is 15000.
      \item[\paramitem{solvoptDisplay}]  Controls the display of the
         algorithm. See SOLVOPT manual. Default is 1.
      \item[\paramitem{solvoptErrorArgument}] See SOLVOPT manual. Default is 1.0e-4. In
         general, it should not be changed.
      \item[\paramitem{solvoptErrorFunction}] See SOLVOPT manual. Default is 1.0e-6. In
         general, it should not be changed.
   \end{description}

  \item[Section [donlp2]]
   This section is designed to define parameters needed by the
   DONLP2\index{Algorithm!DONLP2} algorithm (Section~\ref{sec:opt}).  
   \begin{description}
      \item[\paramitem{donlp2Epsx}] See DONLP2 manual. Default is 1.0e-5. In
         general, it should not be changed.
      \item[\paramitem{donlp2Delmin}] See DONLP2 manual. Default is 1.0e-6. In
         general, it should not be changed.
      \item[\paramitem{donlp2Smallw}] See DONLP2 manual. Default is 3.66685e-11. In
         general, it should not be changed.
      \item[\paramitem{donlp2Epsdif}] See DONLP2 manual. Default is 0.0. In general,
         it should not be changed.
      \item[\paramitem{donlp2NReset}] See DONLP2 manual. Default is 9 . In general,
         it should not be changed.
   \end{description}

\end{description}

\begin{table}
\begin{center}
\begin{tabular}{rl}
Name & Value \\
\hline
gevAlgo & BIO \\
gevScreenPrintLevel & 1 \\
gevLogFilePrintLevel & 2 \\
gevPrintVarCovarAsList & 1 \\
gevPrintVarCovarAsMatrix & 0 \\

\hline
gevAutomaticScalingOfLinearUtility & 0 \\
gevBinaryDataFile &\texttt{\_\_BiogemeData.bin} \\
gevBufferSize & 100000 \\ 
gevCheckDerivatives & 0 \\
gevDataFileDisplayStep & 500 \\
gevDebugDataFirstRow & 0 \\
gevDebugDataLastRow & 0 \\
gevDecimalDigitsStats & 3 \\
gevDecimalDigitsTTest & 2 \\
gevDumpDrawsOnFile & 0 \\
gevEigenvalueThreshold & 1.0e-6 \\
gevForceScientificNotation & 0 \\
gevGenerateActualSample & 0 \\
gevMinimumMu & 1.0e-5 \\
gevMaxPrimeNumber & 1000 \\
gevMissingValue & 99999 \\
\end{tabular}
\end{center}
\caption{Default values of the parameters}
\end{table}

\begin{table}
\begin{center}
\begin{tabular}{rl}
Name & Value \\
\hline
gevNonParamPlotMaxY & 1000.0 \\
gevNonParamPlotMinXSizeCm & 0.00001  \\
gevNonParamPlotMinYSizeCm & 0.00001 \\
gevNonParamPlotRes & 100 \\
gevNonParamPlotXSizeCm & 15 \\
gevNonParamPlotYSizeCm & 10  \\
gevNumberOfThreads & 4 \\
gevOne & \texttt{one} \\
gevOutputActualSample & \texttt{\_\_actualSample.dat} \\
gevPrintPValue & 1 \\
gevRandomDistrib & PSEUDO \\
gevSaveIntermediateResults & 0 \\
gevSeed & 9021967 \\
gevSignificantDigitsParameters & 3 \\
gevSingularValueThreshold & 1.0e-4 \\
gevStopFileName & STOP \\
gevStoreDataOnFile & 0  \\
gevSummaryFile & \verb+summary.log+\\
gevSummaryParameters & \verb+summary.lis+ \\
gevVarCovarFromBHHH & 0 \\
gevTtestThreshold & 1.96 \\
gevWarningLowDraws & 1000 \\
gevWarningSign & \verb+*+ \\
\end{tabular}
\end{center}
\caption{Default values of the parameters (ctd)}
\end{table}

\note{Check the status of the comment below.}

It seems that syntax errors in \verb+default.par+ cause \BIOGEME\  to skip
the rest of the file, ignoring all remaining parameters without
complaining. This ``bug'' still has to be fixed. \BIOGEME\  writes in the file
\texttt{parameters.out} the values of the parameters that have been actually used. 
Make sure you check this file regularly.
\index{Parameter file|)}

\section{Model specification file}
\label{sec:spec}
\index{Model specification file|(}

The file \texttt{mymodel.mod} contains the specification of the discrete choice
model to be estimated.
The sections of this file have to be specified as described below.
Note that comments can be included using \verb+//+.\index{Comments} All characters
after this command, up to the end of the current line, are ignored.

\begin{description}

   \item[\specitem{ModelDescription}]
      Type here any text that describes the model. It may contain several lines. Each line must be within double-quotes, like this
{\footnotesize
\begin{verbatim}
[ModelDescription]
"This is the first line of the model description"
"This is the second line of the model description"
\end{verbatim}
}

Note that it will be copied verbatim in the \LaTeX\ file. Therefore, if it contains special characters which are interpreted by \LaTeX , such as \$ or \&, you may need to edit the \LaTeX\ file before processing it.

   \item[\specitem{Choice}] Provide here the formula to compute the identifier of
      the chosen alternative from the data file. Typically, a ``\verb+choice+''
      entry will be available directly in the file, but any formula can be used to
      compute it. 
Assume for example that you have numbered alternatives 100, 200 and 300. But in the data file, they are numbered 1,2 and 3. In this case, you must write 

      \small
{\footnotesize
      \begin{verbatim}
      [Choice]
       100  *  choice  
      \end{verbatim}
}
      \normalsize
 Any expression  described in Section [Expressions] is valid here.

   \item[\specitem{Weight}] Provide here the formula to compute the
      weight associated to each observation. The weight of an observation
      will be multiplied to the corresponding term in the log-likelihood
      function. Ideally, the sum of the weights should be equal to the
      total number of observations, although it is not required. The file
      reporting the statistics contains a recommendation to adjust the
      weights in order to comply with this convention.

\note{Check what happens if biosim is called with weights}
      Important: do not use the weight section in \BIOSIM .

   \item[\specitem{Beta}]
      Each line of this section corresponds to a parameter of the utility
      functions. Five entries must be provided for each parameter:
      \begin{enumerate}
         \item Name: the first character must be a letter (any case) or an underscore
            (\verb+_+), followed by a sequence of letters, digits, underscore (\verb+_+)
            or dashes (\verb+-+), and terminated by a white space. Note that case sensitivity is enforced. 
            Therefore \verb+varname+ and \verb+Varname+ would represent two different variables.
         \item Default value that will be used as a starting point for the estimation, or used directly for the simulation in BIOSIM.
         \item Lower bound on the valid values\footnote{Bounds specification is mandatory in \BIOGEME. If you do not want bounds, just put large negative values for lower bounds and large positive values for upper bounds. Anyway, if the bound is not active at the solution, it does not play any role, except for safeguarding the algorithm.};
         \item Upper bound on the valid values;
         \item Status, which is 0 if the parameter must be estimated, or 1 if the parameter has to be maintained at the given default value. 
      \end{enumerate}
      Note that this section is independent of the specific model to be
      estimated, as it captures the deterministic part of the utility function.

      \small 
{\footnotesize
      \begin{verbatim}
      [Beta]
      // Name  Value      LowerBound  UpperBound status
         ASC1  0          -10000      10000      1
         ASC2  -0.159016  -10000      10000      0
         ASC3  -0.0869287 -10000      10000      0
         ASC4  -0.51122   -10000      10000      0
         ASC5  0.718513   -10000      10000      0
         ASC6  -1.39177   -10000      10000      0
         BETA1 0.778982   -10000      10000      0
         BETA2 0.809772   -10000      10000      0
      \end{verbatim} 
}
      \normalsize

   \item[\specitem{Mu}] $\mu$ is the homogeneity parameter of the MEV
      model. Usually, it is constrained to be one. However, \BIOGEME\  enables to
      estimate it if requested (see example \verb+10nl-bottom.mod+ for a nested logit model normalized from the bottom, so that $\mu$ is estimated). Four entries are specified here:
      \begin{enumerate}
         \item Default value that will be used as a starting point for the estimation (common value: 1.0);
         \item Lower bound on the valid values (common value: 1.0e-5);
         \item Upper bound on the valid values (common value: 1.0);
         \item Status, which is 0 if the parameter must be estimated, or 1 if the parameter 
            has to be maintained at the given value. 
      \end{enumerate}

   \item[\specitem{Utilities}] Each row of this section corresponds to an
      alternative. Four entries are specified:
     \begin{enumerate}
      \item The identifier of the alternative, with a numbering convention
         consistent with the choice definition;
      \item The name of the alternative:  the first character must be a letter (any case) or an 
         underscore (\verb+_+), followed by a sequence of letters, digits, underscore (\verb+_+)
         or dashes (\verb+-+), and terminated by a white space;
      \item The availability condition: this must be a direct reference to an entry
         in the data file (see Section~\ref{sec:data}), or to an expression defined in the
         Section [Expressions];
      \item The linear-in-parameter utility function is composed of a list of terms,
         separated by a \verb-+-. Each term is composed of the name of a
         parameter and the name of an attribute,
         separated by a \verb+*+. The parameter must be listed in
         Section [Beta], if it is a regular parameter. If it
         is a random parameter, the syntax is
{\footnotesize
         \begin{verbatim}
            nameParam [ nameParam ] 
         \end{verbatim}
}
         in the case of the normal distribution, or :
{\footnotesize
         \begin{verbatim}
            nameParam { nameParam }
         \end{verbatim}
}
         to get a random parameter that comes from a uniform distribution.  For example, 
         in the case of the normal:
{\footnotesize
         \begin{verbatim}
            BETA [ SIGMA ] 
         \end{verbatim}
}

         Note that the blank after each name parameter is required. Also,
         parameters \verb+BETA+ and \verb+SIGMA+ have to be listed in
         Section [Beta]. In the context of an independent random parameter, 
         \verb+BETA+ represents the mean while \verb+SIGMA+ corresponds to the standard deviation. 
         With correlated random parameters, \verb+SIGMA+ technically corresponds to the appropriate term 
         in the Cholesky decomposition matrix that captures the variance-covariance structure among 
         the random parameters. For more details, see the technical section on \hyperlink{Cholesky factorization}{Cholesky factorization}
         An attribute must be an entry of the data file,
         or an expression defined in Section [Expressions].
         In order to comply with this syntax, the  Alternative Specific Constants must
         appear in a term like \verb+ASC * one+, where \verb+one+ is defined in the Section [Expressions].
         Here is an example:
         \small 
{\footnotesize
\begin{verbatim}
[Utilities]
// Id Name  Avail  linear-in-parameter expression
  1   Alt1   av1   ASC1 * one + BETA1 [SIGMA] * x11 + BETA2 * x12
  2   Alt2   av2   ASC2 * one + BETA1 [SIGMA] * x21 + BETA2 * x22
  3   Alt3   av3   ASC3 * one + BETA1 [SIGMA] * x31 + BETA2 * x32
  4   Alt4   av4   ASC4 * one + BETA1 [SIGMA] * x41 + BETA2 * x42
  5   Alt5   av5   ASC5 * one + BETA1 [SIGMA] * x51 + BETA2 * x52
  6   Alt6   av6   ASC6 * one + BETA1 [SIGMA] * x61 + BETA2 * x62
\end{verbatim}
}
         \normalsize
         
         If the utility function does not contain any part which is
         linear-in-parameters, then the keyword \verb+$NONE+ must be
         written. For example:
         \footnotesize
{\footnotesize
         \begin{verbatim}
[Utilities]
// Id Name  Avail linear-in-parameter expression
  1   Alt1   av1  $NONE
\end{verbatim}
}
         \normalsize
     \end{enumerate}
  
   \item[\specitem{GeneralizedUtilities}] 
      This section enables the user to add nonlinear terms to the utility
      function. For each alternative, the syntax is simply the identifier of the
      alternative, followed by the expression.  For example, if the utility
      of alternative 1 is 
      \[
      \beta_1 x_{11} + \beta_2 \frac{x_{12}^\lambda-1}{\lambda}, 
      \] 
      the syntax
      is 
      \footnotesize
{\footnotesize
      \begin{verbatim}
      [Utilities]
      1 Alt1 av1 BETA_1 * X11

      [GeneralizedUtilities]
      1 BETA_2 * (X21 ^ LAMBDA - 1) / LAMBDA
      \end{verbatim}
}
      \normalsize
      
      Another example where a non-linear part is required is when specifying a log-normal 
      random coefficient. Consult: \hyperlink{Example LogNormal}{Example LogNormal}. 
      
   \item[\specitem{ParameterCovariances}]
      \BIOGEME\ allows normally distributed random parameters to be correlated, and can estimate
      their covariance. By default, the variance-covariance matrix of the
      random parameters is supposed to be diagonal, and no covariance is
      estimated. If some covariances must be estimated, each pair of correlated 
      random coefficients must be identified in this section. 
      Each entry of the section should contain: 
      \begin{enumerate}
         \item The name of the first random parameter in the given pair. If it appears in the
            utility function as \verb+BETA [ SIGMA ]+, its name must be typed
            \verb+BETA_SIGMA+. 
         \item The name of the second random parameter involved in the pair, using the same naming
            convention. 
         \item The default value that will be used as a starting point for the estimation;
         \item The lower bound on the valid values;
         \item The upper bound on the valid values;
         \item The status, which is 0 if the parameter must be estimated, or 1 if the parameter 
            has to be maintained at the given value. 
      \end{enumerate}
      See Section~\ref{sec:ex-corr} for an example.
      If no covariance is to be estimated, you must either entirely remove
      the section, or specify \verb+$NONE+ as follows:
      \footnotesize
{\footnotesize
      \begin{verbatim}
      [ParameterCovariances]
      $NONE
      \end{verbatim}
}
      \normalsize


   \item[\specitem{Draws}] Number of draws to be used in Maximum Simulated Likelihood estimation. 

   \item[\specitem{Expressions}]
      In this section are defined all expressions appearing either in the
      availability conditions or in the utility functions of the alternatives
      defined in \hyperlink{Utilities}{Section [Utilities]}. If the expression is
      readily available from the data file, it can be omitted in the list. 
      We show their use with the help of an example in Section~\ref{sec:transfdata}. As we 
      will discover later in the tutorial, it is good practice to generate new variables from this 
      section especially when one objective is to compute market shares or to evaluate effects of 
      policies with the help of \BIOSIM.

      We now summarize the syntax that can be used for generating new variables. Variables which form
      an expression might be of type float or of type integer.  You can use numerical values or the name
      of a numerical variable. New variables can be created using unary and binary expression operators.

      Unary expressions:
         \begin{enumerate}
            \item  \verb$y = sqrt(x)        // y is square root of x.$
            \item  \verb$y = log(x)         // y is natural log of x.$
            \item  \verb$y = exp(x)         // y is exponential of x.$
            \item  \verb$y = abs(x)         // y is absolute value of x.$     
         \end{enumerate}

      binary expression:  (Numerical) 
         \begin{enumerate}
            \item  \verb$y = x + z // y is sum of variables x and z$
            \item  \verb$y = x - z // y is difference of variables x and z$
            \item  \verb$y = x * z // y is product of variables x by z$
            \item  \verb$y = x / z // y is division of variable x by z$
            \item  \verb$y = x ^ z // y is x to power of z (square would be y = x ^ 2) $
            \item  \verb$y = x % z // y is x modulo z, i.e. rest of x/z $
         \end{enumerate}

      binary expression:  (Logical) 
         \begin{enumerate}
            \item  \verb$y = x == z     // y is 1 if x equals  z, 0 otherwise$
            \item  \verb$y = x != z     // y is 1 if x not equal to z, 0 otherwise$
            \item  \verb$y = x || z     // y is 1 if x != 0 OR  z != 0, 0 otherwise$
            \item  \verb$y = x && z     // y is 1 if x != 0 AND z != 0, 0 otherwise$
            \item  \verb$y = x < z      // y is 1 if x < z      (note: also > )$
            \item  \verb$y = x <= z     // y is 1 if x <= z     (note: also >= )$
            \item  \verb$y = max(x,z)   // y is max of x and z  (note: also min)$
         \end{enumerate}


      Note that an expression is considered to be TRUE if it is non zero, and FALSE if it is zero. 
      For a full description of these expressions and alternative syntaxes, please
      look at the files \texttt{patSpecParser.y} and \texttt{patSpecScanner.l} in the BIOGEME distribution.

      Loops can be defined if several expressions have almost the same syntax. 
      The idea is to replace all occurrences of a string, say \verb+xx+, by numbers. 
      The numbers are generated within a loop, defined by 3 numbers: the start of the loop (\verb+a+), 
      the end of the loop (\verb+b+) and the step (\verb+c+) with the following syntax:
      \small 
{\footnotesize
      \begin{verbatim}
         $LOOP {xx a b c}
      \end{verbatim} 
}
      \normalsize


      The expression
      \small
{\footnotesize
      \begin{verbatim}
      $LOOP {xx 1 5 2} my_expression_xx = other_expression_xx * term_xx_first
      \end{verbatim}
}
      \normalsize
      is equivalent to 
      \small 
{\footnotesize
      \begin{verbatim}
      my_expression_1 = other_expression_1 * term_1_first
      my_expression_3 = other_expression_3 * term_3_first
      my_expression_5 = other_expression_5 * term_5_first
      \end{verbatim} 
}
      \normalsize

      Warning: make sure that the string is awkward enough so that it cannot match any other instance by mistake. For example, the loop
      \small 
{\footnotesize
      \begin{verbatim}
      {xp 1 5 2} my_expression_xp = other_expression_xp * term_xp_first
      \end{verbatim}
}
      \normalsize
      is equivalent to
      \small
{\footnotesize
      \begin{verbatim}
      my_e1ression_1 = other_e1ression_1 * term_1_first
      my_e3ression_3 = other_e3ression_3 * term_3_first
      my_e5ression_5 = other_e5ression_5 * term_5_first
      \end{verbatim} 
}
      \normalsize
      which is probably not the desired effect.


   \item[\specitem{Group}]
      Provide here the formula to compute  the group ID of the  observed
      individual. Typically, a ``\verb+group+'' entry will be available directly
      from the data file, but
      any formula can be used to compute it.  Any expression
      described in Section [Expressions] is valid here. A
      different \hyperlink{Scale}{scale parameter} will be estimated for the
      utility of each group.
      
   \item[\specitem{Exclude}] Define an expression (see
      Section [Expressions]) which identifies entries of
      the data file to be excluded. If the result of the expression is not
      zero, the entry will be discarded.  

   \item[\specitem{Model}] Specifies which MEV model is to be used. Valid
      entries are \verb+$BP+ for Binary Probit, \verb+$MNL+ for Multinomial Logit model\index{Model!Multinomial
      Logit}\index{Multinomial Logit},
      \verb+$NL+ for single level Nested Logit model\index{Model!Nested Logit}\index{Nested Logit}, 
      \verb+$CNL+ for Cross-Nested Logit model\index{Model!Cross-Nested
      Logit}\index{Cross-Nested Logit} and \verb+$NGEV+ for Network GEV
      model\index{Model!Network GEV Model}\index{Network GEV Model}.
      See Section~\ref{sec:models} for more details.

   \item[\specitem{PanelData}]\index{Panel data} Used to specify the name of the variable (ex: \verb+userID+) in the dataset 
      identifying the observations belonging to a given individual and to specify the 
      name of the random parameters that are invariant within the observation of a given individual 
      \verb+userID+.
See the example at Section~\ref{sec:panel_ex}.


   \item[\specitem{Scale}] A scale parameter is associated with each group. The
      utility function of each member of a group is multiplied by the associated
      scale parameter. A typical application is the joined estimation of revealed
      and stated preferences. It is therefore possible to estimate a MNL combining
      both data sources, without playing around with dummy nested structures as
      proposed by \citeasnoun{BradDaly91}. Each row of this section corresponds to a
      group. Five entries are required per row:
      \begin{enumerate}
         \item Group number: the numbering must be consistent with the
            \hyperlink{Group}{group} definition;
         \item Default value that will be used as a starting point for the estimation
            (1.0 is a good guess);
         \item Lower bound on the valid values;
         \item Upper bound on the valid values;
         \item Status, which is 0 if the parameter must be estimated, or 1 if the parameter has to be maintained at the given value. 
      \end{enumerate}
      Clearly, one of the groups must have a fixed scale parameter. 

     \item[\specitem{SelectionBias}] Identifies the parameters
       capturing the selection bias, using the estimator proposed by \citeasnoun{BierBoldMcFa08}. Each of them has to  be listed in
         Section [Beta]. The section must contain a
         row per alternative for which a selection bias has to be
         estimated. Each row contains the number of the alternative
         and the name of the associated parameter. Note that these parameters play a similar role as the alternative specific constants, and must not be used with MNL. 
{\footnotesize
\begin{verbatim}
[SelectionBias]
1 SB_1
4 SB_4
6 SB_6
\end{verbatim}
}
         
      \item[\specitem{NLNests}] This section is relevant only if the
      \verb+$NL+ option has been selected in \hyperlink{Model}{Section [Model]}. 
     If the model to estimate is not a  Nested Logit model\index{Model!Nested Logit}\index{Nested Logit}, the section will be
      simply ignored. Note that multilevel Nested Logit models must be modeled as Network MEV models.
      Each row of this section corresponds to a nest. Six entries are required per row:
      \begin{enumerate}
         \item Nest name:   the first character must be a letter (any case) or an underscore
            (\verb+_+), followed by a sequence of letters, digits, underscore (\verb+_+)
            or dashes (\verb+-+), and terminated by a white space;
         \item Default value of the nest parameter $\mu_m$ that will be used as a
            starting point for the estimation (1.0 is a good guess);
         \item Lower bound on the valid values. It is usually 1.0, if $\mu$ is
            constrained to be 1.0. Do not forget that, for each nest $i$, the condition
            $\mu_i \geq \mu$ must be verified to be consistent with discrete choice
            theory;
         \item Upper bound on the valid values;
         \item Status, which is 0 if the parameter must be estimated, or 1 if the parameter has to be maintained at the given value. 
         \item The list of alternatives belonging to the nest, numbered as specified in
            \hyperlink{Utilities}{Section [Utilities]}. Make sure that each alternative
            belongs to exactly one nest, as no automatic verification is implemented in \BIOGEME.
      \end{enumerate}

   \item[\specitem{CNLNests}]  This section is relevant only if the
      \verb+$CNL+ option has been selected in \hyperlink{Model}{Section [Model]}. If the model to estimate is not a Cross-Nested Logit model\index{Model!Cross-Nested
      Logit}\index{Cross-Nested Logit}, the section will be
      simply ignored.  Note that multilevel Cross-Nested Logit models must be modeled as Network MEV models.
      Each row of this section corresponds to a nest. Five entries are required per row:
      \begin{enumerate}
         \item Nest name:   the first character must be a letter (any case) or an underscore
            (\verb+_+), followed by a sequence of letters, digits, underscore (\verb+_+)
            or dashes (\verb+-+), and terminated by a white space;
         \item Default value of the nest parameter $\mu_m$ that will be used as a starting point for the estimation;
         \item Lower bound on the valid values. It is usually 1.0, if $\mu$ is
            constrained to be 1.0. Do not forget that, for each nest $i$, the condition
            $\mu_i \geq \mu$ must be verified to be consistent with discrete choice
            theory;
         \item Upper bound on the valid values;
         \item Status, which is 0 if the parameter must be estimated, or 1 if the parameter has to be maintained at the given value. 
      \end{enumerate}

   \item[\specitem{CNLAlpha}]  This section is relevant only if the
      \verb+$CNL+ option has been selected in \hyperlink{Model}{Section [Model]}. If the model to estimate is not a Cross-Nested Logit model\index{Model!Cross-Nested
      Logit}\index{Cross-Nested Logit}, the section will be
      simply ignored. 
      Each row of this section corresponds to a combination of a nest and an alternative. Six entries are required per row:
      \begin{enumerate}
         \item Alternative name, as defined in \hyperlink{Utilities}{Section [Utilities]};
         \item Nest name:   the first character must be a letter (any case) or an underscore
            (\verb+_+), followed by a sequence of letters, digits, underscore (\verb+_+)
            or dashes (\verb+-+), and terminated by a white space;
         \item Default value of the  parameter capturing the level at which an alternative belongs to a nest that will be used as a starting point for the estimation;
         \item Lower bound on the valid values (usually 0.0);
         \item Upper bound on the valid values (usually 1.0);
         \item Status, which is 0 if the parameter must be estimated, or 1 if the parameter has to be maintained at the given value. 
      \end{enumerate}

   \item[\specitem{Ratios}] It is sometimes useful to read the ratio of two
      estimated coefficients. The most typical case is the value-of-time, being the
      ratio of the time coefficient and the cost coefficient. This feature is only implemented for fixed parameters. 
      Computation of ratio of random parameters is not permitted in this version.  Note that it is not 
      straightforward to characterize the distribution of the ratio of two random coefficients.  
      \citeasnoun{BenABoldBrad93} suggest a simple approach that is directly implementable in BIOGEME
      to handle ratio of random parameters.
      Each row in this section enables to specify such ratios to be produced in the output
      file. Three entries are required:
      \begin{enumerate}
         \item The parameter (from Section [Beta]) being the numerator of the ratio;
         \item The parameter (from Section [Beta]) being the denominator of the ratio;
         \item The name of the ratio, to appear in the output file:  the first character must be a letter (any case) or an underscore
            (\verb+_+), followed by a sequence of letters, digits, underscore (\verb+_+)
            or dashes (\verb+-+), and terminated by a white space. 
      \end{enumerate}

   \item[\specitem{ConstraintNestCoef}] Since Version 0.2, it is possible to
      constrain nests parameters to be equal. This is achieved by adding to this section expressions like
      \small 
{\footnotesize
      \begin{verbatim}
         NEST_A = NEST_B
      \end{verbatim} 
}
      \normalsize
      where \verb+NEST_A+ and \verb+NEST_B+ are names of nests defined in \hyperlink{NLNests}{Section [NLNests]}, \hyperlink{CNLNests}{Section [CNLNests]} or  \hyperlink{NetworkGEVNodes}{Section [NetworkGEVNodes]}. This section will become obsolete in future releases, as there is now a section for linear constraints on the parameters: (\hyperlink{LinearConstraints}{Section [LinearConstraints]}).

   \item[\specitem{NetworkGEVNodes}] This section is relevant only if the
      \verb+$NGEV+ option has been selected in \hyperlink{Model}{Section
      [Model]}. If the model to estimate is not a Network GEV model\index{Model!Network GEV Model}\index{Network GEV Model}, the section
      will be simply ignored.  Each row of this section corresponds to a node of the
      Network GEV model.
      All nodes of the
      Network GEV model except the root and the alternatives must be listed here,
      with their associated parameter.
       Five entries are required per row: 
      \begin{enumerate}
         \item Node name:   the first character must be a letter (any case) or an underscore
            (\verb+_+), followed by a sequence of letters, digits, underscore (\verb+_+)
            or dashes (\verb+-+), and terminated by a white space;
         \item Default value of the node parameter $\mu_j$ that will be used as a starting point for the estimation;
         \item Lower bound on the valid values. It is usually 1.0. Check the condition
            on the parameters for the model to be consistent with the theory in \citeasnoun{Bier02};
         \item Upper bound on the valid values;
         \item Status, which is 0 if the parameter must be estimated, or 1 if the parameter has to be maintained at the given value. 
      \end{enumerate}

   \item[\specitem{NetworkGEVLinks}] This section is relevant only if the
      \verb+$NGEV+ option has been selected in \hyperlink{Model}{Section
      [Model]}. If the model to estimate is not a Network GEV model\index{Model!Network GEV Model}\index{Network GEV Model}, the section
      will be simply ignored.  Each row of this section corresponds to a link of the
      Network GEV model, starting from the $a$-node to the $b$-node.
       The root node is denoted by \verb+__ROOT+.
       All other nodes must be either an alternative or a node listed in
       the \hyperlink{NetworkGEVNodes}{section [NetworkGEVNodes]}.
       Note that an alternative cannot be the $a$-node of any link,
       and the root node cannot be the $b$-node of any link.
       Six entries are required per row: 
      \begin{enumerate}
         \item Name of the $a$-node: it must be either \verb+__ROOT+ or  a node listed in
            the \hyperlink{NetworkGEVNodes}{section [NetworkGEVNodes]}.  
         \item Name of the $b$-node: it must be either a node listed in
             the \hyperlink{NetworkGEVNodes}{section [NetworkGEVNodes]}, or the name of an
            alternative.  
         \item Default value of the link parameter that will be used as a starting point for the estimation;
         \item Lower bound on the valid values.
         \item Upper bound on the valid values;
         \item Status, which is 0 if the parameter must be estimated, or 1 if the parameter has to be maintained at the given value. 
      \end{enumerate}


   \item[\specitem{LinearConstraints}]
      In this section, the user can define a list of linear constraints, in one of the following syntaxes:
      \begin{enumerate}
         \item Formula = number,
         \item Formula $\leq$ number,
         \item Formula $\geq$ number.
      \end{enumerate}
      
      The syntax is formally defined as follows:
{\footnotesize
      \begin{verbatim}
      oneConstraint : equation <= numberParam | 
                  equation = numberParam | 
                  equation >= numberParam  
      equation: eqTerm |  
              - eqTerm | 
              equation + eqTerm  | 
              equation - eqTerm 
      eqTerm: parameter | numberParam * parameter 
      \end{verbatim}
}
      
      For example, the constraint
      \[
      \sum_i \text{ASC}_i = 0.0
      \]
      is written
{\footnotesize
      \begin{verbatim}
      ASC1 + ASC2 + ASC3 + ASC4 + ASC5 + ASC6 = 0.0
      \end{verbatim}
}
      and the constraint
      \[
      \mu \leq \mu_j
      \]
      is written 
{\footnotesize
      \begin{verbatim}
      MU - MUJ <= 0.0
      \end{verbatim}
}
      or
{\footnotesize
      \begin{verbatim}
      MUJ - MU >= 0.0
      \end{verbatim}
}

   \item[\specitem{NonLinearEqualityConstraints}]
      In this section, the user can define a list of nonlinear equality constraints of the form 
      \[
      h(x) = 0.0.
      \]
      The section must contain a list of functions $h(x)$. For example, the constraint
      \[
      \alpha_{a1}^{\mu_a} + \alpha_{b1}^{\mu_b} = 1
      \]
      is written
{\footnotesize
      \begin{verbatim}
      [NonLinearEqualityConstraints]
      ALPHA_A1 ^ MU_A  + ALPHA_B1 ^ MU_B - 1.0
      \end{verbatim}
}

   \item[\specitem{NonLinearInequalityConstraints}] 
      \BIOGEME\ is not able to handle nonlinear inequality constraints yet. It should be available in a future version.


\item[\specitem{DiscreteDistributions}] Provide here the list of random parameters with a discrete distribution, or \verb+$NONE+ if there are none in the model. Each discrete parameter is described using the following syntax:
{\footnotesize
\begin{verbatim}
nameDiscreteParam < listOfDiscreteTerms >
\end{verbatim}, 
}
where \verb+nameDiscreteParam+ is the name of the random parameter, and 
  \verb+listOfDiscreteTerms+ is recursively defined as
{\footnotesize
\begin{verbatim}
oneDiscreteTerm |
listOfDiscreteTerms oneDiscreteTerm
\end{verbatim}
}
where \verb+oneDiscreteTerm+ is defined as 
{\footnotesize
\begin{verbatim}
nameValueParam ( nameProbaParam )
\end{verbatim}
}
where \verb+nameValueParam+ is the name of the parameter capturing the discrete value of the random parameter, and \verb+nameProbaParam+ is the name of the parameter capturing the associated probability. Both must be defined in Section [Beta]. As an example,
{\footnotesize
\begin{verbatim}
[DiscreteDistributions]
BETA1 < B1 ( W1 ) B2 ( W2 ) >
\end{verbatim}
}
defines a random parameter \verb+BETA1+, which takes the value \verb+B1+ with probability (or weight) \verb+W1+, and the value \verb+B2+ with probability \verb+W2+. Note that for this to make sense, the constraint \verb-W1 + W2 = 1.0- should be imposed (\hyperlink{LinearConstraints}{Section [LinearConstraints]}). Note also that the parameter \verb+BETA1+ must not appear in Section [Beta].

\item[\specitem{AggregateLast}] Boolean which, for each row in the sample file,   identifies if it is the last observation in an aggregate. Make sure that the value for the last row is nonzero. As all booleans in \BIOGEME, a numerical value of 0 means ``FALSE'' and a numerical value different from 0 means ``TRUE''. See section~\ref{sec:latentChoice} for details.
 Any expression  described in Section [Expressions] is valid here.

\item[\specitem{AggregateWeight}]
Associates a weight to elemental observations of an aggregate. Corresponds to the term $P(\C_\text{obs}|i)$ in Eq. \req{eq:latentChoice}, Section~\ref{sec:latentChoice}. 
 Any expression  described in Section [Expressions] is valid here.
\end{description}

These sections are new in \BIOGEME :
\begin{description}
\item[\specitem{LaTeX}]
This section allows to define a description of each parameter to be used in the \LaTeX\ file. For instance, the following section
{\footnotesize
\begin{verbatim}
[LaTeX]
ASC1   "Constant for alt. 1"
ASC2   "Constant for alt. 2"
ASC3   "Constant for alt. 3"
ASC4   "Constant for alt. 4"
ASC5   "Constant for alt. 5"
ASC6   "Constant for alt. 6"
BETA1  "$\beta_1$"
BETA2  "$\beta_2$"
\end{verbatim}
}
will produce the following table:
\begin{center}
{\small
\begin{tabular}{rlr@{.}lr@{.}lr@{.}lr@{.}l}
         &                       &   \multicolumn{2}{l}{}    & \multicolumn{2}{l}{Robust}  &     \multicolumn{4}{l}{}   \\
Variable &                       &   \multicolumn{2}{l}{Coeff.}      & \multicolumn{2}{l}{Asympt.}  &     \multicolumn{4}{l}{}   \\
number &  Description                     &   \multicolumn{2}{l}{estimate}      & \multicolumn{2}{l}{std. error}  &   \multicolumn{2}{l}{$t$-stat}  &   \multicolumn{2}{l}{$p$-value}   \\

\hline

1 & Constant for alt. 2 & -0&159 & 0&106 & -1&49 & 0&13 \\
2 & Constant for alt. 3 & -0&0869 & 0&111 & -0&78 & 0&43 \\
3 & Constant for alt. 4 & -0&511 & 0&172 & -2&97 & 0&00 \\
4 & Constant for alt. 5 & 0&719 & 0&158 & 4&54 & 0&00 \\
5 & Constant for alt. 6 & -1&39 & 0&195 & -7&12 & 0&00 \\
6 & $\beta_1$ & 0&779 & 0&0301 & 25&85 & 0&00 \\
7 & $\beta_2$ & 0&810 & 0&0307 & 26&42 & 0&00 \\
\hline

\end{tabular}
}
\end{center}

\item[\specitem{Derivatives}]

\textbf{This section is for advanced users only. Use it at your own risk.}

When nonlinear utility functions are used, \BIOGEME\ computes
automatically the derivatives needed by the maximum likelihood
procedure. However, this automatic derivation can significantly slow
down the estimation process, as no simplification is performed. This
section allows the user to provide \BIOGEME\ with the analytical
derivatives of the utility function, in order to speed up the estimation process. In some instances, half the estimation time was spared thanks to this feature.  

A row must be provided for each
combination of nonlinear utilities (defined in the Section
\hyperlink{GeneralizedUtilities}{Section [GeneralizedUtilities]}) and
parameters involved in the formula. Each of these rows contains three
items:
\begin{itemize}
\item the identifier of the alternative,
\item the name of the parameter,
\item the formula of the derivative.
\end{itemize}

For instance, assume that the systematic utility of alternative 1 is 
\[
V_1 = \text{ASC}_1 + \beta_1 \frac{(x_{11} + 10 )^{\lambda_{11}} - 1}{\lambda_{11}} + \beta_2  \frac{(x_{12} + 10 )^{\lambda_{12}} - 1}{\lambda_{12}}
\]
so that
\[
\begin{array}{rcl}
\displaystyle\frac{\partial V_1}{\beta_1} &=&  \displaystyle\frac{(x_{11} + 10 )^{\lambda_{11}} - 1}{\lambda_{11}}\\&&\\
\displaystyle\frac{\partial V_1}{\beta_2} &=&   \displaystyle\frac{(x_{12} + 10 )^{\lambda_{12}} - 1}{\lambda_{12}} \\&&\\
\displaystyle\frac{\partial V_1}{\lambda_{11}} &=&  \displaystyle\beta_1 \frac{(x11 + 10)^{\lambda_{11}} \lambda_{11}   \ln(x_{11} + 10)  
             - (x_{11} + 10)^{\lambda_{11}} + 1}{\lambda^2_{11}} \\
\displaystyle\frac{\partial V_1}{\lambda_{12}} &=&  \displaystyle\beta_2 \frac{(x12 + 10)^{\lambda_{12}} \lambda_{12}   \ln(x_{12} + 10)  
             - (x_{12} + 10)^{\lambda_{12}} + 1}{\lambda^2_{12}}
         \end{array}
\]
which is coded in \BIOGEME\ as follows: 
{\footnotesize \begin{verbatim}
[Utilities]
// Id Name  Avail  linear-in-parameter expression (beta1*x1 + beta2*x2 + ... )
  1   Alt1   av1   ASC1 * one 
  .
  .
[GeneralizedUtilities]
1  BETA1 * ((x11 + 10 ) ^ LAMBDA11 - 1) / LAMBDA11 + 
   BETA2 * ((x12 + 10 ) ^ LAMBDA12 - 1) / LAMBDA12

[Derivatives]
1 BETA1 ((x11 + 10 ) ^ LAMBDA11 - 1) / LAMBDA11
1 BETA2 ((x12 + 10 ) ^ LAMBDA12 - 1) / LAMBDA12
1 LAMBDA11 
      BETA1 * ((x11 + 10) ^ LAMBDA11 * LN(x11 + 10) * LAMBDA11 
             - (x11 + 10) ^ LAMBDA11 + 1) / (LAMBDA11 * LAMBDA11 )
1 LAMBDA12 
      BETA2 * ((x12 + 10) ^ LAMBDA12 * LN(x12 + 10) * LAMBDA12 
             - (x12 + 10) ^ LAMBDA12 + 1) / (LAMBDA12 * LAMBDA12 )
\end{verbatim}
}


In addition to usual  expressions, the formula may contain the following instruction:
{\footnotesize
\begin{verbatim}
$DERIV( formula , param )
\end{verbatim}
}
which means that you ask \BIOGEME\ to perform the derivation of the
formula for you. Although it may be useful to simplify the coding of
the derivatives, it is mandatory to use it for random parameters.

If \verb+BETA [ SIGMA ]+ is a random parameter, its derivative with
respect to \verb+BETA+ is 1, but its derivative with respect to
\verb+SIGMA+ cannot be written by the user, and must be coded

{\footnotesize
\begin{verbatim}
$DERIV( BETA [ SIGMA ] , SIGMA )
\end{verbatim}
}

For instance, assume that the nonlinear utilities are defined as
{\footnotesize \begin{verbatim}
1 exp( BETA1 [ SIGMA1 ] ) * x11
2 exp( BETA1 [ SIGMA1 ] ) * x21
\end{verbatim}
}
The derivatives are coded as follows:
{\footnotesize 
\begin{verbatim}
[Derivatives]
1 BETA1    exp( BETA1 [ SIGMA1 ] ) * x11
1 SIGMA1   exp( BETA1 [ SIGMA1 ] ) * x11 
              * $DERIV( BETA1 [ SIGMA1 ] , SIGMA1 )
2 BETA1    exp( BETA1 [ SIGMA1 ] ) * x21
2 SIGMA1   exp( BETA1 [ SIGMA1 ] ) * x21 
              * $DERIV( BETA1 [ SIGMA1 ] , SIGMA1 )
\end{verbatim}
}

\textbf{It is very easy to do an error in coding the analytical
derivatives. If there is an error, \BIOGEME\ will not be able to
estimate the parameters, and will not even be able to detect that
there is an error. Therefore, we strongly suggest to set the parameter
\texttt{gevCheckDerivatives} to 1 and make
sure that the numerical derivatives match sufficiently well the
analytical derivatives. Also, estimate the model with few observations
and few draws, once with and once without this section. The results
should be exactly the same.}

\item[\specitem{SNP}]\index{Seminonparametric test}\index{Test!seminonparametric} This section allows to implement the test proposed by \citeasnoun{FosgBier07} (read the paper first if you are not familiar with the test). 
The section is composed of two things:
\begin{enumerate}
\item The name of the random parameter to be tested.  If this parameter appears in the
            utility function as \verb+BETA [ SIGMA ]+, its name in this section must be typed  \verb+BETA_SIGMA+. 
\item A list of positive integers associated with a parameter. The integer is the degree of the Legendre polynomial, and the parameter the associated coefficient in the development. Note that the name of the parameter must appear in Section [Beta].
\end{enumerate}

For instance, if parameter \verb+BETA [ SIGMA ]+ is tested using a seminonparametric development defined by
\[
1 + \delta_1 L_1(x) + \delta_3 L_3(x) + \delta_4 L_4(x),
\]
the syntax in \BIOGEME\ is

{\footnotesize 
\begin{verbatim}
[Beta]
// Name  Value LowerBound UpperBound  status (0=variable, 1=fixed)
....
   BETA  0     -10000     10000       0
   SIGMA 1     -10000     10000       0  
   SMP1  0     -10000     10000       0
   SMP3  0     -10000     10000       0
   SMP4  0     -10000     10000       0

[SNP]
// Define the coefficients of the series 
// generated by the Legendre polynomials
BETA_SIGMA
1 SMP1
3 SMP3
4 SMP4
\end{verbatim}
}


Note that only one random parameter can be transformed  at a time. 

\item[\specitem{OrdinalLogit}] The parameters of ordinal binary logit
models (see  Section~\ref{sec:ordinal}) can be estimated. \textbf{However,
this feature has not been fully tested, and should be seen as a
prototype. Thank you for reporting any bug.} The segments of the
utility difference space must be numbered in a sequential  way,
increasing from the leftmost to the rightmost. In this section, each
segment must be associated with its lower bound, except the first
(because its lower bound is $-\infty$). For instance, if there are 4
segments, like in Figure~\vref{fig:ordinalCategories}, the following
syntax is used:  

{\footnotesize 
\begin{verbatim}
[Beta]
....
tau1 0.3 -1000 1000 1
tau2 0.4 -1000 1000 0 
tau3 0.5 -1000 1000 0 

[OrdinalLogit]
1 $NONE    //  -infty --> tau1 
2 tau1     //  tau1   --> tau2
3 tau2     //  tau2   --> tau3
4 tau3     //  tau3   --> +infty

[LinearConstraints]
tau1 - tau2 <= 0
tau2 - tau3 <= 0
\end{verbatim}
}

Note that the constraints impose that the segments are well-defined.
Recall also that the characters \verb+//+ represent a comment in the file and they are not interpreted by \BIOGEME , as well as all remaining characters on the same line. Therefore, the following syntax for that section is completely equivalent:
{\footnotesize 
\begin{verbatim}
[OrdinalLogit]
1 $NONE
2 tau1 
3 tau2 
4 tau3 
\end{verbatim}
}
However, we strongly advise to use comments in order to clearly identify the segments.
   \item[\specitem{SampleEnum}]\index{BIOSIM!Sample
enumeration}\index{Sample enumeration} This section is ignored by BIOGEME. It is
      used by \BIOSIM\ and contains the number of simulations to perform in
      the sample enumeration step (see Section~\ref{sec:biosim}). 

\item[\specitem{ZhengFosgerau}]\index{BIOSIM!ZhengFosgerau}\index{ZhengFosgerau}  This section is ignored by BIOGEME. It is
      used by \BIOSIM\ and contains instructions to perform the
Zheng-Fosgerau specification test and residual analysis. Make sure to
read the paper by \citeasnoun{Fosg08} before using this section.

There is a line for each test, containing four items:
\begin{enumerate}
\item The first item defines the function $t$ introduced by
\citeasnoun{Fosg08} to reduce the dimensionality of the test. It is
typically either the probability of an alternative, or an expression
involving coefficients and attributes of the models, as soon as the
expression is continuous and not discrete. If it is a probability, the
syntax is
{\footnotesize
\begin{verbatim}
$P { AltName }
\end{verbatim}
}
where \verb+AltName+ is the name of the alternative as defined in
\hyperlink{Utilities}{Section [Utilities]}. If it is a general
expression, the syntax is 
{\footnotesize
\begin{verbatim}
$E { expr }
\end{verbatim}
}
where \texttt{expr} is an expression complying with the syntax of
Section [Expressions]. However, it may also
contain estimated parameters. 
\item The second item is a parameter $c$ used to define the bandwidth for the
nonparametric regression performed by the test  (see end of Section
2.1 in \cite{Fosg08}). The bandwidth used by \BIOSIM\ is defined as
$c/\sqrt{n}$, where $n$ is the sample size. Most users will use the
value $c=1$.
\item The third and the fourth item are lower and upper bounds
(resp.) Values of $t$ outside of the bounds will not be used in the
produced pictures. It is good practice to use wide bounds first, and
to adjust them in order to obtain decent pictures.  Note that if $t$
is a probability, it does not make sense to have bounds wider and $[0:1]$.
\item The last item is the name of the function $t$, used in the
report. Make sure to put the name between double-quotes.
\end{enumerate}
Here is an example of the syntax:
{\footnotesize
\begin{verbatim}
[ZhengFosgerau]
$P { Alt1 } 1 0 1 "P1"
$E { x31 } 1 -1000 1000 "x31"  
\end{verbatim}
}
More details are available in Section~\ref{sec:zhengFosgerau}.

\item[\specitem{IIATest}]\index{BIOSIM!IIA test}\index{IIA test}\index{Test!IIA}  This section is ignored by BIOGEME. It is used to compute the variables necessary to perform the McFadden omitted variables test on a subset of alternatives (see Eq. \req{eq:variablesIIAtest}).

The syntax is illustrated by the following example.
{\footnotesize
\begin{verbatim}
[IIATest]
// Description of the choice subsets to compute the new 
// variable for McFadden's IIA test
// Name list_of_alt
C123 1 2 3
C345 3 4 5
\end{verbatim}
}
Each row corresponds to a new variable. It consists in the name of the variable (it will appear as the column header in the output of \BIOSIM ), followed by the list of alternatives to be included in the associated subset. 

\end{description}



\index{Model specification file|)}

\section{Data file}
\label{sec:data}
\index{Data file|(}
   \BIOGEME\ assumes that each data file contains in its first line a
   list of labels corresponding to the available data, and that each
   subsequent line contains the exact same number of numerical data,
   each row corresponding to an observation.  Delimiters can be tabs
   or spaces.  Note that missing values must not be represented by
   dots. Instead, replace them by obviously meaningless values,
   defined by
   \hyperlink{gevMissingValue}{\texttt{gevMissingValue}}. For those
   who have used it, the convention was the same in the HieLoW package
   (see \cite{BierVand95}, \cite{Bier95a}).

   WARNING: if you have created a data file on DOS or Windows, it may
   cause problems. If you work in a Windows environment and want to avoid 
   using Emacs, we recommend using \texttt{TextPad} 
   which is very intuitive to Windows users. Then just make sure you save the file in a 
   UNIX format by selecting the UNIX format in the Save As window. 
   The users working under Linux must convert
   the file with a utility like 
   \texttt{dos2unix},
   available from
   \begin{center}
   \texttt{www.megaloman.com/\~{}hany/software/hd2u},
   \end{center}
   or using Emacs. With GNU Emacs 20.7.1, a (DOS) tag appears at the left
   of the Emacs info bar when the file is edited, indicating that the
   file needs to be converted. Use the menu
   \verb+Mule|Set Coding System|Buffer File+ or type\footnote{In Emacs
     terminology, \texttt{C-x}
    means that you must press the \texttt{Ctrl} key
   and the \texttt{x} key together.}
   \verb+C-x RET f+. Emacs asks you to choose a
   \begin{center}
   \verb+"Coding system for visited file (default, nil)"+.
   \end{center} 
   Choose the
   default by hitting the return key and save the file.


\index{Data file|)}

\section{Data transformation}
\label{sec:transfdata}
\index{Data transformation|(}

   In this section, we use a basic example where the variables x11 to x61 and x12 to x62
   are available on the dataset.  Let us use the syntax available in the \verb+Expression+ section of 
   the input file to create new variables to be used in the model. The following sections of an input file 
   provide an examples of some new variables that can be created using the \verb+Expression+ section.
   If one wishes to use \BIOSIM\ to produce the predicted probabilities in order to perform post 
   estimation analysis, it is a good idea to create new variables in the \hyperlink{Expressions}{[Expressions]} 
   section. Assume that the idea is to see how choice probabilities would vary as the value of x21 is increased, 
   for instance.  To get the right calculation, because x21 is involved in the new variables, 
   the change would correctly disseminate.
   
   {\footnotesize
   \begin{verbatim}
   [Beta]
   // Name Value  LowerBound UpperBound  status (0=variable, 1=fixed)
   ASC1        0         -10000         10000       1
   ASC2        0         -10000         10000       0
   ASC3        0         -10000         10000       0
   ASC4        0         -10000         10000       0
   ASC5        0         -10000         10000       0
   ASC6        0         -10000         10000       0
   BETA1       0         -10000         10000       0
   BETA2       0         -10000         10000       0
   GAMMA1      0         -10000         10000       0
   GAMMA2      0         -10000         10000       0
   [Utilities]
   // Id Name  Avail  linear-in-parameter expression (beta1*x1 + beta2*x2 + ... )
     1   Alt1   av1   ASC1 * one + BETA1 * x11 + BETA2 * x12  
                                 + GAMMA1 * x11sq   + GAMMA2 * dum12
     2   Alt2   av2   ASC2 * one + BETA1 * x21 + BETA2 * x22  
                                 + GAMMA1 * x21sq   + GAMMA2 * dum12
     3   Alt3   av3   ASC3 * one + BETA1 * x31 + BETA2 * x32  
                                 + GAMMA1 * x31sq
     4   Alt4   av4   ASC4 * one + BETA1 * x41 + BETA2 * x42  
                                 + GAMMA1 * x41sq
     5   Alt5   av5   ASC5 * one + BETA1 * x51 + BETA2 * x52  
                                 + GAMMA1 * x51sq
     6   Alt6   av6   ASC6 * one + BETA1 * x61 + BETA2 * x62  
                                 + GAMMA1 * x61sq
   [Expressions] 
   // Define here arithmetic expressions for name that are not directly 
   // available from the data
   one = 1
            // Loop over alternatives 1 to 6 to create the square of xi1
   {zzz 1 6 1}  xzzz1sq = xzzz1 ^ 2

            // Create dum12 = 1 if x11 >= 1 or x21 >= 1, 0 otherwise.
   dum12 = ( x11 >= 1 ) || ( x21 >= 1 )
   \end{verbatim}
  }
\index{Data transformation|)}

\section{Statistics}
\label{sec:stat}
\index{Statistics|(}
   The file containing the statistics of the sample is \texttt{mymodel.sta}
   It contains the following information.

   \begin{enumerate}
      \item The sample size and the sum of all weights are reported. If they don't match, \BIOGEME\ suggests a factor to modify the weights:
         \small
{\footnotesize
         \begin{verbatim}
          --> It is recommended to multiply all weights by 1.45678
         \end{verbatim}
}
         \normalsize
         In that case, you may want to modify the weight definition in the model specification file:
{\footnotesize
         \begin{verbatim}
            [Weight]
             weight *  1.45678
         \end{verbatim}
}
      \item The number of excluded observations, due to the condition defined in
         \hyperlink{Exclude}{Section [Exclude]} of the model specification file, is
         reported.
      \item The total number of observations in the file
      \item The number of cases, which is the number of alternatives
           available to each observation minus the number of observations 
           (see \cite{BenALerm85}, p. 90). 
      \item For each attribute, the mean,
         the minimum and the maximum 
         value across the sample are reported. 
      \item The number of chosen alternatives, both not taking and taking the weight into account.
      \item The group membership,  both not taking and taking the weight into account.
   \end{enumerate}

\index{Statistics|)}

\section{Report file}
\label{sec:report}
\index{Report file|(}
    The report file (\texttt{mymodel.rep}) contains the results of the maximum likelihood estimation of the model. First, general information is reported:
   \begin{itemize}
      \item Type of model which has been estimated.
      \item Sample size.
      \item \verb+Null log-likelihood+ is the log-likelihood of the sample for a Multinomial Logit model where all $\beta$ parameters are 0. It is computed as
         \begin{equation}
            \label{eq:l0}
            \mathcal{L}^0 = \sum_{n \in \text{sample}} \omega_n \ln \frac{1}{\# \mathcal{C}_n}
         \end{equation}
         where $\# \mathcal{C}_n$ is the number of alternatives available to
         individual $n$ and $\omega_n$ is the associated weight.
      \item \verb+Cte log-likelihood+ is the log-likelihood of the
sample for a Multinomial Logit model where the only coefficients are
the alternative specific constants. \textbf{If all alternatives are
always available},  it is computed as
\begin{equation}
\sum_{j \in \C} n_j \ln n_j - n \ln n,
\end{equation}
where $n_j$ is the number of times alternative $j$ has been chosen,
and $n=\sum_{j \in \C} n_j$ is the number of observations in the
sample. Note that if some alternatives are not available for some
observations, the formula is not valid, and the value is not reported. 
      \item \verb+Init log-likelihood+ is the log-likelihood of the sample for the model defined in the \verb+.mod+ file. 
      \item \verb+Final log-likelihood+ is the log-likelihood of the sample for the estimated model. 
      \item \verb+Likelihood ratio test+ is 
         \begin{equation}
            -2 ( \mathcal{L}^0 - \mathcal{L}^*)
         \end{equation}
         where 
         $ \mathcal{L}^0$ is the log-likelihood of the sample for a Multinomial Logit model where all $\beta$ parameters are 0, defined by  \req{eq:l0}, and $\mathcal{L}^*$ is the log-likelihood of the sample for the estimated model. 
      \item \verb+Rho-square+ is
         \begin{equation}
            \rho^2 = 1 - \frac{\mathcal{L}^*}{\mathcal{L}^0}.
         \end{equation}
        \item \verb+Adjusted rho-square+ is
         \begin{equation}
            \rho^2 = 1 - \frac{\mathcal{L}^* - K}{\mathcal{L}^0}.
         \end{equation}
         where $K$ is the number of estimated parameters. Note that this statistic is meaningless in the presence of constraints, where the number of degrees of freedom is less than  the number of parameters. 
      \item \verb+Final gradient norm+ is the gradient of the log-likelihood function computed for the estimated parameters. If no constraint is active at the solution, it should be close to 0. If there are equality constraints, or if some bound constraints or inequality constraints are active at the solution (that is, they are verified with equality), the gradient may not be close to zero. 
\item \verb+Diagnostic+ is the diagnostic reported by the optimization
algorithm. If the algorithm has not converged, the estimation results presented
in the file cannot be used as such. 
\item \verb+Iterations+ is the number of iterations used by the
algorithm before it stopped. 
\item \verb+Run time+ is the actual time used by the algorithm before
it stopped.
   \item \verb+Variance-covariance+ specifies how the second-derivative matrix (inverted to obtain the variance-covariance matrix) has been calculated. If can be either from a finite difference approximation  (which is accurate, but may take time to compute), or from the BHHH matrix (which is less accurate, but faster to compute, see
         \cite{BernHallHallHaus74}). The user selects this option with parameter \hyperlink{gevVarCovarFromBHHH}{\texttt{gevVarCovarFromBHHH}}.
   \end{itemize}

   Then follow results about the parameters.
   \begin{itemize}
      \item The estimated value of the $\beta$ parameters, with the
         associated standard error, the $t$-test and the corresponding $p$-value. A sign (defined by \hyperlink{gevWarningSign}{\texttt{gevWarningSign}}) is
         appended if the $t$-test fails, according to the threshold specified
         by the parameter
         \hyperlink{gevTtestThreshold}{\texttt{gevTtestThreshold}} in
         the parameter file. Similar values obtained from the robust estimation
         of the variance-covariance matrix are also provided (see Section~\ref{sec:robust}).

      \item The estimated value of the $\mu$ parameter, with the associated
         standard error and the $t$-test. A sign (defined by \hyperlink{gevWarningSign}{\texttt{gevWarningSign}}) is appended if the
         $t$-test fails, according to the threshold specified by the parameter
         \hyperlink{gevTtestThreshold}{\texttt{gevTtestThreshold}} in
         the parameter file. Similar values obtained from the robust estimation
         of the variance-covariance matrix are also provided (see Section~\ref{sec:robust}).
      \item The estimated value of the GEV model parameters, with the
          associated standard error and the $t$-test. A sign (defined by \hyperlink{gevWarningSign}{\texttt{gevWarningSign}}) is
         appended if the $t$-test fails, according to the threshold specified
         by the parameter
         \hyperlink{gevTtestThreshold}{\texttt{gevTtestThreshold}} in
         the parameter file. Similar values obtained from the robust estimation
         of the variance-covariance matrix are also provided (see
         Section~\ref{sec:robust}). Note that the
         $t$-test is computed to compare the estimated value both to 0 and 1.
      \item The estimated value of the scale parameters, with the associated
         standard error and the $t$-test. A sign (defined by \hyperlink{gevWarningSign}{\texttt{gevWarningSign}}) is appended if the
         $t$-test fails, according to the threshold specified by the parameter
         \hyperlink{gevTtestThreshold}{\texttt{gevTtestThreshold}} the parameter file. Similar values obtained from the robust estimation
         of the variance-covariance matrix are also provided (see
         Section~\ref{sec:robust}). Note that the
         $t$-test is computed to compare the estimated value to 1.
      \item The ratios requested in \hyperlink{Ratios}{Section [Ratios]} of the model 
         specification file.
      \item A covariance/correlation analysis of pairs of estimated $\beta$
         parameters, sorted according to the $t$-test value.  A sign (defined
         by \hyperlink{gevWarningSign}{\texttt{gevWarningSign}}) is appended
         if the $t$-test fails, according to the threshold specified by the
         parameter \hyperlink{gevTtestThreshold}{\texttt{gevTtestThreshold}}
         in the parameter file. 
      \item When applicable, a report about the singularity of the second derivatives matrix. 
   \end{itemize}
\index{Report file|)}

\section{Summary file}
\index{Summary|(}

   This file is designed to be imported into a spreadsheet, for further
   analysis, results comparisons and presentations. Each line corresponds
   to one run of \BIOGEME\ in the directory. They contain
   \begin{enumerate}
      \item The date and time when the run has terminated;
      \item The name of the model;
      \item The name of the report file;
      \item The final log-likelihood;
      \item The sample size;
      \item The estimated value and $t$-test of the parameters listed in the
         file defined by
         \hyperlink{gevSummaryParameters}{\texttt{gevSummaryParameters}};
      \item The exclusion condition.
   \end{enumerate}

\index{Summary|)}

\section{Other output files}

   \BIOGEME\ also generates files for debugging purposes.\index{Debug}
   \begin{enumerate}
      \item \texttt{parameters.out} This file contains the list of parameters that
         \BIOGEME\ has actually used during the run, and the associated values. Syntax
         errors in the file \texttt{default.par} are usually not detected by
         \BIOGEME. Instead, in the presence of a syntax error, the rest of the file is
         skipped without warning and default values of the parameters are then
         used. This has to be improved in the future. At this point, the file
         \texttt{parameters.out} helps to check if the values actually used by
         \BIOGEME\ are the values that were  set by the user. 
      \item \texttt{model.debug} This file contains debugging information about the
         model specification. A regular user should not need it.
      \item \texttt{mymodel.res}  \specitem{res} This file has exactly the same structure as the
         file \texttt{mymodel.mod}, where the default values of
         the parameters have been replaced by the estimated values. This file is a
         valid model specification file for a future \BIOGEME\ run.  It just needs to be 
         renamed with a .mod extension.
   \end{enumerate}

   When requested (see parameter \hyperlink{gevDumpDrawsOnFile}{\texttt{gevDumpDrawsOnFile}}), 
   the draws are dumped into a file. They are organized as follows:
   for each observation, for each random parameter,  there are $n$ draws
   generated, where $n$ is defined in the \hyperlink{Draws}{Section [Draws]}.
   Those draws are either pseudo-random numbers or Halton sequences,
   depending on the value of \hyperlink{gevRandomDistrib}{\texttt{gevRandomDistrib}}).


\section{Optimization algorithms}
\label{sec:opt}
\index{Optimization algorithms|(}

   \BIOGEME\ can use five different optimization algorithms: CFSQP,
   DONLP2, SOLVOPT, BIO and BIOMC. Note that it is possible that each of them 
   produce different solutions. Usually, the discrepancies are small, and
   due to numerical differences and various stopping criteria. Also, none
   of them identifies a global maximum of the likelihood
   function. Therefore, it may happen that one of them is caught in a
   local maxima, different from local maxima found by other
   algorithms. 

   Which one to choose is difficult to say. They all have advantages and
   disadvantages. BIO (which stands for BIerlaire's Optimization, like in
   BIOGEME) has been specifically adapted for this software
   package, but it cannot accommodate nontrivial constraints yet. A version for simulated maximum likelihood estimation, called BIOMC, is also available. CFSQP is not free and, therefore, not included in the general
   distribution of \BIOGEME. DONLP2 is slower than CFSQP, but faster
   than SOLVOPT.  SOLVOPT can sometimes be very slow. The algorithm is
   not to blame. It has not been originally designed for the kind of
   optimization problem involved in BIOGEME. However, it seems robust on
   ill-specified models. When other algorithms fail to converge, SOLVOPT
   may succeed in finding a solution.  Therefore, our recommendation would be:
   \begin{itemize}
      \item If there are no non-trivial constraint on the parameters, use BIO.
      \item If there are, or if BIO is very slow, use CFSQP if you have it.
      \item If not, use DONLP2.
      \item If all fail, try SOLVOPT.
      \item If it fails again, redefine your model. 
   \end{itemize}
   It is always a good idea to solve the same problem with several
   algorithms.


   \begin{description}
      \item[BIO \index{Algorithm!BIO}] 
         BIO is a trust-region algorithm (see \cite{ConnGoulToin00}) designed
         for problems with simple bounds constraints, using a
         truncated conjugate-gradient method to solve the trust-region
         subproblem. By default, it uses the BHHH (\cite{BernHallHallHaus74})
         matrix as an approximation of the second derivatives matrix.  At each
         iteration, it displays 
         \begin{enumerate}
            \item The value used in the stopping criterion at
               iterate $x$, that
               is the infinite norm of the relative gradient, computed as
               \begin{equation}
             \label{eq:gmax}
               \gamma = \max_{i} \left| \frac{|g_i(x_i)| \max(1,|x_i|) }{\max(f(x),t_f)} \right|
               \end{equation}
               where $g$ is the projection of the gradient of $f$ onto the feasible
               set, $t_f$ is defined by \hyperlink{BTRTypf}{\texttt{BTRTypf}}  
               (see \cite{DennSchn96}).
            \item The iteration number;
            \item The radius of the trust region;
            \item The current value of the objective function\footnote{As it is a
               minimization algorithm, the objective function is the opposite of
               the log-likelihood and, therefore, is a positive value.};
            \item The exit status of the subproblem solver;
            \item The value used to check if the radius of the trust region is
               appropriate, that is 
               \[
               \frac{f(x^+) - f(x_c)}{m(x^+)-m(x_c)}
               \] 
               where $x_c$ is the current iterate, $x^+$ the new candidate, and $m$
               the quadratic model approximating $f$  at $x_c$ (see
               \cite{ConnGoulToin00} for details).
            \item The number of variables not constrained to one of their bounds:
            \item The status of the iteration, that is very successful (++),
               successful (+) or unsuccessful (-).
            \item If the subproblem is preconditioned, a \verb+P+ is also displayed.
         \end{enumerate}
         
       \item[BIOMC \index{Algorithm!BIOMC}] is a version of BIO
         designed for simulated maximum likelihood. The idea is to use
         BIO with few draws in the beginning, in order to obtain a
         rough value of the parameters, and then to increase the
         number of draws until reaching the number required by the
         user ($d_u$). Let $d_k$ be the  number of draws considered by BIOMC
         (where $d_0$ is defined by \hyperlink{BTRStartDraws}{\texttt{BTRStartDraws}}). Then, algorithm BIO runs until the following condition is verified
         \[
            \frac{\ln \gamma}{\ln \varepsilon} \geq \frac{d_k}{d_u},
         \]
         where $\gamma$ is defined by \req{eq:gmax} and $\varepsilon$ is defined by \hyperlink{BTRTolerance}{\texttt{BTRTolerance}}, so that the convergence requirements are not as strong when the number of draws is low. Then, the number of draws is increased
\[
d_{k+1} = \min(\lambda d_k,d_u),
\]
where the factor $\lambda$ is defined by \hyperlink{BTRIncreaseDraws}{\texttt{BTRIncreaseDraws}}, and the process starts again. The algorithm stops when $d_k=d_u$.
         
In general, BIOMC is not faster than BIO. But it allows to obtain good approximations of the parameters pretty quickly.

      \item[CFSQP\index{Algorithm!CFSQP}] CFSQP
         is a C implementation of the FSQP optimization algorithm 
         developed by E.R. Panier, A.L. Tits, J.L. Zhou, and C.T. Lawrence (see
         \cite{LawrZhouTits97}). CFSQP is licensed to
         AEM Design. The conditions for
         external use are the following
         \begin{enumerate}
            \item The CFSQP routines may not be distributed to third parties.
                 Interested parties shall contact AEM Design directly.
            \item If modifications are performed on the routines, these
                 modifications shall be communicated to AEM Design.  The
                 modified routines will remain the sole property of the authors.
            \item Due acknowledgment shall be made of the use of the CFSQP
                 routines in research reports or publications. Whenever
                 such reports are released for public access, a copy shall
                 be forwarded to AEM Design.
            \item The CFSQP routines may only be used for research and
                 development, unless it has been agreed otherwise with AEM
                 Design in writing.
         \end{enumerate}

         If you have a CFSQP license, and need a Windows version of \BIOGEME\ with CFSQP, send
         an Email to \linebreak (\texttt{michel.bierlaire@epfl.ch}) 
         to receive the executable.

      \item[SOLVOPT\index{Algorithm!SOLVOPT}] Solvopt is defined by its authors, Alexei V. Kuntsevich and
         Franz Kappel, as follows: \emph{The program SolvOpt (Solver for local
         optimization problems) is concerned with minimization resp. maximization of
         nonlinear, possibly non-smooth objective functions and with the solution of
         nonlinear programming problems taking into account constraints by the
         so-called method of exact penalization.} The package implements a version of
         minimization method with space dilation by \citeasnoun{Shor85}. See
         \citeasnoun{KuntKapp97} for a tutorial of
         the package and the description of the algorithm.
      \item[DONLP2\index{Algorithm!DONLP2}] DONLP2 is a sequential equality constrained quadratic
         programming method, developed by \citeasnoun{SpelDONLP2}. The algorithm is
         described by \citeasnoun{Spel98a} and \citeasnoun{Spel98}. The conditions of
         use of the DONLP2 package are the following.

         \begin{enumerate}
            \item donlp2 is under the exclusive copyright of P. Spellucci                   
               \begin{center}
                  e-mail:spellucci@mathematik.tu-darmstadt.de
               \end{center}
                ``donlp2" is a reserved name                                               
            \item donlp2 and its constituent parts come with no warranty, whether expressed or 
               implied, that it is free of errors or suitable for any specific purpose.                                                         
               It must not be used to solve any problem, whose incorrect solution        
               could result in injury to a person , institution or property.             
               It is at the users own risk to use donlp2 or parts of it and the          
               author disclaims all liability for such use.                              
            \item donlp2 is distributed ``as is". In particular, no maintenance, support     
               or trouble-shooting or subsequent upgrade is implied.                     
            \item The use of donlp2 must be acknowledged, in any publication which contains 
               results obtained with it or parts of it. Citation of the authors name     
               and netlib-source is suitable.                                            
            \item The free use of donlp2 and parts of it is restricted for research purposes
               commercial uses require permission and licensing from P. Spellucci.       
         \end{enumerate}
     \end{description}
\index{Optimization algorithms|)}


\section{Generating draws}
\index{Draws|(}

All distributions needed by \BIOGEME\ are generated from uniform [0,1]
distributions. The derivation of uniform [-1,1] is obvious. The
derivation of normal $N(0,1)$ is performed using Wichura's method
\cite{Wich88}. 

The uniform [0,1] distributions can be generated in three different
ways. See \cite{Trai09} for more details.
\begin{enumerate}
\item Using Unix's pseudo-random number generator.
\item Using Halton draws.
\item Using the Modified Latin Hypercube Sample procedure proposed by \citeasnoun{HessTraiPola05}.
It generates a small random perturbation of  equally distributed
draws. If $R$ is the number of draws required, it generates a vector
$d(0:R-1)$ such that 
\[
d(i) = \frac{i}{R} + \frac{\xi}{R}
\]
where $\xi$ is a draw from a uniform [0:1] distribution, such that
$\xi \neq 0$ and $\xi \neq 1$.
\end{enumerate}


\index{Draws|)}


\section{Simulation: sample enumeration}
\label{sec:biosim}
\index{BIOSIM!Sample enumeration|(}
\index{Sample enumeration|(}
   The package \BIOSIM\ is invoked exactly like \BIOGEME, with the exact
   same input file. But instead of performing a parameter estimation, it
   performs a sample enumeration.
 Sample enumeration performed by \BIOSIM, produces 
   correct predicted probabilities for all model versions as long as
it is not in a panel data\index{Panel data} setting.  
   The panel data setting requires a  large set of choice probability calculations and this will not be 
   available in \BIOSIM\ in the very near future. 

   The file \texttt{mymodel.enu} contains the result of the sample enumeration.
   For each observation in the sample, the following results are provided:
   \begin{enumerate}
      \item The identifier of the choice actually reported in the sample file;
      \item The name of the choice actually reported in the sample file;
      \item The probability given by the model for  the chosen alternative;
      \item For each alternative, the utility given by the model;
      \item For each alternative, the probability given by the model;
      \item A list of simulated choice, based on Monte-Carlo simulation using the model.
   \end{enumerate}

   The sample enumeration file is extremely useful for producing the
   aggregate market shares computed at convergence. The usual way to
   produce the predicted probabilities is to rename the file that is
   generated at convergence with a \hyperlink{res}{.res} extension
   into a file with a .mod extension. Then replace the word biogeme
   with biosim in the call.  For a model input file called
   \verb+mymodel.mod+ for which we rename the \verb+mymodel.res+ file
   into \verb+mymodel_res.mod+ and given a data base called
   \verb+sample.dat+, the command: 
{\footnotesize
\begin{verbatim} 
biosim mymodel_res  sample.dat 
\end{verbatim} would create an enumeration file called
}
   \verb+mymodel_res.enu+ which would contain among other things the
   choice probabilities of each available alternatives. To produce an
   analysis of the impact of a given policy, change the file
   \verb+mymodel_res.enu+ to reflect the change to a given variable or
   a given set of variable.  This is where using the
   \hyperlink{Expressions}{[Expressions]} section to create variables
   takes all its sense. Applying \BIOSIM\ to this input file would
   create a \verb+.enu+ file that would reflect the new values of the
   choice probabilities following the change. Then, bringing the two
   \verb+.enu+ into an Excel spreadsheet, for example, would allow one
   to measure the change of aggregate shares computed by given market
   segments.

As a final note, the use of weights may be counter-intuitive in
Biosim. If an observation is weighted by $\omega_n$, its
contribution to the log-likelihood in the estimation process would be 
\[
\omega_n \ln P_n(i_n) = \ln P_n(i_n)^{\omega_n}.
\]
As Biosim and Biogeme use the exact same formulation, the use of
weights with Biosim produces the value
\[
P_n(i_n)^{\omega_n},
\]
which may not be the desired effect. 

\index{BIOSIM!Sample enumeration|)}
\index{Sample enumeration|)}
\section{Ordinal logit}
\label{sec:ordinal}
\index{Ordinal logit|(}

An ordinal binary choice model is derived when ordinal responses are
available, where the respondent not only reports the preference, but
also the strength of the preference. For instance, if alternatives $i$
and $j$ are available, the respondent can report one of the following.
\begin{itemize}
\item definitely choose $j$;
\item probably choose $j$;
\item indifferent;
\item probably choose $i$;
\item definitely choose $i$.
\end{itemize}
As for the binary choice model, the selected category is explained by the
difference $U_{in}-U_{jn}$ between the utilities of the two alternatives, as depicted in Figure~\ref{fig:ordinalCategories}.

\begin{figure}[htbf]
  \centering
  \setlength{\unitlength}{1mm}
  \begin{picture}(100,20)
    \put(0,10){\vector(1,0){100}}
    \put(20,9){\line(0,1){6}}
    \put(40,9){\line(0,1){6}}
    \put(50,9){\line(0,1){2}}
    \put(60,9){\line(0,1){6}}
    \put(80,9){\line(0,1){6}}


   \put(50,7){\makebox(0,0)[c]{0}}
   \put(100,7){\makebox(0,0)[c]{$U_{in}-U_{jn}$}}
    \put(20,6){\makebox(0,0)[c]{$\tau_1$}}
    \put(40,6){\makebox(0,0)[c]{$\tau_2$}}
    \put(60,6){\makebox(0,0)[c]{$\tau_3$}}
    \put(80,6){\makebox(0,0)[c]{$\tau_4$}}
    \put(10,16){\makebox(0,0)[c]{Def. $j$}}
    \put(30,16){\makebox(0,0)[c]{Prob. $j$}}
    \put(50,16){\makebox(0,0)[c]{Indiff.}}
    \put(70,16){\makebox(0,0)[c]{Prob. $i$}}
    \put(90,16){\makebox(0,0)[c]{Def. $i$}}
  \end{picture}\caption{Categories for the ordinal binary choice model}
  \label{fig:ordinalCategories}
\end{figure}

Formally, we consider $Q \geq 2$ categories, ordered such that category $q$
corresponds to a stronger preference towards alternative $i$ compared
to category $q-1$, for $q=1,\ldots,Q$.
We define $Q+1$ parameters
$\tau_q$, $q=0,\ldots,Q$, such that $\tau_0 = -\infty$,
$\tau_Q=+\infty$, and $\tau_{q-1} \leq \tau_q$, $q=1,\ldots,Q$. A
category $q$ is associated with the interval $[\tau_{q-1},\tau_q]$.
The probability for  category $q$ to be selected by the respondent is
\begin{equation}
\begin{array}{rcl}
P_n(q) &=& \prob(\tau_{q-1} \leq U_{in} - U_{jn} \leq  \tau_q) \\
       &=& \prob(\tau_{q-1} \leq (V_{in} - V_{jn}) - (\varepsilon_{jn} - \varepsilon_{in}) \leq \tau_q) \\
       &=& \prob(V_{in} - V_{jn} - \tau_q \leq \varepsilon_n \leq V_{in} - V_{jn} -\tau_{q-1}) \\
       &=& F_{\varepsilon_n}(V_{in} - V_{jn} -\tau_{q-1}) - F_{\varepsilon_n}(V_{in} - V_{jn} - \tau_q)
\end{array}
\end{equation}
where $\varepsilon_n=\varepsilon_{jn} - \varepsilon_{in}$, and $ F_{\varepsilon_n}$ is the CDF of $\varepsilon_n$.
By definition of the CDF, the probability for the extreme categories simplify to
\begin{equation}
\begin{array}{rcrcl}
P_n(1) &=&  F_{\varepsilon_n}(V_{in} - V_{jn} + \infty) &-& F_{\varepsilon_n}(V_{in} - V_{jn} - \tau_1 ) \\ &=& 1 &-& F_{\varepsilon_n}(V_{in} - V_{jn} - \tau_1 ), \\
P_n(Q) &=&  F_{\varepsilon_n}(V_{in} - V_{jn} -\tau_{Q-1}) &-& F_{\varepsilon_n}(V_{in} - V_{jn} - \infty)\\& =& F_{\varepsilon_n}(V_{in} - V_{jn} -\tau_{Q-1}). &&
\end{array}
\end{equation}

In particular, if $\varepsilon_n$ is logistically distributed, we obtain the \emph{ordinal logit} model. 
We immediately note that binary choice models are specific instances
of ordinal binary choice models, with two categories ($Q=2$), and $\tau_1=0$.

The parameter $\tau$ can be estimated by \BIOGEME\ using \hyperlink{OrdinalLogit}{Section [OrdinalLogit]}

\subsection*{Example}

The file \texttt{23ordinalLogit.mod} contains an example of such a model, using 4 intervals (and, therefore, three thresholds $\tau_1$, $\tau_2$ and $\tau_3$). In order to comply with the general syntax of \BIOGEME, the following conventions are used:
\begin{itemize}
\item the model must contain exactly two alternatives;
\item the identifier of the alternative is completely ignored;
\item alternative $i$ is the first by alphabetical order, and alternative $j$ is the second.
\end{itemize}
To illustrate this last point, the example is designed with a xonfusing numbering. ``\texttt{Alt2}'' is first if we rank the alternatives using the IDs, and second if we rank them by alphabetical order. As the IDs are ignored, the model is based on \texttt{Alt1 - Alt2}, so that
\begin{itemize}
\item $V_{in}$ = \texttt{ASC1 * one + BETA1 * x11 + BETA2 * x12},
\item $V_{jn}$ = \texttt{ASC2 * one + BETA1 * x21 + BETA2 * x22}.
\end{itemize}

In order to remove any ambiguity, the exact formula used by the model (that is, the difference of the two utilities)  is reported in the output file.

Note that if all the threshold parameters are estimated, all constants must be normalized to 0 (see the example). 



\index{Ordinal logit|)}

\section{Latent choice}
\label{sec:latentChoice}
\index{Latent choice|(}
A choice is said to be ``latent'' when it is not directly observed.
This idea has been proposed by \citeasnoun{BierFrej07} in a route
choice context where the actual chosen route was not directly
observed. Instead, the respondent reported a sequence of locations
that they traversed. In many cases, several  routes in the
network may have produced the same reported locations. 

Each observation consists of an aggregate, a set of actual
alternatives that may correspond to the observed situations.  If $\C_\text{obs}$ is the observed aggregate, than the
probability given by the choice model is
\begin{equation}
\label{eq:latentChoice}
P(\C_\text{obs}) = \sum_{i\in \C} P(\C_\text{obs}|i) P(i | \C).
\end{equation}

Equation $P(\C_\text{obs}|i)$ can be viewed as a measurement equation,
and represents the probability to observe $\C_\text{obs}$ if $i$ was
the actual choice. 

In \BIOGEME , an aggregate observation is represented by a consecutive
sequence of elemental observations, associated with the probability
$P(\C_\text{obs}|i)$.
Two additional sections in the model specification file are used for the specification: \hyperlink{AggregateLast}{section [AggregateLast]} defines a boolean with is true if the corresponding row is the last elemental observation of the current aggregate, and false otherwise. \hyperlink{AggregateWeight}{section [AggregateWeight]} defines the value of $P(\C_\text{obs}|i)$.
\index{Latent choice|)}

\section{The Zheng Fosgerau test}
\label{sec:zhengFosgerau}
\index{BIOSIM!ZhengFosgerau|(}
\index{ZhengFosgerau|(}

\BIOSIM\ can compute the Zheng-Fosgerau test. Proposed by
\citeasnoun{Zhen96}, it has been adapted to discrete choice models by
\citeasnoun{Fosg08}. In addition to the value of the test itself,
\BIOSIM\ reports pictures allowing to perform residual analysis. 

We consider here the example in the file
\verb+24ZhengFosgerau.mod+. Note that this is not a genuine model. Our
objective here is to illustrate the tool. In this file, 3 tests are
proposed, with 3 definitions for the function $t$ introduced by
\citeasnoun{Fosg08}. We consider the second one, which is exactly the
expression of the utility function of alternative 2. The syntax is 
{\footnotesize
\begin{verbatim}
 $E { ASC2 * one + BETA1 * x21 + BETA2 * x22 } 1 -1000 1000 "Util2" 
\end{verbatim}
}
\BIOSIM\ first generates a plot to show how $t$ (i.e. the utility of
alternative 2 in this case) is distributed in the
sample. This plots appears in the file
\texttt{24ZhengFosgerau\_zheng.tex}, which must be processed with the
\LaTeX\footnote{\LaTeX\ is distributed freely on internet. Note that the package \texttt{pstricks} is required to produce the plots.} word processor. The density function is estimated using nonparametric
regression. As we can see on Figure~\ref{fig:1_proba}, the shape is
not too different from a normal distribution, with very few values of
this expression are out
of the range $[-10:10]$.

\begin{figure}
\begin{center}
%\epsfig{figure=densityUtil2,width=\textwidth}
\caption{\label{fig:1_proba}Density of Util2 = ( (  ASC2   *  one   ) + (  BETA1   *  x21   ) ) + (  BETA2   *  x22   )}
\end{center}
 \end{figure}


\BIOSIM\ also generates plots of the residuals, that is the difference
$(y_{in}-P_n(i))$, where $y_{in}$ is 1 if individual $n$ has chosen alternative
$i$ in the sample, and 0 otherwise, and $P_n(i)$ is the probability as
computed by the model. In principle, the residuals should be a white
noise unrelated to the independent variables. Figure~\ref{fig:1_1}
plots a nonparametric estimation of the residuals for alternative 2 as a function of $t$, that is
the utility of alternative 2 in this case.  Clearly, the residuals are
not independent from the utility, which is a sign of a
misspecification.  Unfortunately, the source of the misspecification
itself is not revealed by the plot.

\begin{figure}
\begin{center}
%\epsfig{figure=residualUtil2,width=\textwidth}
\caption{\label{fig:1_1}Testing Util2 = ( (  ASC2   *  one   ) + (  BETA1   *  x21   ) ) + (  BETA2   *  x22   ) with alt. Alt2}
\end{center}
 \end{figure}

We can trim the data and exclude values below -7 and above 7, using the syntax 
{\footnotesize
\begin{verbatim}
 $E { ASC2 * one + BETA1 * x21 + BETA2 * x22 } 1 -7 7 "Util2" 
\end{verbatim}
}
Doing this, we exclude only 2.8\% of the data, and the plot on
Figure~\ref{fig:1_1trim} emphasizes even more the misspecification.
Note that trimming is not equivalent to a zoom on the plot. The data
are excluded before the nonparametric estimation is
performed. Although in principle it should not affect the general
shape of the plot, some discrepancies my appear especially at the
borders of the selected interval.

\begin{figure}
\begin{center}
%\epsfig{figure=residualUtil2trim,width=\textwidth}
\caption{\label{fig:1_1trim}Testing Util2 in $[-7:7]$ with alt. Alt2}
\end{center}
 \end{figure}

If \LaTeX\ is not available,  the plots may be generated using Excel
or something similar. Indeed, \BIOSIM\ creates also the file
\texttt{24ZhengFosgerau\_zheng.enu} which is an ASCII file, easily
imported in a spreadsheet. The file is organized as follows. For each
test (that is for each function $t$ defined by the user), a total of
$5 (J+1)$ rows are generated, where $J$ is the number of
alternatives. The name of the function $t$ is reported in the first
column. The first 5 rows contain the smallest and the largest values,
the range, the bandwidth used for the nonparametric regression (that
is $c/\sqrt{n}$, where $n$ is the sample size and $c$ is user defined,
and 1 by default), and a description of the trimming using the syntax 
{\footnotesize
\begin{verbatim}
 [l:u]: nl < ni > nu <==> pl% < pi% > pu%
\end{verbatim}
}
where \text{l} and \text{u} are the lower and the upper bound defined
by the user, \texttt{nl} and \texttt{nu} are the number pieces of data excluded
because they are beyond the lower (resp. upper) bound, and \texttt{ni}
is the number of pieces of data considered in the analysis. \texttt{pl,
pi} and \texttt{pu} report the same information in terms of
percentages.  

For each alternative, 5 rows are generated, containing the following information:
\begin{enumerate}
\item The name of the alternative, the ID and the value of the Zheng
test;
\item A list of  values corresponding to th $x$-axis of the plot. By default, there
are 100 of them.
\item A  list of values for the residual, corresponding
to the continuous line in Figure~\ref{fig:1_1trim}.
\item A  list of values for the lower bound of the
confidence interval, corresponding to the lower dashed line in Figure~\ref{fig:1_1trim}.
\item A  list of values for the upper bound of the
confidence interval, corresponding to the upper dashed line in Figure~\ref{fig:1_1trim}.
\end{enumerate}

\index{ZhengFosgerau|)}
\index{BIOSIM!ZhengFosgerau|)}

\section{IIA test}
\label{sec:iia}
\index{IIA test}
\index{Test!IIA}
\index{BIOSIM!IIA test}
Suppose that we have estimated a logit model, using all the observations. The final log likelihood of this model is $\L_1$. Denote by $P_{in}$ the probability given by this model that individual $n$ in the sample chooses alternative $i$.

Consider $\widehat{\C} \subseteq \C$ a given subset of alternatives. Define the new variables
\begin{equation}
\label{eq:variablesIIAtest}
z_{in} = \left\{ 
\begin{array}{ll}
\displaystyle V_{in} - \frac{\sum_{j\in \widehat{\C}} P_{jn} V_{jn}}{\sum_{j\in \widehat{\C}} P_{jn}} & \text{if } i \in \widehat{\C}, \\&\\
0 & \text{if } i \not\in \widehat{\C}. 
\end{array}
\right.
\end{equation}

Estimate the same model as before where the new variables have been
also included in the specification.  Testing if IIA holds is
equivalent to testing if all the coefficients of the new variables are 0,
which can be performed with a likelihood ratio test.

\section{Merging files}
\label{sec:biomerge}
\index{Merge files}

It is often convenient (in particular when performing the IIA test
described in Section~\ref{sec:iia}) to expand the original
observation database with new variables that have been computed (for example) with \BIOSIM. A simple utility, called \texttt{biomerge} has been implemented to perform this task easily. If \texttt{file1}, \texttt{file2}, \ldots, \texttt{filen} are $n$ ASCII files containing the exact same number of rows each. 
The command
{\footnotesize
\begin{verbatim}
biomerge file1 file2 ... filen
\end{verbatim}
}
will generate a file called \texttt{biomergeOutput.lis} such that row number $j$ of this file is the concatenation of row number $j$ of all input files. 


\section{Known problems}

\begin{enumerate}
\item The loglikelihood estimator used by \BIOGEME\ to estimate  a model
with panel data\index{Panel data} has been designed for instances
where all random parameters are panel. When some of the random parameters
are cross-sectional, the estimator is not exactly correct. It is
conjectured that the estimates are still consistent, but not as
efficient as they should be. 
So, except if you have good reasons to do otherwise,
make sure that all the random
variables are listed in the \verb+[PanelData]+ section.
\item The values in the section ``Variance of random
coefficients'' have been reported wrong by several users on some model
instances. Make sure to verify if the reported values make sense. If not, simply ignore this section. The value of the
parameters reported in the ``Utility parameters'' section are
correct. 
\end{enumerate}


\section{Basic examples}
\label{sec:examples}
\index{Examples|(}
A list of examples is available from the BIOGEME webpage. 
Two complementary data files are available: \verb+sample.dat+ containing 1000
observations, and \verb+sample2.dat+ containing 999 observations. These two files are grouped in the file \verb+fullsample.dat+.  Therefore, the following runs are equivalent:
\begin{center}
\verb+biogeme mymodel sample.dat sample2.dat+
\end{center}
and
\begin{center}
\verb+biogeme mymodel fullsample.dat+
\end{center}
These examples are designed to help the user understanding how to use
\BIOGEME. They are not meant to illustrate how to build good
models. Note that reading this section supposes that you can read and
edit the example files, and run \BIOGEME.

\subsection{A binary logit model}
\begin{flushright}
\verb+00bl.mod+
\end{flushright}

Example of a model specification file for binary logit. The
Alternative Specific Constant (ASC) associated with alternative 1 has
been fixed, and will not be estimated.

In order to use the same data file as for the other examples, all observations with a choice strictly larger than 2 are excluded using the following syntax:
{\footnotesize
\begin{verbatim}
[Exclude]
Choice > 2
\end{verbatim}
}
Therefore, each observation corresponds to the choice of alternative 1 or alternative 2.

\subsection{A binary probit model}
\begin{flushright}
\verb+00bp.mod+
\end{flushright}

Example of a model specification file for binary probit. Except for the distribution assumption on the error term, the model specification is the same as in \verb+00bl.mod+.

\subsection{A basic model}
\begin{flushright}
\verb+01mnl-basic.mod+
\end{flushright}

The file \verb+01mnl-basic.mod+ contains the minimum model description needed
by \BIOGEME. It is a typical example of a file created by hand. The
model has 6 alternatives, and the utility functions contain only the
Alternative Specific Constants. The ASC associated with alternative 1
has been fixed, and will not be estimated.



\subsection{Weight the observations}
\begin{flushright}
\verb+02mnl-weights.mod+
\end{flushright}

The observations are now weighted. But weighting the observations must
be done carefully. Namely, the sum of all weights should be equal  to
the sample size. \BIOGEME\ provides some help to achieve this
property. In the file \verb+02mnl-weights.sta+, it is reported
\small
{\footnotesize
\begin{verbatim}
Sample size=1000
Total weight=994.295
     --> It is recommended to multiply all weights by 1.005738e+00
\end{verbatim}
}
\normalsize

\subsection{Corrected weights}
\begin{flushright}
\verb+03mnl-weights.mod+
\end{flushright}
The weights are corrected based on the recommendation from the
\verb+.sta+ file in the following way:
\small
{\footnotesize
\begin{verbatim}
[Weight]
Weight * 1.005738
\end{verbatim}
}
\normalsize

\subsection{Heterogeneous samples}
\begin{flushright}
\verb+04mnl-heterosample.mod+
\end{flushright}
This example illustrates the estimation of scale parameters for
different groups in the sample. We have here two groups, defined by
\small
{\footnotesize
\begin{verbatim}
[Group]
(Id <= 50) * 1 + (Id >= 51) * 2
\end{verbatim}
}
\normalsize
It means that group 1 is composed of individuals with ids up to
 50, and group 2 with ids from 51.
The associated scale parameters are defined by
\small
{\footnotesize
\begin{verbatim}
[Scale]
// Group_number  Scale  LowerBound   UpperBound  Status
       1          1        0.001       1000        1
       2          1        0.001       1000        0
\end{verbatim}
}
\normalsize

Clearly, only one of them is identifiable. Note that this allows to
avoid complicated tricks based on nested structures in the presence of
heterogeneous populations. 

\subsection{More coefficients}
\begin{flushright}
\verb+05mnl-beta.mod+
\end{flushright}
Here, we have included some additional coefficients into the model.
\small
{\footnotesize
\begin{verbatim}
BETA1       0         -10000         10000       0
BETA2       0         -10000         10000       0
\end{verbatim}
}
\normalsize

There are both significant:
\small
{\footnotesize
\begin{verbatim}
Name  Value          Robust Std err Robust t-test
BETA1 +7.5924002e-001 +3.7156070e-002 +2.0433808e+001
BETA2 +7.7572746e-001 +3.6835050e-002 +2.1059493e+001
\end{verbatim}
}
\normalsize

But they are correlated in such a way that the hypothesis that they
are equal cannot be rejected, at a 95\% level:
\footnotesize
{\footnotesize
\begin{verbatim}
Coefficient1 Coefficient2      Rob. cov.     Rob. corr.    Rob. t-test
~~~~~~~~~~~~ ~~~~~~~~~~~~      ~~~~~~~~~     ~~~~~~~~~~    ~~~~~~~~~~~
BETA1        BETA2        +1.0688450e-03 +7.8095080e-01	-6.7326255e-01 *
\end{verbatim}
}
\normalsize

\subsection{Modification of an attribute}
\begin{flushright}
\verb+06mnl-modif-attrib.mod+
\end{flushright}
This example exploits the looping feature on the Expressions section.

\footnotesize
{\footnotesize
\begin{verbatim}
        [Utilities]
        // Id Name  Avail  linear-in-parameter expression (beta1*x1 + beta2*x2 + ... )
          1   Alt1   av1   ASC1 * one + BETA1 * logx11 + BETA2 * x12
          2   Alt2   av2   ASC2 * one + BETA1 * logx21 + BETA2 * x22
          3   Alt3   av3   ASC3 * one + BETA1 * logx31 + BETA2 * x32
          4   Alt4   av4   ASC4 * one + BETA1 * logx41 + BETA2 * x42
          5   Alt5   av5   ASC5 * one + BETA1 * logx51 + BETA2 * x52
          6   Alt6   av6   ASC6 * one + BETA1 * logx61 + BETA2 * x62

        [Expressions] 
        // Define here arithmetic expressions for name that are not directly 
        // available from the data
        one = 1

        $LOOP{ZZ 1 6 1} logxZZ1 = log( xZZ1 + 15.0 )
\end{verbatim}
}
\normalsize

\subsection{A simple Mixed Logit model}
\begin{flushright}
\verb+07mixed-mnl.mod+
\end{flushright}
This example allows for a single normally distributed random
coefficient \verb+BETA1 [ SIGMA1 ]+.  More detailed
examples are provided in the next section.
\begin{flushright}
\verb+07mixed-unif-mnl.mod+
\end{flushright}
This example allows for a single uniformly distributed random
coefficient \verb+BETA1 { SIGMA1 }+.


Note that, in both cases, the number of draws is very low, because the only purpose of these example is to illustrate the syntax, and to test the software. In practice, the number of draws should be at least 1000.

\subsection{Discrete mixture}
\begin{flushright}
\verb+08mixed-discrete.mod+
\end{flushright}
This example allows for a the coefficient \verb+BETA1+ to follow a discrete distribution. It can take two values: \verb+B1+, with probability \verb+W1+, and \verb+B2+, with probability \verb+W2+. For the model to make sense, it is necessary to impose the linear constraint:

{\footnotesize
\begin{verbatim}
[LinearConstraints]
W1 + W2 = 1.0
\end{verbatim}
}

Due to the presence of this constraint, algorithm BIO cannot be used. Therefore, a file \verb+08mixed-discrete.par+ has been created, where the algorithm DONLP2 is preferred:
{\footnotesize
\begin{verbatim}
gevAlgo = "DONLP2"
\end{verbatim}
}

\subsection{A simple Non Linear model}
\begin{flushright}
\verb+09mnl-nonlinear.mod+
\end{flushright}

The example \verb+09mnl-nonlinear.mod+ demonstrates how to add non linear components to the 
specification of the utilities. In this case we apply a Box-Tuckey transformation to the x
variables in the specification of utility 1.  The code to implement this is:

\footnotesize
{\footnotesize
\begin{verbatim}
[Utilities]
// Id Name  Avail  linear-in-parameter expression (beta1*x1 + beta2*x2 + ... )
  1   Alt1   av1   ASC1 * one 
  2   Alt2   av2   ASC2 * one + BETA1 * x21 + BETA2 * x22
  3   Alt3   av3   ASC3 * one + BETA1 * x31 + BETA2 * x32
  4   Alt4   av4   ASC4 * one + BETA1 * x41 + BETA2 * x42
  5   Alt5   av5   ASC5 * one + BETA1 * x51 + BETA2 * x52
  6   Alt6   av6   ASC6 * one + BETA1 * x61 + BETA2 * x62

[GeneralizedUtilities]
1  BETA1 * ((x11 + 10 ) ^ LAMBDA11 - 1) / LAMBDA11 
 + BETA2 * ((x12 + 10 ) ^ LAMBDA12 - 1) / LAMBDA12
\end{verbatim}
}
\normalsize

\begin{flushright}
\verb+09mnl-nonlinear-deriv.mod+
\end{flushright}

Same file, where the derivatives are explicitly coded in the specification file as follows:

\footnotesize
{\footnotesize
\begin{verbatim}
[Derivatives]
1 BETA1 ((x11 + 10 ) ^ LAMBDA11 - 1) / LAMBDA11
1 BETA2 ((x12 + 10 ) ^ LAMBDA12 - 1) / LAMBDA12
1 LAMBDA11 
      BETA1 * ((x11 + 10) ^ LAMBDA11 * LN(x11 + 10) * LAMBDA11 
             - (x11 + 10) ^ LAMBDA11 + 1) / (LAMBDA11 * LAMBDA11 )
1 LAMBDA12 
      BETA2 * ((x12 + 10) ^ LAMBDA12 * LN(x12 + 10) * LAMBDA12 
             - (x12 + 10) ^ LAMBDA12 + 1) / (LAMBDA12 * LAMBDA12 )
\end{verbatim}
}
\normalsize

\subsection{A simple Nested Logit model}
\begin{flushright}
\verb+10nl.mod+
\end{flushright}
A Nested Logit model with two nests, A and B, is tested. Alternatives 1, 2 and 3 
belong to nest A, and the other alternatives to nest B.
\small
{\footnotesize
\begin{verbatim}
[NLNests]
// Name paramvalue  LowerBound UpperBound  status list of alt
NESTA     1.0           1.0       10.0         0   1 2 3 
NESTB     1.0           1.0       10.0         0   4 5 6
\end{verbatim}
}
\normalsize

Note that it is normalized from the top, that is $\mu=1$, imposing that \verb+NESTA+ $\geq 1$ and \verb+NESTB+ $\geq 1$, in order to obtain the conditions required by the theory, that is
\[
0 \leq \mu/\text{NESTA} \leq 1,
\]
and
\[
0 \leq \mu/\text{NESTB} \leq 1.
\]


\begin{flushright}
\verb+10nl-bottom.mod+
\end{flushright}

In the file \verb+10nl-bottom.mod+, the exact same model is described, but
normalized from the bottom, while the previous was normalized from
the top.  The coefficient of nest A is constrained to 1, and the $\mu$
parameter is estimated. 
{\footnotesize
\begin{verbatim}
[Mu]
// Value LowerBound UpperBound Status
     1.0        0.0        1.0      0
\end{verbatim}
}

It is important to understand that both models are equivalent, even if
the estimated parameters do not have the same values. In the following
table, the column ``Top'' contains the estimated parameters for the
model normalized at the top, and ``Bottom'' the estimated parameters
for the model normalized at the bottom. The third column contains the
scaled parameters, that is each parameter multiplied by $\mu$, except
for the nests parameters, where the value $\mu/\mu_m$ is reported, $m$
being the nest. These values are independent of the normalization, and
should be used when comparing models.

\begin{center}
\begin{tabular}{rrrr}
\hline
           &        Top &     Bottom &     Scaled \\
\hline
      ASC1 &          0 &          0 &          0 \\

      ASC2 &    -0.0897 &    -0.1527 &    -0.0897 \\

      ASC3 &    -0.0650 &    -0.1107 &    -0.0650 \\

      ASC4 &    -0.3282 &    -0.5587 &    -0.3282 \\

      ASC5 &     0.5651 &     0.9619 &     0.5651 \\

      ASC6 &    -0.8872 &    -1.5102 &    -0.8872 \\

     BETA1 &     0.5350 &     0.9107 &     0.5350 \\

     BETA2 &     0.5537 &     0.9426 &     0.5538 \\
\hline
        MU &     1.0000 &     0.5875 &            \\

     NESTA &     1.7023 &     1.0000 &    0.5874  \\

     NESTB &     3.2339 &     1.8996 &    0.3092  \\
\hline
\end{tabular} 
\end{center} 

\begin{flushright}
\verb+10nl-constrained.mod+
\end{flushright}

In this example, the nest parameters of the nested logit model are
constrained to be equal. Note that it is not a normalization
constraint, as the drop in loglikelihood from $-848.171$ to $-858.941$
illustrates.

{\footnotesize
\begin{verbatim}
[LinearConstraints]
NESTA - NESTB = 0.0
\end{verbatim}
}

\subsection{A Cross-Nested Logit model}
\begin{flushright}
\verb+11cnl.mod+
\end{flushright}

The CNL model has two nests, A and B, and each alternative  belongs to both nests. 
The  $\alpha$ parameters are set to 1/2:
\small 
{\footnotesize
\begin{verbatim}
[CNLAlpha]
// Alt Nest value LowerBound UpperBound  status
Alt1 NESTA   0.5   0.0001  1.0   1
Alt2 NESTA   0.5   0.0001  1.0   1
Alt3 NESTA   0.5   0.0001  1.0   1
Alt4 NESTA   0.5   0.0001  1.0   1
Alt5 NESTA   0.5   0.0001  1.0   1
Alt6 NESTA   0.5   0.0001  1.0   1
Alt1 NESTB   0.5   0.0001  1.0   1
Alt2 NESTB   0.5   0.0001  1.0   1
Alt3 NESTB   0.5   0.0001  1.0   1
Alt4 NESTB   0.5   0.0001  1.0   1
Alt5 NESTB   0.5   0.0001  1.0   1
Alt6 NESTB   0.5   0.0001  1.0   1
\end{verbatim}
}
\normalsize

\begin{flushright}
\verb+12cnl.mod+
\end{flushright}
In the file \verb+12cnl.mod+, the $\alpha$ parameters are now
estimated. For each alternative, the sum of corresponding $\alpha$
parameters must sum up to 1.0. Therefore, we add the constraints
{\footnotesize
\begin{verbatim}
[LinearConstraints]
NESTA_Alt1 + NESTB_Alt1 = 1.0
NESTA_Alt2 + NESTB_Alt2 = 1.0
NESTA_Alt3 + NESTB_Alt3 = 1.0
NESTA_Alt4 + NESTB_Alt4 = 1.0
NESTA_Alt5 + NESTB_Alt5 = 1.0
NESTA_Alt6 + NESTB_Alt6 = 1.0
\end{verbatim}
}

\begin{flushright}
\verb+13cnl.mod+
\end{flushright}
The file \verb+13cnl.mod+ is the same as \verb+12cnl.mod+, with
another starting point based on the estimates of the nested logit model.

\subsection{A Network GEV model}
\begin{flushright}
\verb+14ngev.mod+
\end{flushright}
The Nested Logit model of file \verb+10nl.mod+ is described here using
the Network GEV syntax. Note that the high level of generality
provided by the network GEV model comes with a cost. On my computer, a
Network GEV model takes much longer to estimate than the same
Nested Logit model. 

\begin{flushright}
\verb+15ngev.mod+
\end{flushright}

It is important to note that the model formulation of the Network GEV
model (\cite{DalyBier06}) is not consistent with the Cross-Nested
Logit model formulation. In order to illustrate it, the file
\verb+15ngev.mod+ is mimicking the model described in
\verb+11cnl.mod+, but should be used for syntax considerations only.
In general, the two models will give different results, although they
are theoretically equivalent, for two reasons.

\begin{enumerate}
\item The normalization conditions of the Network GEV models are not
  clear, and definitely nonlinear. They have not been specified in the
  file \verb+15ngev.mod+, and it complicates the run of the algorithm
  as the optimization is degenerate.
\item When the $\alpha$ parameters are estimated in a CNL or a Network
  GEV model, the loglikelihood function exhibits many local maxima. It
  is very rare that estimations on the two versions of the model leads
  to the same local maximum.
\end{enumerate}

\subsection{Panel data}
\label{sec:panel_ex}
\index{Panel data}
\begin{flushright}
\verb+16panel.mod+
\end{flushright}
The MNL model from file \verb+05mnl-beta.mod+ combined with individual
specific error components \verb+ZERO [ SIGMA ] * one+, where \verb+SIGMA+
is estimated. Note that \verb+ZERO+ must be declared, but is
fixed to 0. 
The section
{\footnotesize
\begin{verbatim}
[PanelData]
Id
ZERO_SIGMA
\end{verbatim}
}
tells \BIOGEME\ that individuals ids can be found under \verb+Id+ in
the sample file, and that the random coefficient  \verb+ZERO_SIGMA+
does not vary across observations from the same individual. Note that
it is assumed in \BIOGEME\ that the data file is sorted in such a way
that all observations from each individual are successive in the data file.

\subsection{Expressions}

\begin{flushright}
 17expressions.mod
\end{flushright}

Illustrates the syntax of expressions. Namely, a dummy variable which is defined by
\[
\text{dum12} = \left\{ 
\begin{array}{ll}
1 & \text{ if x11} \geq 1 \text{ or x21} \geq 1 \\
0 & \text{ otherwise}
\end{array}
\right.
\]
is coded as
{\footnotesize
\begin{verbatim}
dum12 = ( x11 >= 1 ) || ( x21 >= 1 )
\end{verbatim}
}

\subsection{Selection bias}

\begin{flushright}
  18selectionBias.mod
\end{flushright}

\BIOGEME\ has the capability to correct for selection bias in some
circumstances. The syntax is simple: the list of additionnal
parameters to be estimated must be listed together with their
associated alternative in the Section
[SelectionBias] of the .mod file, as illustrated in this file. See
Section~\ref{sec:selectionBias} and \cite{BierBoldMcFa08} for more
details.

\subsection{Discrete distributions and panel data}
\index{Panel data}
\begin{flushright}
  19panelDiscrete.mod
\end{flushright}

Illustrate a model where one random coefficient has a continuous distribution, and another a discrete distribution, in a panel data context. 


\subsection{Seminonparametric transformation}

\begin{flushright}
  20legendre.mod
\end{flushright}

Example of a mixture of MNL (actually, same as \verb+07mixed-mnl.mod+)
where a seminonparametric transformation, based on the Legendre
polynomials of degree 1, 3 and 4, has been applied. Not that, in practice, it is more common to use consecutive terms. Again, this example is designed to illustrate the syntax, and to emphasize that some terns may be omitted if necessary. See \citeasnoun{FosgBier07} for details.

\subsection{Lognormal distribution}
\begin{flushright}
21mixed-lognormal.mod
\end{flushright}

Example of a mixture with a lognormally distributed coefficient.

\begin{flushright}
21mixed-lognormal.mod
\end{flushright}

Same example where the derivatives are explicitly implemented by the user. It illustrate the use of the operator \verb+$DERIV+ used to ask BIOGEME to compute the derivative for you. It is mandatory to use it when random variables are involved, such as in this example. 

\subsection{Ordinal logit}
\begin{flushright}
22ordinalLogit.mod
\end{flushright}

Exact same model as in the file \verb+00bl.mod+, but using the syntax of an ordinal logit model (with only two categories, in this case). It is interesting to compare the sign of the coefficients between the two models. 

\begin{flushright}
23ordinalLogit.mod
\end{flushright}


Example of a model specification file for an ordinal logit model with 4 categories. Note the following section, defining the categories:
\footnotesize
{\footnotesize
\begin{verbatim}
[OrdinalLogit]
1 $NONE    //  Category 1 spans -infty --> tau1 
2 tau1     //           2 spans tau1   --> tau2
3 tau2     //           3 spans tau2   --> tau3
4 tau3     //           4 spans tau3   --> +infty
\end{verbatim}
}
\normalsize

Remember the convention introduced in Section~\ref{sec:ordinal}:
\begin{itemize}
\item the model must contain exactly two alternatives;
\item the identifier of the alternative is completely ignored;
\item alternative $i$ is the first by alphabetical order, and alternative $j$ is the second.
\end{itemize}


The estimation of all basic examples are summarized in Table~\ref{tab:summary}\index{Summary}.
\begin{table}[htbf]
% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{center}
\begin{tabular}{rrrrrr}
\hline
{\textbf Model} & {\textbf Loglike} & {\textbf Obs.} & {\textbf Ind.} & {\textbf BETA1} & {\textbf BETA2} \\
\hline

      00bl &   -151.954 &       1019 &       1019 &      0.921 &      0.954 \\

      00bp &   -151.709 &       1019 &       1019 &      0.509 &      0.528 \\

01mnl-basic &  -2477.245 &       1999 &       1999 &          - &          - \\

02mnl-weights &  -2474.038 &       1999 &       1999 &          - &          - \\

03mnl-weights &  -2488.234 &       1999 &       1999 &          - &          - \\

04mnl-heterosample &  -2477.241 &       1999 &       1999 &          - &          - \\

05mnl-beta &   -891.225 &       1999 &       1999 &      0.779 &       0.81 \\

06mnl-modif-attrib &   -904.776 &       1999 &       1999 &         12 &      0.793 \\

07mixed-mnl &   -890.626\footnotemark[1] &       1999 &       1999 &      0.782 &      0.811 \\

07mixed-unif-mnl &   -890.823\footnotemark[1] &       1999 &       1999 &      0.781 &       0.81 \\

08mixed-discrete &   -891.225 &       1999 &       1999 &    -dist.- &       0.81 \\

09mnl-nonlinear-deriv &   -890.775 &       1999 &       1999 &      0.787 &      0.809 \\

09mnl-nonlinear &   -890.775 &       1999 &       1999 &      0.787 &      0.809 \\

10nl-bottom &   -848.171 &       1999 &       1999 &      0.911 &      0.943 \\

10nl-constrained &   -858.941 &       1999 &       1999 &      0.536 &      0.558 \\

      10nl &   -848.171 &       1999 &       1999 &      0.535 &      0.554 \\

   10nlsim &   -848.171 &       1999 &       1999 &      0.535 &      0.554 \\

     11cnl &   -890.902 &       1999 &       1999 &      0.659 &      0.685 \\

     12cnl &   -846.955\footnotemark[2] &       1999 &       1999 &      0.513 &       0.53 \\

     13cnl &   -846.955 &       1999 &       1999 &      0.513 &       0.53 \\

    14ngev &   -848.171 &       1999 &       1999 &      0.535 &      0.554 \\

    15ngev &    -890.92 &       1999 &       1999 &      0.647 &      0.672 \\

   16panel &   -890.008\footnotemark[1] &       1999 &        200 &      0.782 &      0.813 \\

17expressions &   -891.162 &       1999 &       1999 &      0.776 &       0.81 \\

18selectionBias &   -846.778 &       1999 &       1999 &      0.539 &      0.558 \\

19panelDiscrete &   -890.008\footnotemark[1] &       1999 &        200 &    -dist.- &      0.813 \\

20legendre &    -891.34\footnotemark[1] &       1999 &        200 &      0.791 &      0.815 \\

21mixed-lognormal-deriv &   -895.748 &       1999 &       1999 &     -0.256 &      0.806 \\

21mixed-lognormal &   -895.748 &       1999 &       1999 &     -0.256 &      0.806 \\

22ordinalLogit &   -151.954 &       1019 &       1019 &     -0.921 &     -0.954 \\

23ordinalLogit &  -2113.617 &       1672 &       1672 &     -0.0856 &    -0.0968 \\

\hline
\multicolumn{6}{r}{\footnotesize $\mbox{}^1$ The value will vary from machine to machine due to the random seed }\\
\multicolumn{6}{r}{\footnotesize $\mbox{}^2$ On some machines, 12cnl converges to a loglikelihood of -891.225 }
\end{tabular}  
\end{center}





\caption{\label{tab:summary}Summary of the estimation of the basic examples}
\end{table}


\section{Examples of logit kernel (mixed logit) formulations}

{\emph The examples in this section have been kindly prepared and tested by D. Bolduc and M.-H. Godbout}

In this section, we explore several versions of logit kernel formulations in
order to demonstrate the capabilities of Biogeme. \ To achieve this, we
generate a sample of 1000 observations arising from a very general model
specification which contains, as a special case, several submodels that are
often used in applied work. \ 

\subsection{The data generating process}

This subsection introduces the notation, describes the general model and shows
how we generated the synthetic sample datafile we provide with the examples.
The following section gives the specialized form of the model and 
provides the associated input files. Let's consider a choice situation involving
the choice among 6 alternatives. \ The following data generating process is
used to generate data for a sample of 1000 synthetic choices:\ %

\begin{equation}%
\begin{array}
[c]{cccccccc}%
U_{1n}= & \alpha_{1} & +X_{11n}\beta_{1} & +X_{12n}\beta_{2} & +\sigma_{1}%
\xi_{1n} &  &  & +\nu_{1n}\\
U_{2n}= & \alpha_{2} & +X_{21n}\beta_{1} & +X_{22n}\beta_{2} & +\sigma_{1}%
\xi_{1n} & +\sigma_{2}\xi_{2n} &  & +\nu_{2n}\\
U_{3n}= & \alpha_{3} & +X_{31n}\beta_{1} & +X_{32n}\beta_{2} &  & +\sigma
_{2}\xi_{2n} &  & +\nu_{3n}\\
U_{4n}= & \alpha_{4} & +X_{41n}\beta_{1} & +X_{42n}\beta_{2} &  & +\sigma
_{2}\xi_{2n} &  & +\nu_{4n}\\
U_{5n}= & \alpha_{5} & +X_{51n}\beta_{1} & +X_{52n}\beta_{2} &  & +\sigma
_{2}\xi_{2n} & +\sigma_{3}\xi_{3n} & +\nu_{5n}\\
U_{6n}= &  & +X_{61n}\beta_{1} & +X_{62n}\beta_{2} &  &  & +\sigma_{3}\xi_{3n}
& +\nu_{6n}%
\end{array}
\label{General process}%
\end{equation}


In this specification, many interesting effects are allowed. \ For instance,
for a given alternative $i$, heteroscedasticity in utility $i$ could be
modeled using a random alternative specific constant (ASC). \ The second two
columns contains two variables $X_{1}$ and $X_{2}$ associated with two generic
coefficients. \ Flexibility would allow them to be random. \ These components
would permit to model heterogeneity across individuals. \ In our example,
$\beta_{1}$ and $\beta_{2}$ are assumed to come from a joint normal
distribution with respective means $\bar{\beta}_{1}$ and $\bar{\beta}_{2}$ and
variance and covariance matrix:%
\begin{equation}
\Sigma_{\beta}=\left[
\begin{array}
[c]{cc}%
var(\beta_{1}) & cov(\beta_{1},\beta_{2})\\
cov(\beta_{1},\beta_{2}) & var(\beta_{2})
\end{array}
\right]  =\left[
\begin{array}
[c]{cc}%
\sigma_{1}^{2} & \sigma_{12}\\
\sigma_{12} & \sigma_{2}^{2}%
\end{array}
\right]  . \label{varcov of beta}%
\end{equation}
For convenience, the $X\,_{kin}^{\prime}s$ , $k=1,2,$ $i=1,...,6$ \ and
$n=1,...,N=1000,\;$are i.i.d. random variates generated from a standard normal
distribution. The $\xi_{in}$ are error component terms (factors) that allow to
model the correlation across the utilities. Here, alternatives 1 and 2 are
related through factor 1, alternatives 2, 3, 4 and 5 are related through
common factor 2 and the last two alternatives have factor 3 in common. \ The
$\nu_{in}^{\prime}s$ are i.i.d. Gumbel error terms.

\subsubsection{On correlated random coefficients}

\specitem{Cholesky factorization} 
In the above subsection, we assumed that:%
\[
\left(
\begin{array}
[c]{c}%
\beta_{1}\\
\beta_{2}%
\end{array}
\right)  \sim MVN(\left(
\begin{array}
[c]{c}%
\bar{\beta}_{1}\\
\bar{\beta}_{2}%
\end{array}
\right)  ,\left[
\begin{array}
[c]{cc}%
\sigma_{1}^{2} & \sigma_{12}\\
\sigma_{12} & \sigma_{2}^{2}%
\end{array}
\right]  ).
\]
Using the Cholesky factorization, the vector $(\beta_{1},\beta_{2})^{\prime}$
can be replaced by:%
\begin{equation}
\left(
\begin{array}
[c]{c}%
\beta_{1}\\
\beta_{2}%
\end{array}
\right)  =\left(
\begin{array}
[c]{c}%
\bar{\beta}_{1}\\
\bar{\beta}_{2}%
\end{array}
\right)  +\left[
\begin{array}
[c]{cc}%
p_{11} & 0\\
p_{21} & p_{22}%
\end{array}
\right]  \left[
\begin{array}
[c]{c}%
\zeta_{1}\\
\zeta_{2}%
\end{array}
\right]  \label{Cholesky 1}%
\end{equation}
where $\zeta_{1}$ and $\zeta_{2}$ are i.i.d. standard normal variates. Using a
matrix notation, we write it as:%
\begin{equation}
\beta=\bar{\beta}+P\zeta, \label{Cholesky 2}%
\end{equation}
where $P$ corresponds to a lower triangular Cholesky factorization matrix such
that \ $PP^{\prime}=\Sigma_{\beta}.$

We now consider several submodels of the above general formulation.

\subsection{Linear specification with independent normally distributed random
coefficients}


In this version, the model is written as:%

\begin{equation}%
\begin{array}
[c]{ccccc}%
U_{1n}= & \alpha_{1} & + X_{11n}\beta_{1} & + X_{21n}\beta_{2} & + \nu_{1n}\\
U_{2n}= & \alpha_{2} & + X_{12n}\beta_{1} & + X_{22n}\beta_{2} & + \nu_{2n}\\
U_{3n}= & \alpha_{3} & + X_{13n}\beta_{1} & + X_{23n}\beta_{2} & + \nu_{3n}\\
U_{4n}= & \alpha_{4} & + X_{14n}\beta_{1} & + X_{24n}\beta_{2} & + \nu_{4n}\\
U_{5n}= & \alpha_{5} & + X_{15n}\beta_{1} & + X_{25n}\beta_{2} & + \nu_{5n}\\
U_{6n}= &  & + X_{16n}\beta_{1} & + X_{26n}\beta_{2} & + \nu_{6n}%
\end{array}
\label{ind random coefs}%
\end{equation}
where the $\alpha^{\prime}s$ are fixed and where the $\beta_{k},k=1,2$ are
independently generated as follows: $\beta_{1}$ $\sim N(\bar{\beta}_{1}%
,\sigma_{1}^{2})$ and $\beta_{2}$ $\sim N(\bar{\beta}_{2},\sigma_{2}^{2}).$

\subsubsection{Input file}

\begin{flushright}
\verb+17_2.mod+
\end{flushright}

The main sections of the Biogeme file required to estimate this model is as follows:

\tiny
{\footnotesize
\begin{verbatim}
 
[Beta]
// Name   Value     LowerBound UpperBound  status (0=variable, 1=fixed)
ASC1        1.0          -10.0     10.0         0
ASC2        1.0          -10.0     10.0         0
ASC3        1.0          -10.0     10.0         0
ASC4        1.0          -10.0     10.0         0
ASC5        1.0          -10.0     10.0         0
BETA1       1.0          -10.0     10.0         0
BETA2       1.0          -10.0     10.0         0
BETA1_S     1.0          -10.0     10.0         0
BETA2_S     1.0          -10.0     10.0         0
 
[Utilities]
// Id  Name  Avail  linear-in-parameter expression (beta1*x1 + beta2*x2 + ... )
 1   Alt1  av1  ASC1 * one + BETA1 [ BETA1_S ] * x11 + BETA2 [ BETA2_S ] * x12 
 2   Alt2  av2  ASC2 * one + BETA1 [ BETA1_S ] * x21 + BETA2 [ BETA2_S ] * x22 
 3   Alt3  av3  ASC3 * one + BETA1 [ BETA1_S ] * x31 + BETA2 [ BETA2_S ] * x32 
 4   Alt4  av4  ASC4 * one + BETA1 [ BETA1_S ] * x41 + BETA2 [ BETA2_S ] * x42 
 5   Alt5  av5  ASC5 * one + BETA1 [ BETA1_S ] * x51 + BETA2 [ BETA2_S ] * x52 
 6   Alt6  av6               BETA1 [ BETA1_S ] * x61 + BETA2 [ BETA2_S ] * x62 
      
[Model]
// Currently, only $MNL (multinomial logit), $NL (nested logit), $CNL
// (cross-nested logit) and $NGEV (Network GEV model) are valid keywords
//
$MNL
\end{verbatim}
}
\normalsize

In the case with independent random coefficients, the parameter name between
the brackets designates the standard deviation of the random parameter term
with mean specified on the left of the bracket.

\subsection{Linear specification with correlated normally distributed random
coefficients}

In this version, the model is written as:%

\begin{equation}%
\begin{array}
[c]{ccccc}%
U_{1n}= & \alpha_{1} & +X_{11n}\beta_{1} & +X_{21n}\beta_{2} & +\nu_{1n}\\
U_{2n}= & \alpha_{2} & +X_{12n}\beta_{1} & +X_{22n}\beta_{2} & +\nu_{2n}\\
U_{3n}= & \alpha_{3} & +X_{13n}\beta_{1} & +X_{23n}\beta_{2} & +\nu_{3n}\\
U_{4n}= & \alpha_{4} & +X_{14n}\beta_{1} & +X_{24n}\beta_{2} & +\nu_{4n}\\
U_{5n}= & \alpha_{5} & +X_{15n}\beta_{1} & +X_{25n}\beta_{2} & +\nu_{5n}\\
U_{6n}= &  & +X_{16n}\beta_{1} & +X_{26n}\beta_{2} & +\nu_{6n}%
\end{array}
\end{equation}
where the $\alpha^{\prime}s$ are fixed and where each $\beta_{k},k=1,2$ are
generated from equation (\ref{Cholesky 1}) where the $p^{\prime}s$ are
Cholesky terms. \ 

\subsubsection{Input file}
\label{sec:ex-corr}

\begin{flushright}
\verb+17_3.mod+
\end{flushright}

The main sections of the Biogeme file required to estimate this model is as follows:

\tiny
{\footnotesize
\begin{verbatim}
 
[Beta]
// Name   Value     LowerBound UpperBound  status (0=variable, 1=fixed)
ASC1        1.0          -10.0     10.0         0
ASC2        1.0          -10.0     10.0         0
ASC3        1.0          -10.0     10.0         0
ASC4        1.0          -10.0     10.0         0
ASC5        1.0          -10.0     10.0         0
BETA1       1.0          -10.0     10.0         0
BETA2       1.0          -10.0     10.0         0
BETA1_S     1.0          -10.0     10.0         0
BETA2_S     1.0          -10.0     10.0         0
 
[Utilities]
// Id  Name Avail  linear-in-parameter expression (beta1*x1 + beta2*x2 + ... )
 1   Alt1   av1 ASC1  * one + BETA1 [ BETA1_S ] * x11 + BETA2 [ BETA2_S ] * x12 
 2   Alt2   av2 ASC2  * one + BETA1 [ BETA1_S ] * x21 + BETA2 [ BETA2_S ] * x22 
 3   Alt3   av3 ASC3  * one + BETA1 [ BETA1_S ] * x31 + BETA2 [ BETA2_S ] * x32 
 4   Alt4   av4 ASC4  * one + BETA1 [ BETA1_S ] * x41 + BETA2 [ BETA2_S ] * x42 
 5   Alt5   av5 ASC5  * one + BETA1 [ BETA1_S ] * x51 + BETA2 [ BETA2_S ] * x52 
 6   Alt6   av6               BETA1 [ BETA1_S ] * x61 + BETA2 [ BETA2_S ] * x62 
  
 
[ParameterCovariances]
 //  Par_i         Par_j    Value LowerBound UpperBound status (0=variable, 1=fixed)
BETA1_BETA1_S BETA2_BETA2_S   1.0      -10.0     10.0        0
    
[Model]
// Currently, only $MNL (multinomial logit), $NL (nested logit), $CNL
// (cross-nested logit) and $NGEV (Network GEV model) are valid keywords
//
$MNL
 
\end{verbatim}
}
\normalsize

The only difference with the previous example is that, we added the section
ParameterCovariances which indicates which pairs of coefficients are
correlated. In a situation with correlation, the coefficients describing the
variance covariance structure are Cholesky factorization terms. Thus, BETA1\_S
corresponds to $p_{11}$, BETA2\_S corresponds to $p_{22}$ and the term called
\newline BETA1\_BETA1\_S\_BETA2\_BETA2\_S in Biogeme corresponds to $p_{21}$.
In the output file, the estimates first presented correspond to those
coefficients. Then the Biogeme output converts the Cholesky terms into
variances and covariances. By definition, in the case with independent random
coefficients, the terms on the diagonal of the diagonal Cholesky factorization
matrix directly correspond to the standard deviations of the respective random coefficients.

\subsection{Specification with correlated normally and lognormally distributed
random coefficients}

In this version, we allow $\beta_{1}$ to be normally distributed and
$\beta_{2}$ to be lognormally distributed. \ They are also allowed to be
correlated. \ The model is written as:%

\begin{equation}%
\begin{array}
[c]{ccccc}%
U_{1n}= & \alpha_{1} & +X_{11n}\beta_{1} & +X_{21n}\beta_{2} & +\nu_{1n}\\
U_{2n}= & \alpha_{2} & +X_{12n}\beta_{1} & +X_{22n}\beta_{2} & +\nu_{2n}\\
U_{3n}= & \alpha_{3} & +X_{13n}\beta_{1} & +X_{23n}\beta_{2} & +\nu_{3n}\\
U_{4n}= & \alpha_{4} & +X_{14n}\beta_{1} & +X_{24n}\beta_{2} & +\nu_{4n}\\
U_{5n}= & \alpha_{5} & +X_{15n}\beta_{1} & +X_{25n}\beta_{2} & +\nu_{5n}\\
U_{6n}= &  & +X_{16n}\beta_{1} & +X_{26n}\beta_{2} & +\nu_{6n}%
\end{array}
\end{equation}
where the $\alpha^{\prime}s$ are fixed and where each $\beta_{k},k=1,2$ are
generated from the equation:%

\begin{equation}
\left(
\begin{array}
[c]{c}%
\beta_{1}\\
\ln\;\beta_{2}%
\end{array}
\right)  =\left(
\begin{array}
[c]{c}%
\bar{\beta}_{1}\\
\bar{\beta}_{2}%
\end{array}
\right)  +\left[
\begin{array}
[c]{cc}%
p_{11} & 0\\
p_{21} & p_{22}%
\end{array}
\right]  \left[
\begin{array}
[c]{c}%
\zeta_{1}\\
\zeta_{2}%
\end{array}
\right]
\end{equation}


where the $p^{\prime}s$ are Cholesky terms. \ 

\subsubsection{Input file}

\begin{flushright}
  \verb+17_4.mod+
\end{flushright}
\specitem{Example LogNormal} The main sections of the Biogeme file required to estimate 
this model is as follows:

\tiny
{\footnotesize
\begin{verbatim}
 
[Beta]
// Name   Value     LowerBound UpperBound  status (0=variable, 1=fixed)
ASC1        1.0          -10.0     10.0         0
ASC2        1.0          -10.0     10.0         0
ASC3        1.0          -10.0     10.0         0
ASC4        1.0          -10.0     10.0         0
ASC5        1.0          -10.0     10.0         0
BETA1       1.0          -10.0     10.0         0
BETA2       1.0          -10.0     10.0         0
BETA1_S     1.0          -10.0     10.0         0
BETA2_S     1.0          -10.0     10.0         0
 
[Utilities]
// Id  Name  Avail  linear-in-parameter expression (beta1*x1 + beta2*x2 + ... )
   1   Alt1    av1     ASC1  * one + BETA1 [ BETA1_S ] * x11   
   2   Alt2    av2     ASC2  * one + BETA1 [ BETA1_S ] * x21   
   3   Alt3    av3     ASC3  * one + BETA1 [ BETA1_S ] * x31   
   4   Alt4    av4     ASC4  * one + BETA1 [ BETA1_S ] * x41   
   5   Alt5    av5     ASC5  * one + BETA1 [ BETA1_S ] * x51   
   6   Alt6    av6                   BETA1 [ BETA1_S ] * x61   
  
[GeneralizedUtilities]
// Id Name  Avail  linear-in-parameter expression (beta1*x1 + beta2*x2 + ... )
1  exp( BETA2 [ BETA2_S ] ) * x12
2  exp( BETA2 [ BETA2_S ] ) * x22
3  exp( BETA2 [ BETA2_S ] ) * x32
4  exp( BETA2 [ BETA2_S ] ) * x42
5  exp( BETA2 [ BETA2_S ] ) * x52
6  exp( BETA2 [ BETA2_S ] ) * x62
 
 
[ParameterCovariances]
 //  Par_i         Par_j      Value  LowerBound UpperBound  status 
 BETA1_BETA1_S BETA2_BETA2_S   1.0      -10.0     10.0        0
\end{verbatim}
}
\normalsize

As mentioned in the manual, non linearities in the parameters must absolutely
be incorporated in the GeneralizedUtilities section of the input file.\ 

\subsection{Linear specification with independent heteroscedastic utilities}

In this version, the model is written as:%

\begin{equation}%
\begin{array}
[c]{ccccc}%
U_{1n}= & \alpha_{1} & +X_{11n}\beta_{1} & +X_{21n}\beta_{2} & +\nu_{1n}\\
U_{2n}= & \alpha_{2} & +X_{12n}\beta_{1} & +X_{22n}\beta_{2} & +\nu_{2n}\\
U_{3n}= & \alpha_{3} & +X_{13n}\beta_{1} & +X_{23n}\beta_{2} & +\nu_{3n}\\
U_{4n}= & \alpha_{4} & +X_{14n}\beta_{1} & +X_{24n}\beta_{2} & +\nu_{4n}\\
U_{5n}= & \alpha_{5} & +X_{15n}\beta_{1} & +X_{25n}\beta_{2} & +\nu_{5n}\\
U_{6n}= &  & +X_{16n}\beta_{1} & +X_{26n}\beta_{2} & +\nu_{6n}%
\end{array}
\end{equation}
where the $\alpha^{\prime}s$ are independent random variables each one with
its own specific variance, \ and where each $\beta_{k},k=1,2$ are fixed
coefficients. \ Identification conditions are discussed in Walker, Ben-Akiva
and Bolduc (2004). \ 

\subsubsection{Input file}

\begin{flushright}
  \verb+17_5.mod+
\end{flushright}
The main sections of the Biogeme file required to estimate this model is as follows:
\tiny
{\footnotesize
\begin{verbatim}
 
[Beta]
// Name   Value     LowerBound UpperBound  status (0=variable, 1=fixed)
ASC1        1.0          -10.0     10.0         0
ASC2        1.0          -10.0     10.0         0
ASC3        1.0          -10.0     10.0         0
ASC4        1.0          -10.0     10.0         0
ASC5        1.0          -10.0     10.0         0
BETA1       1.0          -10.0     10.0         0
BETA2       1.0          -10.0     10.0         0
ASC1_S      1.0          -10.0     10.0         0
ASC2_S      1.0          -10.0     10.0         0
ASC3_S      1.0          -10.0     10.0         0
ASC4_S      1.0          -10.0     10.0         0
ASC5_S      1.0          -10.0     10.0         0
 
[Utilities]
// Id  Name  Avail  linear-in-parameter expression (beta1*x1 + beta2*x2 + ... )
   1   Alt1    av1     ASC1 [ ASC1_S ]  * one + BETA1  * x11  + BETA2  * x12 
   2   Alt2    av2     ASC2 [ ASC2_S ]  * one + BETA1  * x21  + BETA2  * x22 
   3   Alt3    av3     ASC3 [ ASC3_S ]  * one + BETA1  * x31  + BETA2  * x32 
   4   Alt4    av4     ASC4 [ ASC4_S ]  * one + BETA1  * x41  + BETA2  * x42 
   5   Alt5    av5     ASC5 [ ASC5_S ]  * one + BETA1  * x51  + BETA2  * x52 
   6   Alt6    av6                              BETA1  * x61  + BETA2  * x62   
 
 
[Model]
// Currently, only $MNL (multinomial logit), $NL (nested logit), $CNL
// (cross-nested logit) and $NGEV (Network GEV model) are valid keywords
//
$MNL
 
\end{verbatim}
}
\normalsize

\subsection{Linear specification with error component structure}

In this version, the model is written as:%

\begin{equation}%
\begin{array}
[c]{cccccccc}%
U_{1n}= & \alpha_{1} & +X_{11n}\beta_{1} & +X_{12n}\beta_{2} & +\sigma_{1}%
\xi_{1n} &  &  & +\nu_{1n}\\
U_{2n}= & \alpha_{2} & +X_{21n}\beta_{1} & +X_{22n}\beta_{2} & +\sigma_{1}%
\xi_{1n} & +\sigma_{2}\xi_{2n} &  & +\nu_{2n}\\
U_{3n}= & \alpha_{3} & +X_{31n}\beta_{1} & +X_{32n}\beta_{2} &  & +\sigma
_{2}\xi_{2n} &  & +\nu_{3n}\\
U_{4n}= & \alpha_{4} & +X_{41n}\beta_{1} & +X_{42n}\beta_{2} &  & +\sigma
_{2}\xi_{2n} &  & +\nu_{4n}\\
U_{5n}= & \alpha_{5} & +X_{51n}\beta_{1} & +X_{52n}\beta_{2} &  & +\sigma
_{2}\xi_{2n} & +\sigma_{3}\xi_{3n} & +\nu_{5n}\\
U_{6n}= &  & +X_{61n}\beta_{1} & +X_{62n}\beta_{2} &  &  & +\sigma_{3}\xi_{3n}
& +\nu_{6n}%
\end{array}
\end{equation}
where the $\alpha^{\prime}s$ and each $\beta_{k},k=1,2$ are fixed
parameters$.$

\subsubsection{Input file}

\begin{flushright}
  \verb+17_6.mod+
\end{flushright}

The main sections of the Biogeme file required to estimate this model is as follows:

\tiny
{\footnotesize
\begin{verbatim}
[Beta]
// Name   Value     LowerBound UpperBound  status (0=variable, 1=fixed)
ASC1        1.0          -10.0     10.0         0
ASC2        1.0          -10.0     10.0         0
ASC3        1.0          -10.0     10.0         0
ASC4        1.0          -10.0     10.0         0
ASC5        1.0          -10.0     10.0         0
BETA1       1.0          -10.0     10.0         0
BETA2       1.0          -10.0     10.0         0
fact1       0.0          -10.0     10.0         1
fact2       0.0          -10.0     10.0         1
fact3       0.0          -10.0     10.0         1
fact1_s     1.0          -10.0     10.0         0
fact2_s     1.0          -10.0     10.0         0
fact3_s     1.0          -10.0     10.0         0

[Utilities]
// Id  Name  Avail  linear-in-parameter expression (beta1*x1 + beta2*x2 + ... )
   1   Alt1    av1     ASC1 * one + BETA1   * x11  + BETA2  * x12 + fact1 [ fact1_s ] * one
   2   Alt2    av2     ASC2 * one + BETA1   * x21  + BETA2  * x22 + fact1 [ fact1_s ] * one 
                       + fact2 [ fact2_s ] * one
   3   Alt3    av3     ASC3 * one + BETA1   * x31  + BETA2  * x32 + fact2 [ fact2_s ] * one
   4   Alt4    av4     ASC4 * one + BETA1   * x41  + BETA2  * x42 + fact2 [ fact2_s ] * one
   5   Alt5    av5     ASC5 * one + BETA1   * x51  + BETA2  * x52 + fact2 [ fact2_s ] * one 
                      + fact3 [ fact3_s ] * one
   6   Alt6    av6                  BETA1   * x61  + BETA2  * x62 + fact3 [ fact3_s ] * one
  

[Model]
// Currently, only $MNL (multinomial logit), $NL (nested logit), $CNL
// (cross-nested logit) and $NGEV (Network GEV model) are valid keywords
//
$MNL

\end{verbatim}
}
\normalsize

\subsection{Specification with non linear random heterogeneous value of time}

For this specialized version of the model, we consider estimating 
the following model:%

\begin{equation}%
\begin{array}
[c]{ccccc}%
U_{1n}= & \alpha_{1} & +X_{11n}\beta_{1} & +(\text{\textit{cost}}_{1n}\cdot
inc_{n}^{\eta})\beta_{2} & +\nu_{1n}\\
U_{2n}= & \alpha_{2} & +X_{21n}\beta_{1} & +(\text{\textit{cost}}_{2n}\cdot
inc_{n}^{\eta})\beta_{2} & +\nu_{2n}\\
U_{3n}= & \alpha_{3} & +X_{31n}\beta_{1} & +(\text{\textit{cost}}_{3n}\cdot
inc_{n}^{\eta})\beta_{2} & +\nu_{3n}\\
U_{4n}= & \alpha_{4} & +X_{41n}\beta_{1} & +(\text{\textit{cost}}_{4n}\cdot
inc_{n}^{\eta})\beta_{2} & +\nu_{4n}\\
U_{5n}= & \alpha_{5} & +X_{51n}\beta_{1} & +(\text{\textit{cost}}_{5n}\cdot
inc_{n}^{\eta})\beta_{2} & +\nu_{5n}\\
U_{6n}= &  & +X_{61n}\beta_{1} & +(\text{\textit{cost}}_{6n}\cdot
inc_{n}^{\eta})\beta_{2} & +\nu_{6n}%
\end{array}
\end{equation}
where the $\alpha^{\prime}s$ are fixed and where each $\beta_{k},k=1,2$ are
independently generated as follows: $\beta_{1}$ $\sim N(\bar{\beta}_{1}%
,\sigma_{1}^{2})$ and $\beta_{2}$ $\sim N(\bar{\beta}_{2},\sigma_{2}^{2}).$
The model contains a cost variable which vary across alternatives and an
income variable which is evaluated to the power $\eta$ where $\eta$ is a
normally distributed random coefficient. The database may be found in the
directory where the Biogeme input file resides. \ 

\subsubsection{Input file}

\begin{flushright}
  \verb+17_7.mod+

\end{flushright}
The main sections of the Biogeme file required to estimate this model is as follows:

\footnotesize
{\footnotesize
\begin{verbatim}

[Beta]
// Name   Value  LowerBound UpperBound  status (0=variable, 1=fixed)
ASC1        1.0        -10.0     10.0         0
ASC2        1.0        -10.0     10.0         0
ASC3        1.0        -10.0     10.0         0
ASC4        1.0        -10.0     10.0         0
ASC5        1.0        -10.0     10.0         0
BETA1       1.0        -10.0     10.0         0
BETA2       1.0        -10.0     10.0         0
BETA1_S     1.0        -10.0     10.0         0
BETA2_S     1.0        -10.0     10.0         0
ETA         1.0        -10.0     10.0         0
ETA_S       1.0        -10.0     10.0         0

[Utilities]
// Id  Name  Avail  linear-in-parameter expression 
   1   Alt1    av1     ASC1  * one + BETA1 [ BETA1_S ] * x11   
   2   Alt2    av2     ASC2  * one + BETA1 [ BETA1_S ] * x21   
   3   Alt3    av3     ASC3  * one + BETA1 [ BETA1_S ] * x31   
   4   Alt4    av4     ASC4  * one + BETA1 [ BETA1_S ] * x41   
   5   Alt5    av5     ASC5  * one + BETA1 [ BETA1_S ] * x51   
   6   Alt6    av6                   BETA1 [ BETA1_S ] * x61   
  
[GeneralizedUtilities]
// Id Name  Avail  linear-in-parameter expression 
1  BETA2 [ BETA2_S ] * ( inc ^ ETA [ ETA_S ] ) * cost1
2  BETA2 [ BETA2_S ] * ( inc ^ ETA [ ETA_S ] ) * cost2
3  BETA2 [ BETA2_S ] * ( inc ^ ETA [ ETA_S ] ) * cost3
4  BETA2 [ BETA2_S ] * ( inc ^ ETA [ ETA_S ] ) * cost4
5  BETA2 [ BETA2_S ] * ( inc ^ ETA [ ETA_S ] ) * cost5
6  BETA2 [ BETA2_S ] * ( inc ^ ETA [ ETA_S ] ) * cost6

    
[Model]
// Currently, only $MNL (multinomial logit), $NL (nested logit), $CNL
// (cross-nested logit) and $NGEV (Network GEV model) are valid keywords
$MNL
\end{verbatim}
}
\normalsize


Again, non linearities must be incorporated in the GeneralizedUtilities
section of the input file.

\subsection{Panel data}
\index{Panel data}
In Biogeme, when panel data is used, it is possible to identify which random parameters should vary only across individuals, and not across observations. This functionality is illustrated by the files \verb+17_8.mod+ and \verb+17_8simple.mod+.

\index{Examples|)}

\section{Compiling from the sources}
\label{sec:compiling}
\index{Compilation|(}

\BIOGEME\ has been developed using  GNU C++ (see, among many others,
\cite{Swan99}). In general, this environment is available on computer
running linux or Mac OS X operating systems. On computers running
Windows, several distributions of GNU tools are available (\cite{HageWeisZare01}). BIOGEME
is actually developed within the \texttt{cygwin} environment available
from \texttt{www.cygwin.com}. The
executable itself is compiled within the \texttt{Minimalist GNU for
Windows (MinGW)} environment, available at
\texttt{www.mingw.org}. The following
assumes that you are familiar with one of these environments. I have
included screen shots from the \texttt{MinGW} environment.

Before starting the installation, make sure to  install the Fast Light
Toolkit from \texttt{www.fltk.org} in order to be able
to compile the Graphical User Interface.



\begin{enumerate}
\item First, the distribution must be unzipped in a directory. It is
good practice to call that directory \texttt{biogeme}, but it is not
required. In this example, the directory is
\texttt{/home/biogeme}. After unzipping, the following should appear in
the directory:
\begin{center}
%\epsfig{figure=unzip,width=0.8\textwidth}
\end{center}

\item Before compiling, the environment variable \texttt{MAKEHOME}
must contain the name of the directory where the source files have
been installed. Depending on the Shell you are using, the syntax may
be slightly different.
If you use \texttt{tcsh} as a shell, type
{\footnotesize
\begin{verbatim}
setenv MAKEHOME `pwd`
\end{verbatim}
}
 If you use \texttt{bash} as a shell, type
{\footnotesize
\begin{verbatim}
export MAKEHOME=`pwd`
\end{verbatim}
}
as illustrated here:
\begin{center}
%\epsfig{figure=makehome,width=0.8\textwidth}
\end{center}
\item Type \texttt{make} or \texttt{gmake} to launch the
compilation. Depending on your computer, it may take several
minutes. You will probably obtain the following error message:
\begin{center}
%\epsfig{figure=norule,width=0.8\textwidth}
\end{center}
Just retype \texttt{make} or \texttt{gmake}. When it is done, you'll
obtain something like:
\begin{center}
%\epsfig{figure=makedone,width=0.8\textwidth}
\end{center}

These executables are now available: 
{\footnotesize
\begin{verbatim}
biogeme 
bioroute/bioroute 
biosim/biosim 
fltk/winbiogeme.exe 
\end{verbatim}
}
Make sure that you move them to a directory in your search path for executables, or that you update your path so that they can be found. 

\end{enumerate}

\index{Compilation|)}

\section{Parallel computing with BIOGEME}
\index{Parallel computing|(}

It is possible to run \BIOGEME\ much faster for the estimation of
multinomial logit (MNL) models, or mixtures of MNL, in particular
those involving nonlinear utility functions.  This is done within the
directory \texttt{fastbiogeme}. In order to illustrate the process, we
estimate the model from the file \texttt{16panel.mod} on a linux
machine with 8 processors. We first copy
the model specification file as well as the data file in the \texttt{fastbiogeme}
directory. 

\begin{center}
%\epsfig{figure=fastbiogeme,width=0.8\textwidth}
\end{center}

The core of \BIOGEME\ is available in this directory within the file
\texttt{libbiogeme.dll}. If you are using a linux machine, the
extension is expected to be \texttt{.so}, not \texttt{.dll}. In this
case, just rename the file.

\begin{center}
%\epsfig{figure=dllso,width=0.8\textwidth}
\end{center}

Now, the idea is to build an executable dedicated to your
model. Before doing that, it is useful to define the number of
processors on your computer. Edit the file \texttt{default.par} and
set the parameter \texttt{gevNumberOfThreads} to the appropriate
value. If you define more processors than the actual number, the
program will run just fine, but may be slowed down due to unnecessary
overhead. If you only have one processor, it is still worth using this
procedure, as the running time is significantly decreased, especially
when the model involves nonlinear utility functions.  In this case,
set the parameter  \texttt{gevNumberOfThreads} to 1.

When you're done, compile the software   using
the command
{\footnotesize
\begin{verbatim}
make mymodel.exe
\end{verbatim}
}
as illustrated below:
\begin{center}
%\epsfig{figure=make,width=0.8\textwidth}
\end{center}

As you can see, this involves the compilation of a C++
code. Consequently, it is recommended to use this feature after you've
compiled \BIOGEME\ on your own computer using the procedure described
in Section~\ref{sec:compiling}. 
The new executable can now be used instead of \texttt{biogeme} using
the following command:
{\footnotesize
\begin{verbatim}
16panel.exe 16panel sample.dat
\end{verbatim}
}
instead of 
{\footnotesize
\begin{verbatim}
biogeme.exe 16panel sample.dat
\end{verbatim}
}

This feature is recent. Although we have tested and used it in many
circumstances, there may be some problems on some
computers. Therefore, it is always good practice to check  on simple
models that the results provided by the parallel version are the same
as those provided by the regular version of \BIOGEME . Please report
any problem to the users' group. 

To illustrate the gain in speed, we have estimated the model \texttt{21mixed-lognormal} with 1000 and 5000 draws. The run time for estimation are reported in Table~\ref{tab:runtime}. 

\begin{table}[htbf]
\begin{center}
\begin{tabular}{rlll}
Version & \# processors & \multicolumn{2}{c}{Draws} \\
\cline{3-4}
   &    &  1000 & 5000 \\
\hline
BIOGEME & 1  & 08:03 & 38:41 \\
FASTBIOGEME & 1 & 01:37 & 07:48 \\
            & 2 & 01:08 & 05:43\\
            & 4 & 00:44 & 03:33 \\ 
            & 8 & 00:31 & 02:21\\
\end{tabular}

\end{center}
\caption{\label{tab:runtime}Actual run time (mm:ss) of BIOGEME  and FASTBIOGEME}
\end{table}



\index{Parallel computing|)}


\note{Talk about missing values}
\chapter{Pythonbiogeme}




\section{Acknowledgments}

I would like to thank the following persons who played various roles in the development of Biogeme along the years. The list is probably not complete, and I apologize for those who are omitted: 
Alexandre Alahi, 
Nicolas Antille, 
Gianluca Antonini, 
Kay Axhausen,
John Bates, 
Denis Bolduc,
David Bunch, 
Andrew Daly, 
Anna Fernandez Antolin,
Mamy Fetiarison,
Mogens Fosgerau, 
Emma Frejinger,
Carmine Gioia, 
Marie-H\'el\`ene Godbout, 
Stephane Hess, 
Richard Hurni, 
Jasper Knockaert, 
Xinjun Lai,
Carolina Osorio,
Thomas Robin,
Pascal Scheiben,
Matteo Sorci,
Micha\"el Th\'emans, 
Joan Walker.

Finally, I would like to express a special thank to Moshe Ben-Akiva
and Daniel McFadden for their friendship, and for the immense
influence that they had and still have on my work.

\clearpage
\appendix

\bibliographystyle{dcu}
\bibliography{dca}

\clearpage


\printindex





\end{document}





